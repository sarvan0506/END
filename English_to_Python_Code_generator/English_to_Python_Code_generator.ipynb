{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English_to_Python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAOjbR0vrYl-",
        "outputId": "5e9e5596-28a9-4765-bfa5-80cee1bda4f6"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsiaMgTLOyNj"
      },
      "source": [
        "## Import necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSh2dmzhreGD"
      },
      "source": [
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "from __future__ import unicode_literals\r\n",
        "\r\n",
        "import csv\r\n",
        "import random\r\n",
        "import re\r\n",
        "import os\r\n",
        "import math\r\n",
        "import time\r\n",
        "import unicodedata\r\n",
        "import codecs\r\n",
        "from io import open\r\n",
        "import itertools\r\n",
        "\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.jit import script, trace\r\n",
        "\r\n",
        "import torchtext\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "\r\n",
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13GbsC293LQZ"
      },
      "source": [
        "#!pip uninstall torch -y\r\n",
        "#!pip uninstall torchtext -y\r\n",
        "#!pip install torch==1.7 torchtext==0.8.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxkOAQAV_N5X",
        "outputId": "75dd2ba3-dafb-48ad-b43a-6a6403c7ec4c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEaW5tXEBKkY"
      },
      "source": [
        "with open('gdrive/MyDrive/END/eng_to_python/program_qa_sep.py', 'r') as datafile:\r\n",
        "    text = datafile.read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6nV4yLLO3ey"
      },
      "source": [
        "## Create Source and Target data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpkqcpodI0pe"
      },
      "source": [
        "questions = [x.split(\"\\n\")[0] for x in text.split('\\n\\n\\n#')]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXRuswhhGikm",
        "outputId": "8e528704-fc9d-40ed-b9dd-0f4e1b689fa1"
      },
      "source": [
        "# Split question and answer\r\n",
        "\r\n",
        "python_code = []\r\n",
        "\r\n",
        "for i, code in enumerate(text.split('\\n\\n\\n#')):\r\n",
        "    try:\r\n",
        "        python_code.append(code.split(questions[i]+\"\\n\")[1].strip())\r\n",
        "    except:\r\n",
        "        print(i)\r\n",
        "        print(code)\r\n",
        "        python_code.append(\" \")\r\n",
        "        next"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106\n",
            " write the list comprehension to pick out only negative integers from a\n",
            "153\n",
            " write a python program to print only digit or only apha charac in a\n",
            "1290\n",
            " 44 write a python program to  rotate dictionary by K\n",
            "1311\n",
            " 64 write a program  to convert string to dictionary and print it\n",
            "1548\n",
            " Python program to find whether a given number (accept from the user) is even or odd, print out an appropriate\n",
            "1559\n",
            " Python program to print out all even numbers from a given numbers list in the same order and stop the printing if\n",
            "1575\n",
            " Python program to create a list containing the power of said number in bases raised to the corresponding number in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRhvOa6VPOLL"
      },
      "source": [
        "## Clean the code by seperating special characters to reduce number of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkzcQ-de9kx4"
      },
      "source": [
        "\r\n",
        "clean_code = []\r\n",
        "\r\n",
        "for code in python_code:\r\n",
        "  code = code.replace(\"(\", \" ( \")\r\n",
        "  code = code.replace(\"[\", \" [ \")\r\n",
        "  code = code.replace(\":\", \" : \")\r\n",
        "  code = code.replace(\")\", \" ) \")\r\n",
        "  code = code.replace(\",\", \" , \")\r\n",
        "  \r\n",
        "  \r\n",
        "  code = code.replace(\"]\", \" ] \")\r\n",
        "  code = code.replace(\"}\", \" } \")\r\n",
        "  code = code.replace(\"{\", \" { \")\r\n",
        "  code = code.replace(\"=\", \" = \")\r\n",
        "  code = code.replace(\"=  =\", \"==\")\r\n",
        "  code = code.replace(\"> =\", \">=\")\r\n",
        "  code = code.replace(\"< =\", \"<=\")\r\n",
        "  code = code.replace(\"! =\", \"!=\")\r\n",
        "  code = code.replace(\"+ =\", \"+=\")\r\n",
        "  code = code.replace(\"- =\", \"-=\")\r\n",
        "  code = code.replace(\"* =\", \"*=\")\r\n",
        "  code = code.replace(\"/ =\", \"/=\")\r\n",
        "  code = code.replace(\"& =\", \"&=\")\r\n",
        "  # <\r\n",
        "  code = code.replace(\"<\", \" < \")\r\n",
        "  code = code.replace(\"< <\", \"<<\")\r\n",
        "  code = code.replace(\"< =\", \"<=\")\r\n",
        "  code = code.replace(\"< -\", \"<-\")\r\n",
        "  # -\r\n",
        "  code = code.replace(\"-\", \" - \")\r\n",
        "  code = code.replace(\"- =\", \"-=\")\r\n",
        "  code = code.replace(\"< -\", \"<-\")\r\n",
        "  # >\r\n",
        "  code = code.replace(\">\", \" > \")\r\n",
        "  code = code.replace(\"> >\", \">>\")\r\n",
        "  code = code.replace(\"> =\", \">=\")\r\n",
        "  # !\r\n",
        "  code = code.replace(\"!\", \" ! \")\r\n",
        "  code = code.replace(\"! =\", \"!=\")\r\n",
        "  # +\r\n",
        "  code = code.replace(\"+\", \" + \")\r\n",
        "  code = code.replace(\"+ =\", \"+=\")\r\n",
        "  # *\r\n",
        "  code = code.replace(\"*\", \" * \")\r\n",
        "  code = code.replace(\"* *\", \"**\")\r\n",
        "  code = code.replace(\"* =\", \"*=\")\r\n",
        "  # /\r\n",
        "  code = code.replace(\"/\", \" / \")\r\n",
        "  code = code.replace(\"/ /\", \"//\")\r\n",
        "  code = code.replace(\"/ =\", \"/=\")\r\n",
        "  # &\r\n",
        "  code = code.replace(\"&\", \" & \")\r\n",
        "  code = code.replace(\"& =\", \"&=\")\r\n",
        "  code = code.replace(\"& &\", \"&&\")\r\n",
        "  # ~\r\n",
        "  code = code.replace(\"~\", \" ~ \")\r\n",
        "  # \\n\r\n",
        "  #code = code.replace(\"\\n\", \" \\n \")\r\n",
        "  \r\n",
        "\r\n",
        "  clean_code.append(code)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#clean_code = python_code"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxCE8XtyoR1K",
        "outputId": "251ce13a-d9b4-4715-a765-5a072ec52152"
      },
      "source": [
        "k = 988\r\n",
        "\r\n",
        "questions[k], clean_code[k]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' 56 Write a Python function to find three numbers from an array such that the sum of three numbers equal to zero.',\n",
              " 'def three_Sum ( num )  : \\n    if len ( num )  < 3 :  return  [  ] \\n    num.sort (  ) \\n    result =  [  ] \\n    for i in range ( len ( num )  - 2 )  : \\n        left = i + 1\\n        right = len ( num )  - 1\\n        if i != 0 and num [ i ]  == num [ i - 1 ]  : continue\\n        while left < right : \\n            if num [ left ]  + num [ right ]  ==  - num [ i ]  : \\n                result.append (  [ num [ i ]  , num [ left ]  , num [ right ]  ]  ) \\n                left = left + 1\\n                right = right - 1\\n                while num [ left ]  == num [ left - 1 ]  and left < right : left = left + 1\\n                while num [ right ]  == num [ right + 1 ]  and left < right :  right = right - 1\\n            elif num [ left ]  + num [ right ]  <- num [ i ]  : \\n                left = left + 1\\n            else : \\n                right = right - 1\\n    return result')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPYQ2f9jPeBa"
      },
      "source": [
        "## Define tokenizers and Field objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4ssJsyXIhIG",
        "outputId": "2ee1713d-179a-4fbd-ccd6-8e4b2d5e11ea"
      },
      "source": [
        "def tokenize_en_char(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(\" \".join([tok for tok in text]), )]\r\n",
        "\r\n",
        "def tokenize_en_word(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text, )]\r\n",
        "\r\n",
        "\r\n",
        "SRC = Field(tokenize = tokenize_en_word, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "TRG = Field(tokenize = tokenize_en_word, \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = False, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "fields = [('src',SRC), ('trg', TRG)]\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixSK2LpgIj6d",
        "outputId": "0cf222ba-f1df-4576-926c-99654f190e27"
      },
      "source": [
        "example = [torchtext.data.Example.fromlist([questions[i], clean_code[i]], fields) for i in range(len(questions))] \r\n",
        "pyDataset = torchtext.data.Dataset(example, fields)\r\n",
        "(train, valid, test) = pyDataset.split(split_ratio=[0.9, 0.07, 0.03], random_state=random.seed(SEED))\r\n",
        "(len(train), len(valid), len(test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3920, 130, 305)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMA9QuXVPwjL"
      },
      "source": [
        "## Filter Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zngHP3qh8TS4",
        "outputId": "1a504b89-921c-4091-ff63-d416dbf80ddf"
      },
      "source": [
        "MAX_SEQ_LEN = 256\r\n",
        "\r\n",
        "MIN_SEQ_LEN = 10\r\n",
        "\r\n",
        "\r\n",
        "for i in range(len(train.examples)):\r\n",
        "\r\n",
        "  train_trg = vars(train.examples[i])['trg']\r\n",
        "\r\n",
        "  if len(train_trg) > (MAX_SEQ_LEN - 2):\r\n",
        "    del train.examples[i]\r\n",
        "    i = 0\r\n",
        "\r\n",
        "for i in range(len(test.examples)):\r\n",
        "\r\n",
        "  test_trg = vars(test.examples[i])['trg']\r\n",
        "\r\n",
        "  if len(test_trg) > (MAX_SEQ_LEN - 2):\r\n",
        "    del test.examples[i]\r\n",
        "    i = 0\r\n",
        "\r\n",
        "for i in range(len(valid.examples)):\r\n",
        "\r\n",
        "  val_trg = vars(valid.examples[i])['trg']\r\n",
        "\r\n",
        "  if len(val_trg) > (MAX_SEQ_LEN - 2):\r\n",
        "    del valid.examples[i]\r\n",
        "    i = 0\r\n",
        "\r\n",
        "(len(train), len(valid), len(test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3851, 129, 296)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NFGRNY59vJB",
        "outputId": "a29813e6-27e1-4a2d-c40f-e4fb1be1cc56"
      },
      "source": [
        "vars(valid.examples[91])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': [' ',\n",
              "  'calculate',\n",
              "  'memory',\n",
              "  'is',\n",
              "  'being',\n",
              "  'used',\n",
              "  'by',\n",
              "  'an',\n",
              "  'list',\n",
              "  'in',\n",
              "  'python'],\n",
              " 'trg': ['import',\n",
              "  'sys',\n",
              "  '\\n',\n",
              "  'list1',\n",
              "  ' ',\n",
              "  '=',\n",
              "  '  ',\n",
              "  '[',\n",
              "  \"'\",\n",
              "  'Scott',\n",
              "  \"'\",\n",
              "  ',',\n",
              "  ' ',\n",
              "  \"'\",\n",
              "  'Eric',\n",
              "  \"'\",\n",
              "  ',',\n",
              "  ' ',\n",
              "  \"'\",\n",
              "  'Kelly',\n",
              "  \"'\",\n",
              "  ',',\n",
              "  ' ',\n",
              "  \"'\",\n",
              "  'Emma',\n",
              "  \"'\",\n",
              "  ',',\n",
              "  ' ',\n",
              "  \"'\",\n",
              "  'Smith',\n",
              "  \"'\",\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'print',\n",
              "  '(',\n",
              "  '\"',\n",
              "  'size',\n",
              "  'of',\n",
              "  'list',\n",
              "  ' ',\n",
              "  '=',\n",
              "  ' ',\n",
              "  '\"',\n",
              "  ',',\n",
              "  'sys.getsizeof',\n",
              "  '(',\n",
              "  'list1',\n",
              "  ')',\n",
              "  ' ',\n",
              "  ')']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkZ_D_yW9IXY"
      },
      "source": [
        "# Build vocabulary\r\n",
        "SRC.build_vocab(pyDataset, min_freq = 2)\r\n",
        "TRG.build_vocab(pyDataset, min_freq = 2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEGWARyKYrHW",
        "outputId": "30429372-69c0-459d-9c22-2d68f86b0835"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1603, 5125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3I0pLzQ8U-p",
        "outputId": "52f8553d-ace7-4618-88e1-1ac162cb6089"
      },
      "source": [
        "vars(TRG.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'import': 734,\n",
              "          'functools': 17,\n",
              "          '\\n': 5320,\n",
              "          'os': 28,\n",
              "          'from': 301,\n",
              "          'time': 85,\n",
              "          'localtime': 2,\n",
              "          'threading': 5,\n",
              "          'Thread': 9,\n",
              "          'random': 141,\n",
              "          're': 61,\n",
              "          'itertools': 62,\n",
              "          'json': 27,\n",
              "          'datetime': 132,\n",
              "          'date': 37,\n",
              "          'num1': 282,\n",
              "          ' ': 56202,\n",
              "          '=': 13149,\n",
              "          '1.5': 12,\n",
              "          'num2': 266,\n",
              "          '6.3': 11,\n",
              "          'sum': 417,\n",
              "          '+': 2673,\n",
              "          'print': 3876,\n",
              "          '(': 18525,\n",
              "          \"f'Sum\": 9,\n",
              "          ':': 11615,\n",
              "          '  ': 5253,\n",
              "          '{': 1418,\n",
              "          '}': 1418,\n",
              "          \"'\": 6708,\n",
              "          ')': 18516,\n",
              "          'def': 2605,\n",
              "          'add_two_numbers': 5,\n",
              "          ',': 13468,\n",
              "          '\\n    ': 5077,\n",
              "          'return': 2523,\n",
              "          '10': 581,\n",
              "          '12': 213,\n",
              "          'num3': 52,\n",
              "          '14': 29,\n",
              "          'if': 2123,\n",
              "          '>': 884,\n",
              "          'and': 489,\n",
              "          'largest': 95,\n",
              "          'elif': 272,\n",
              "          'else': 902,\n",
              "          \"f'largest\": 5,\n",
              "          '<': 628,\n",
              "          'smallest': 23,\n",
              "          \"f'smallest\": 2,\n",
              "          'merge_lists': 6,\n",
              "          'l1': 110,\n",
              "          'l2': 88,\n",
              "          'num': 934,\n",
              "          '337': 1,\n",
              "          '1': 3658,\n",
              "          'for': 2418,\n",
              "          'i': 2974,\n",
              "          'in': 2749,\n",
              "          'range': 985,\n",
              "          '2': 1933,\n",
              "          '/': 1019,\n",
              "          '\\n        ': 2698,\n",
              "          '%': 780,\n",
              "          '0': 2679,\n",
              "          '\\n            ': 984,\n",
              "          '\"': 8800,\n",
              "          'is': 1078,\n",
              "          'not': 364,\n",
              "          'a': 1804,\n",
              "          'prime': 51,\n",
              "          'number': 432,\n",
              "          'f': 253,\n",
              "          'times': 38,\n",
              "          'break': 151,\n",
              "          '\\n   ': 608,\n",
              "          'print_factors': 6,\n",
              "          'x': 1625,\n",
              "          'f\"The': 24,\n",
              "          'factors': 23,\n",
              "          'of': 569,\n",
              "          'are': 138,\n",
              "          '13': 38,\n",
              "          'factorial': 74,\n",
              "          '\\n\\n': 1073,\n",
              "          'No': 34,\n",
              "          'factorials': 1,\n",
              "          'negative': 15,\n",
              "          'numbers': 142,\n",
              "          '!': 438,\n",
              "          'The': 508,\n",
              "          '*': 2153,\n",
              "          'check_pnz': 1,\n",
              "          'Positive': 10,\n",
              "          '\\n\\n    ': 321,\n",
              "          'Zero': 8,\n",
              "          'Negative': 7,\n",
              "          '9': 347,\n",
              "          '11': 132,\n",
              "          'two_power': 1,\n",
              "          'terms': 46,\n",
              "          'result': 429,\n",
              "          'list': 868,\n",
              "          'map': 100,\n",
              "          'lambda': 194,\n",
              "          'total': 74,\n",
              "          'f\"2^': 1,\n",
              "          '[': 5672,\n",
              "          ']': 5671,\n",
              "          'my_list': 103,\n",
              "          '45': 70,\n",
              "          '74': 1,\n",
              "          '89': 12,\n",
              "          '132': 1,\n",
              "          '239': 3,\n",
              "          '721': 1,\n",
              "          '21': 52,\n",
              "          '3': 1031,\n",
              "          'filter': 63,\n",
              "          'f\"Numbers': 2,\n",
              "          'divisible': 11,\n",
              "          'by': 54,\n",
              "          'sum_natural': 1,\n",
              "          'Please': 43,\n",
              "          'enter': 34,\n",
              "          'positive': 22,\n",
              "          'while': 388,\n",
              "          '-=': 55,\n",
              "          '4': 892,\n",
              "          '5': 905,\n",
              "          '6': 547,\n",
              "          '-': 2350,\n",
              "          'findArea': 8,\n",
              "          'r': 383,\n",
              "          'PI': 18,\n",
              "          '3.142': 5,\n",
              "          'n': 1806,\n",
              "          'sum_n': 3,\n",
              "          '7': 448,\n",
              "          '8': 427,\n",
              "          'len': 938,\n",
              "          'my_tuple': 6,\n",
              "          'custom_print': 1,\n",
              "          'l': 362,\n",
              "          '_': 899,\n",
              "          'remove_odd': 1,\n",
              "          'remove_even': 1,\n",
              "          'zip_list': 1,\n",
              "          'list1': 310,\n",
              "          'list2': 120,\n",
              "          'zip': 116,\n",
              "          'file_name': 7,\n",
              "          'temp.txt': 1,\n",
              "          'with': 127,\n",
              "          'open': 81,\n",
              "          'as': 127,\n",
              "          'f.read': 5,\n",
              "          'lcm': 66,\n",
              "          'b': 721,\n",
              "          'min': 71,\n",
              "          'True': 284,\n",
              "          'set': 196,\n",
              "          'digisum': 1,\n",
              "          'dig': 21,\n",
              "          '/=': 26,\n",
              "          '12321': 1,\n",
              "          'temp': 254,\n",
              "          'rev': 36,\n",
              "          'palindrome': 31,\n",
              "          \"n't\": 19,\n",
              "          'print_n': 1,\n",
              "          'val': 161,\n",
              "          'square_area': 2,\n",
              "          'square_perimeter': 1,\n",
              "          'rectangle_area': 2,\n",
              "          'rectangle_perimeter': 1,\n",
              "          'calc_elect_bill': 1,\n",
              "          'units': 5,\n",
              "          '750': 3,\n",
              "          'give_day': 1,\n",
              "          'day_dict': 2,\n",
              "          'Sunday': 2,\n",
              "          'Monday': 2,\n",
              "          'Tuesday': 2,\n",
              "          'Wednesday': 2,\n",
              "          'Thursday': 2,\n",
              "          'Friday': 2,\n",
              "          'Saturday': 2,\n",
              "          'h': 121,\n",
              "          'pi': 112,\n",
              "          '3.14': 58,\n",
              "          'volume': 46,\n",
              "          'calc_avg': 1,\n",
              "          'args': 86,\n",
              "          'None': 144,\n",
              "          'comp_int': 1,\n",
              "          'p': 132,\n",
              "          't': 149,\n",
              "          'amount': 13,\n",
              "          '100': 170,\n",
              "          'interest': 18,\n",
              "          'simp_int': 1,\n",
              "          'st': 26,\n",
              "          'Where': 1,\n",
              "          'this': 59,\n",
              "          'going': 1,\n",
              "          '?': 136,\n",
              "          'Could': 1,\n",
              "          'you': 44,\n",
              "          'please': 4,\n",
              "          'help': 6,\n",
              "          'me': 2,\n",
              "          'understand': 2,\n",
              "          'vowels': 63,\n",
              "          'AEIOUaeiou': 6,\n",
              "          'v': 75,\n",
              "          'st.replace': 1,\n",
              "          'is_perfect': 1,\n",
              "          'False': 200,\n",
              "          'seperate_pn': 1,\n",
              "          'pos_list': 2,\n",
              "          'neg_list': 2,\n",
              "          'neg_list.append': 1,\n",
              "          'pos_list.append': 1,\n",
              "          'w': 40,\n",
              "          'area': 68,\n",
              "          '0.5': 41,\n",
              "          'acc': 1,\n",
              "          'u': 53,\n",
              "          'multiply': 21,\n",
              "          'add': 20,\n",
              "          'even': 34,\n",
              "          'ascii': 1,\n",
              "          'chr': 25,\n",
              "          'dig_cnt': 1,\n",
              "          'str': 707,\n",
              "          'is_valid_triangle_angle': 1,\n",
              "          'c': 405,\n",
              "          '180': 19,\n",
              "          'is_valid_triangle_length': 1,\n",
              "          'count_word': 1,\n",
              "          's': 603,\n",
              "          's.split': 17,\n",
              "          'int': 510,\n",
              "          'input': 466,\n",
              "          'Enter': 212,\n",
              "          'multiple': 9,\n",
              "          'digit': 63,\n",
              "          'end': 303,\n",
              "          'bmi': 16,\n",
              "          'height': 107,\n",
              "          'Meters': 1,\n",
              "          'weight': 10,\n",
              "          'Kgs': 1,\n",
              "          'Your': 7,\n",
              "          'BMI': 1,\n",
              "          '.format': 72,\n",
              "          \"''\": 197,\n",
              "          '16': 57,\n",
              "          'severely': 2,\n",
              "          'underweight': 2,\n",
              "          '.': 449,\n",
              "          '18.5': 2,\n",
              "          '25': 50,\n",
              "          'healthy': 1,\n",
              "          '30': 76,\n",
              "          'overweight': 2,\n",
              "          'string': 443,\n",
              "          '$': 18,\n",
              "          'john.snow#@Got.bad_ending': 1,\n",
              "          'com': 5,\n",
              "          'ch': 17,\n",
              "          'A': 174,\n",
              "          'Z': 14,\n",
              "          'or': 183,\n",
              "          'z': 100,\n",
              "          'pass': 54,\n",
              "          'hanoi': 11,\n",
              "          'cm_to_inch': 1,\n",
              "          '2.54': 4,\n",
              "          'union': 9,\n",
              "          '|': 62,\n",
              "          'intersection': 15,\n",
              "          '&': 91,\n",
              "          '32': 38,\n",
              "          'con_str': 1,\n",
              "          'sep': 18,\n",
              "          '\\n  ': 471,\n",
              "          'sep.join': 1,\n",
              "          'r1': 8,\n",
              "          'r2': 12,\n",
              "          '28': 6,\n",
              "          'dict1': 31,\n",
              "          'car': 1,\n",
              "          'bike': 1,\n",
              "          'truck': 1,\n",
              "          '19': 24,\n",
              "          'original': 206,\n",
              "          'dictionary': 120,\n",
              "          'res': 663,\n",
              "          'dict': 125,\n",
              "          'key': 528,\n",
              "          'sorted': 139,\n",
              "          'now': 20,\n",
              "          'datetime.datetime.now': 10,\n",
              "          'now.strftime': 1,\n",
              "          'Y': 106,\n",
              "          'm': 123,\n",
              "          'd': 436,\n",
              "          'H': 16,\n",
              "          'M': 41,\n",
              "          'S': 19,\n",
              "          'f\"Current': 1,\n",
              "          \"f'Absolute\": 1,\n",
              "          'abs': 24,\n",
              "          'sample_list': 5,\n",
              "          \"f'length\": 1,\n",
              "          'f_date': 5,\n",
              "          '2019': 3,\n",
              "          '15': 79,\n",
              "          '#': 776,\n",
              "          'YYYY': 3,\n",
              "          'MM': 3,\n",
              "          'DD': 3,\n",
              "          'l_date': 5,\n",
              "          '2020': 38,\n",
              "          'delta': 16,\n",
              "          \"f'No\": 1,\n",
              "          'days': 22,\n",
              "          'between': 33,\n",
              "          'delta.days': 5,\n",
              "          'python_dict': 2,\n",
              "          'name': 148,\n",
              "          'David': 1,\n",
              "          'age': 42,\n",
              "          'class': 168,\n",
              "          'I': 48,\n",
              "          'json_dict': 2,\n",
              "          'json.dumps': 9,\n",
              "          'sort_keys': 7,\n",
              "          'indent': 7,\n",
              "          'f\"json': 1,\n",
              "          'max_num_in_list': 2,\n",
              "          'max': 112,\n",
              "          '\\n\\n\\n': 156,\n",
              "          \"f'max_num_in_list\": 1,\n",
              "          'Ans': 1,\n",
              "          '20': 187,\n",
              "          '50': 79,\n",
              "          '60': 69,\n",
              "          '40': 60,\n",
              "          '80': 12,\n",
              "          'dup_items': 12,\n",
              "          'uniq_items': 8,\n",
              "          'uniq_items.append': 5,\n",
              "          'dup_items.add': 5,\n",
              "          \"f'dup_items\": 1,\n",
              "          'original_list': 2,\n",
              "          'new_merged_list': 2,\n",
              "          'itertools.chain': 3,\n",
              "          \"f'merged\": 1,\n",
              "          'flatten': 20,\n",
              "          'obj': 23,\n",
              "          \"f'create\": 1,\n",
              "          'd1': 17,\n",
              "          '200': 30,\n",
              "          'd2': 20,\n",
              "          '300': 13,\n",
              "          'y': 581,\n",
              "          'd1.copy': 3,\n",
              "          'd.update': 9,\n",
              "          \"f'merge\": 1,\n",
              "          'two': 81,\n",
              "          'dictionaries': 3,\n",
              "          'my_dict': 12,\n",
              "          'data1': 1,\n",
              "          'data2': 1,\n",
              "          '54': 31,\n",
              "          'data3': 1,\n",
              "          '247': 1,\n",
              "          'all': 59,\n",
              "          'the': 572,\n",
              "          'items': 48,\n",
              "          'my_dict.values': 1,\n",
              "          '500': 12,\n",
              "          '5874': 1,\n",
              "          '560': 1,\n",
              "          'key_max': 2,\n",
              "          'my_dict.keys': 2,\n",
              "          'k': 375,\n",
              "          'key_min': 2,\n",
              "          'Maximum': 11,\n",
              "          'Value': 20,\n",
              "          'Minimum': 5,\n",
              "          'Nothing': 1,\n",
              "          'count': 410,\n",
              "          'value': 260,\n",
              "          'enumerate': 51,\n",
              "          'a_dict': 2,\n",
              "          'a_dict.setdefault': 1,\n",
              "          \"f'After\": 2,\n",
              "          'appending': 5,\n",
              "          'new': 24,\n",
              "          'square': 20,\n",
              "          'squared': 2,\n",
              "          \"f'mapped\": 1,\n",
              "          \"f'modulo\": 1,\n",
              "          'Sol': 1,\n",
              "          'global': 25,\n",
              "          'enclosing': 2,\n",
              "          'g': 42,\n",
              "          'obj1': 4,\n",
              "          'explain': 2,\n",
              "          'scope': 2,\n",
              "          'f1': 7,\n",
              "          'local': 3,\n",
              "          'obj2': 3,\n",
              "          'Find': 6,\n",
              "          'characters': 35,\n",
              "          'given': 33,\n",
              "          're.findall': 21,\n",
              "          '123FOO456': 1,\n",
              "          '\\n         ': 83,\n",
              "          'flags': 3,\n",
              "          'IGNORECASE': 1,\n",
              "          'foo123bar': 1,\n",
              "          '123': 10,\n",
              "          'find': 23,\n",
              "          'position': 25,\n",
              "          \"f'convert\": 2,\n",
              "          'lowercase': 14,\n",
              "          'to': 289,\n",
              "          'uppercase': 10,\n",
              "          'a.upper': 1,\n",
              "          'STRING': 1,\n",
              "          'a.lower': 1,\n",
              "          'num_sqrt': 8,\n",
              "          'root': 17,\n",
              "          '0.3f': 7,\n",
              "          'kilometers': 28,\n",
              "          '10.0': 1,\n",
              "          'conv_fac': 16,\n",
              "          '0.621371': 8,\n",
              "          'miles': 20,\n",
              "          '0.2f': 11,\n",
              "          'equal': 24,\n",
              "          'celsius': 28,\n",
              "          '37.5': 6,\n",
              "          'fahrenheit': 21,\n",
              "          '1.8': 13,\n",
              "          '0.1f': 12,\n",
              "          'degree': 16,\n",
              "          'Celsius': 11,\n",
              "          'Fahrenheit': 8,\n",
              "          '\\n      ': 205,\n",
              "          'Even\".format': 3,\n",
              "          'Odd\".format': 3,\n",
              "          'Rolling': 5,\n",
              "          'dices': 6,\n",
              "          '...': 77,\n",
              "          'values': 83,\n",
              "          'random.randint': 22,\n",
              "          'average': 9,\n",
              "          'f\"the': 1,\n",
              "          'score': 10,\n",
              "          '   ': 35,\n",
              "          \"f'reverese\": 1,\n",
              "          'elements': 46,\n",
              "          'print_time': 3,\n",
              "          'threadName': 2,\n",
              "          'delay': 2,\n",
              "          'time.sleep': 3,\n",
              "          'time.ctime': 2,\n",
              "          'time.time': 4,\n",
              "          'try': 35,\n",
              "          '    ': 7,\n",
              "          'target': 27,\n",
              "          '.start': 2,\n",
              "          'except': 39,\n",
              "          'Error': 6,\n",
              "          'unable': 1,\n",
              "          'start': 174,\n",
              "          'thread': 1,\n",
              "          'near_thousand': 8,\n",
              "          '1000': 28,\n",
              "          '2000': 29,\n",
              "          'near': 2,\n",
              "          '1300': 2,\n",
              "          'ab': 4,\n",
              "          'cd': 4,\n",
              "          'i.upper': 4,\n",
              "          'names1': 2,\n",
              "          'Amir': 1,\n",
              "          'Bala': 1,\n",
              "          'Chales': 1,\n",
              "          'n.lower': 1,\n",
              "          'amir': 1,\n",
              "          'Yes': 13,\n",
              "          'exists': 4,\n",
              "          'matrix': 39,\n",
              "          'activities': 2,\n",
              "          'Sleeping': 1,\n",
              "          '\\n              ': 17,\n",
              "          'Commuting': 2,\n",
              "          '17': 38,\n",
              "          'Working': 1,\n",
              "          '18': 39,\n",
              "          'Eating': 1,\n",
              "          '22': 45,\n",
              "          'Resting': 1,\n",
              "          'time_now': 1,\n",
              "          'hour': 3,\n",
              "          'time_now.tm_hour': 1,\n",
              "          'activity_time': 3,\n",
              "          'activities.keys': 1,\n",
              "          'Unknown': 4,\n",
              "          'AFK': 1,\n",
              "          'sleeping': 1,\n",
              "          'fname': 57,\n",
              "          'sample.txt': 1,\n",
              "          'keyword': 3,\n",
              "          'letter': 86,\n",
              "          'be': 33,\n",
              "          'searched': 1,\n",
              "          'line': 68,\n",
              "          'words': 159,\n",
              "          'line.split': 20,\n",
              "          '\\n                ': 241,\n",
              "          'Occurrences': 3,\n",
              "          'tuple_sorted': 2,\n",
              "          'tuple': 138,\n",
              "          'integers': 10,\n",
              "          'pune': 1,\n",
              "          'mumbai': 1,\n",
              "          'delhi': 1,\n",
              "          'w.upper': 1,\n",
              "          'l3': 9,\n",
              "          'added': 1,\n",
              "          'row': 70,\n",
              "          'unpack': 3,\n",
              "          'lamb': 2,\n",
              "          'python': 67,\n",
              "          'maximum': 28,\n",
              "          'a.values': 1,\n",
              "          'a.keys': 1,\n",
              "          'a.pop': 2,\n",
              "          'john': 4,\n",
              "          'peter': 3,\n",
              "          '466': 1,\n",
              "          'd.keys': 5,\n",
              "          'frozenset': 1,\n",
              "          'Exception': 8,\n",
              "          'e': 80,\n",
              "          'nums': 139,\n",
              "          \"abcdefcdghcd'.split\": 1,\n",
              "          \"ef'.title\": 1,\n",
              "          \"ab'.zfill\": 1,\n",
              "          \"abcdef12'.replace\": 1,\n",
              "          'str1': 487,\n",
              "          'Hello': 93,\n",
              "          '2@#World': 1,\n",
              "          'str1.istitle': 1,\n",
              "          'title': 1,\n",
              "          \"xyyzxxyxyy'.lstrip\": 1,\n",
              "          'xyy': 1,\n",
              "          \"for'.isidentifier\": 1,\n",
              "          \"11'.isnumeric\": 1,\n",
              "          '1@': 1,\n",
              "          \"a'.isprintable\": 1,\n",
              "          '.isspace': 1,\n",
              "          \"HelloWorld'.istitle\": 1,\n",
              "          \"12'.isalnum\": 1,\n",
              "          \"ab'.isalpha\": 1,\n",
              "          \"0xa'.isdigit\": 1,\n",
              "          'var1': 2,\n",
              "          'language': 4,\n",
              "          \"f'f\": 1,\n",
              "          'an': 74,\n",
              "          'good': 35,\n",
              "          'feature': 1,\n",
              "          'D': 35,\n",
              "          'san': 1,\n",
              "          'q': 32,\n",
              "          'foundry': 1,\n",
              "          'a.replace': 1,\n",
              "          'f11': 2,\n",
              "          'yield': 51,\n",
              "          'next': 40,\n",
              "          'f12': 2,\n",
              "          'test': 11,\n",
              "          're.compile': 7,\n",
              "          'a.findall': 1,\n",
              "          'trees': 1,\n",
              "          'os.getcwd': 2,\n",
              "          'ord': 68,\n",
              "          'abc': 8,\n",
              "          '56': 9,\n",
              "          'a.append': 10,\n",
              "          '87': 4,\n",
              "          'a.extend': 2,\n",
              "          '67': 11,\n",
              "          'my_string': 13,\n",
              "          'balaji': 1,\n",
              "          'aeiou': 22,\n",
              "          'Not': 23,\n",
              "          'vowel': 12,\n",
              "          ';': 228,\n",
              "          'j': 869,\n",
              "          'oh': 1,\n",
              "          'excellent': 1,\n",
              "          '450': 1,\n",
              "          'n.isalpha': 1,\n",
              "          'n.isdigit': 1,\n",
              "          'tday': 2,\n",
              "          'datetime.date.today': 1,\n",
              "          'functools.reduce': 2,\n",
              "          'cat': 5,\n",
              "          'window': 1,\n",
              "          'defenestrate': 1,\n",
              "          'make_incrementor': 2,\n",
              "          '42': 7,\n",
              "          'pairs': 2,\n",
              "          'one': 26,\n",
              "          'three': 13,\n",
              "          'four': 10,\n",
              "          'pairs.sort': 1,\n",
              "          'pair': 19,\n",
              "          '66.25': 1,\n",
              "          '333': 6,\n",
              "          '1234.5': 1,\n",
              "          'del': 21,\n",
              "          'word': 275,\n",
              "          'goal': 2,\n",
              "          'phrase': 1,\n",
              "          'surprise': 2,\n",
              "          'here': 12,\n",
              "          'somewhere': 1,\n",
              "          'phrase.find': 1,\n",
              "          'assert': 12,\n",
              "          'X': 126,\n",
              "          'too': 5,\n",
              "          'small': 1,\n",
              "          '2.3': 4,\n",
              "          'product': 43,\n",
              "          \"f'Product\": 3,\n",
              "          'divide_first_number_by_second': 3,\n",
              "          'largest_and_smallest': 3,\n",
              "          'list_of_nums': 18,\n",
              "          'fibonacci_recursive': 1,\n",
              "          '\\n       ': 264,\n",
              "          'recur_fibo': 13,\n",
              "          'read_and_print_file': 3,\n",
              "          'filepath': 14,\n",
              "          'infile': 3,\n",
              "          'infile.read': 3,\n",
              "          '62': 3,\n",
              "          'sort_ascending': 3,\n",
              "          'list_to_be_sorted': 33,\n",
              "          'sort_descending': 3,\n",
              "          'reverse': 69,\n",
              "          'sum_first_n': 3,\n",
              "          'sum_first_n_recursive': 6,\n",
              "          'filter_with_key_value': 3,\n",
              "          'list_of_dicts': 12,\n",
              "          'x.get': 4,\n",
              "          'seq': 23,\n",
              "          'SeqType': 6,\n",
              "          'type': 51,\n",
              "          'emptySeq': 9,\n",
              "          'restrev': 6,\n",
              "          'first': 83,\n",
              "          'selection_sort': 7,\n",
              "          'sorted_list': 45,\n",
              "          'new_min': 12,\n",
              "          'new_min_old_place': 9,\n",
              "          'old_val': 6,\n",
              "          'User': 7,\n",
              "          'Input': 52,\n",
              "          'shift_and_scale': 3,\n",
              "          'mean': 21,\n",
              "          'std': 6,\n",
              "          'list_of_seq': 6,\n",
              "          'guess': 19,\n",
              "          'will': 22,\n",
              "          'within': 5,\n",
              "          'chances': 3,\n",
              "          'guess1': 6,\n",
              "          'Is': 18,\n",
              "          'it': 55,\n",
              "          '\\\\n': 42,\n",
              "          'guess2': 12,\n",
              "          'guess3': 6,\n",
              "          'Yay': 15,\n",
              "          'found': 67,\n",
              "          'its': 20,\n",
              "          'a.update': 3,\n",
              "          'reverse_string': 7,\n",
              "          'str_to_be_reversed': 6,\n",
              "          'World': 42,\n",
              "          'a.items': 3,\n",
              "          'print_ascii': 3,\n",
              "          'char': 164,\n",
              "          'hcf': 35,\n",
              "          'smaller': 46,\n",
              "          'bigger': 15,\n",
              "          'recursive_sum': 6,\n",
              "          'delete_last_element': 3,\n",
              "          'list_to_be_processed': 6,\n",
              "          'deleted_element': 6,\n",
              "          'list_to_be_processed.pop': 3,\n",
              "          'square_list_elements': 3,\n",
              "          'list_to_be_squared': 6,\n",
              "          'find_integer_square_roots': 3,\n",
              "          'integer': 27,\n",
              "          'input_num': 12,\n",
              "          '27': 4,\n",
              "          'divide': 9,\n",
              "          'abcde': 5,\n",
              "          'Found': 6,\n",
              "          'sort_and_merge': 6,\n",
              "          'new_list': 20,\n",
              "          'l1_len': 9,\n",
              "          'l2_len': 9,\n",
              "          'new_list.append': 10,\n",
              "          'recursive_merge_sort': 9,\n",
              "          'final_list': 10,\n",
              "          'last': 33,\n",
              "          'final_list.extend': 6,\n",
              "          'mid': 140,\n",
              "          'cal_mean': 3,\n",
              "          'num_list': 57,\n",
              "          'float': 511,\n",
              "          'cal_median': 3,\n",
              "          '\\n                    ': 32,\n",
              "          'cal_triangle_area': 3,\n",
              "          'round': 32,\n",
              "          'cal_eq_triangle_area': 3,\n",
              "          'cal_rt_triangle_area': 3,\n",
              "          'base': 98,\n",
              "          'cal_dist_from_orign': 3,\n",
              "          'cal_cart_distance': 3,\n",
              "          'x1': 41,\n",
              "          'y1': 21,\n",
              "          'x2': 35,\n",
              "          'y2': 21,\n",
              "          'root_type': 3,\n",
              "          'real': 7,\n",
              "          'imaginary': 7,\n",
              "          'sum_of_roots': 3,\n",
              "          'prod_of_roots': 3,\n",
              "          'roots_of_qad_eq': 3,\n",
              "          'find_profit_or_loss': 3,\n",
              "          'cp': 15,\n",
              "          'sp': 21,\n",
              "          'loss': 6,\n",
              "          'profit': 6,\n",
              "          'no': 36,\n",
              "          'cal_area_rect': 3,\n",
              "          'length': 144,\n",
              "          'breadth': 22,\n",
              "          'cal_area_square': 3,\n",
              "          'side': 58,\n",
              "          'cal_area_rhombus': 3,\n",
              "          'q1': 14,\n",
              "          'q2': 14,\n",
              "          'cal_area_trapezium': 3,\n",
              "          'cal_area_circle': 3,\n",
              "          'cal_circumference': 3,\n",
              "          'cal_perimeter_rect': 3,\n",
              "          'bredth': 6,\n",
              "          'cal_perimeter_triangle': 3,\n",
              "          's1': 113,\n",
              "          's2': 65,\n",
              "          's3': 10,\n",
              "          'cal_perimeter_square': 3,\n",
              "          'cal_perimeter_eq_triangle': 3,\n",
              "          'cal_perimeter_iso_triangle': 3,\n",
              "          'cal_area_ellipse': 3,\n",
              "          'minor': 6,\n",
              "          'major': 6,\n",
              "          'cal_cylinder_lat_surf_area': 3,\n",
              "          'radius': 140,\n",
              "          'cal_cone_curved_surf_area': 3,\n",
              "          'slant_height': 8,\n",
              "          'cal_surface_area_cube': 3,\n",
              "          'cal_surface_area_cuboid': 3,\n",
              "          'cal_area_sphere': 3,\n",
              "          'cal_area_hemisphere': 3,\n",
              "          'cal_cylinder_surf_area': 3,\n",
              "          'cal_cone_lateral_surf_area': 3,\n",
              "          'cal_cylinder_volume': 3,\n",
              "          'cal_cone_volume': 3,\n",
              "          'cal_hemisphere_volume': 3,\n",
              "          'cal_sphere_volume': 3,\n",
              "          'cal_cuboid_volume': 3,\n",
              "          'cal_cube_volume': 3,\n",
              "          'cal_speed': 3,\n",
              "          'distance': 29,\n",
              "          'cal_distance': 3,\n",
              "          'speed': 19,\n",
              "          'cal_time': 3,\n",
              "          'cal_torque': 3,\n",
              "          'force': 6,\n",
              "          'theta': 26,\n",
              "          'math': 106,\n",
              "          'math.sin': 18,\n",
              "          'cal_angular_velocity': 3,\n",
              "          'angular_dist': 6,\n",
              "          'cal_focal_length_of_lense': 3,\n",
              "          'cal_gforce': 3,\n",
              "          'mass1': 6,\n",
              "          'mass2': 6,\n",
              "          '6.674': 3,\n",
              "          'cal_current': 3,\n",
              "          'resistance': 6,\n",
              "          'voltage': 6,\n",
              "          'cal_total_cap_in_parallel': 3,\n",
              "          'cap_list': 6,\n",
              "          'cal_total_res_in_parallel': 3,\n",
              "          'res_list': 22,\n",
              "          'cal_total_res_in_series': 3,\n",
              "          'cal_mi_ring': 3,\n",
              "          'mass': 36,\n",
              "          'cal_mi_sphere': 3,\n",
              "          'find_pressure_of_ideal_gas': 3,\n",
              "          '8.3145': 9,\n",
              "          'gas': 9,\n",
              "          'constant': 9,\n",
              "          'R': 26,\n",
              "          'find_volume_of_ideal_gas': 3,\n",
              "          'pressure': 12,\n",
              "          'find_temp_of_ideal_gas': 3,\n",
              "          'cal_final_velocity': 3,\n",
              "          'initial_velocity': 12,\n",
              "          'accelration': 12,\n",
              "          '\\n     ': 142,\n",
              "          'cal_displacement': 3,\n",
              "          '.5': 4,\n",
              "          'cal_half_life': 3,\n",
              "          'initail_quatity': 6,\n",
              "          'time_elapsed': 6,\n",
              "          'half_life': 6,\n",
              "          'cal_sp_after_discount': 3,\n",
              "          'discount': 6,\n",
              "          'get_si': 3,\n",
              "          'get_ci': 3,\n",
              "          'cal_energy_by_mass': 3,\n",
              "          '300000': 3,\n",
              "          'cal_ke': 3,\n",
              "          'velocity': 6,\n",
              "          'cal_pe': 3,\n",
              "          '9.8': 3,\n",
              "          'cal_electrostatic_force': 3,\n",
              "          'cal_density': 3,\n",
              "          'Write': 8,\n",
              "          'function': 106,\n",
              "          'convert': 10,\n",
              "          'temprature': 4,\n",
              "          '\\n ': 73,\n",
              "          'temp_converter': 5,\n",
              "          'temp_given_in': 4,\n",
              "          'Return': 16,\n",
              "          'converted': 9,\n",
              "          'temp_given_in.lower': 3,\n",
              "          'Convert': 17,\n",
              "          'C': 76,\n",
              "          'F': 19,\n",
              "          'merge1': 3,\n",
              "          'test_list1': 47,\n",
              "          '\\n                   ': 8,\n",
              "          'gfg': 49,\n",
              "          'test_list2': 39,\n",
              "          'fg': 3,\n",
              "          'idx': 189,\n",
              "          'id_keys': 6,\n",
              "          '.keys': 5,\n",
              "          '\\n\\n            ': 16,\n",
              "          'Merged': 3,\n",
              "          'Dictionary': 19,\n",
              "          'vertical_concatenation': 6,\n",
              "          'test_list': 380,\n",
              "          'program': 20,\n",
              "          'vertical': 3,\n",
              "          'concatenation': 4,\n",
              "          'N': 174,\n",
              "          'IndexError': 12,\n",
              "          'res.append': 46,\n",
              "          'ele': 261,\n",
              "          'List': 57,\n",
              "          'after': 104,\n",
              "          'column': 11,\n",
              "          'Concatenation': 6,\n",
              "          'kth_column': 3,\n",
              "          'K': 127,\n",
              "          'Kth': 7,\n",
              "          'printSubArrays': 12,\n",
              "          'arr': 374,\n",
              "          'sum_nestedlist': 9,\n",
              "          'power': 42,\n",
              "          'P': 39,\n",
              "          'f_substring': 3,\n",
              "          'substring': 23,\n",
              "          'sub_str': 26,\n",
              "          'geeks': 42,\n",
              "          'Filtered': 11,\n",
              "          'r_punc': 3,\n",
              "          'test_str': 100,\n",
              "          'best': 91,\n",
              "          'Nlp': 3,\n",
              "          'punc': 6,\n",
              "          '\\\\': 86,\n",
              "          '@#$%^': 18,\n",
              "          '~': 28,\n",
              "          'test_str.replace': 8,\n",
              "          'punctuation': 13,\n",
              "          'htness_4': 1,\n",
              "          'gnomeSort': 6,\n",
              "          'index': 167,\n",
              "          '34': 14,\n",
              "          'Sorted': 40,\n",
              "          'seqquence': 3,\n",
              "          'applying': 3,\n",
              "          'Gnome': 3,\n",
              "          'Sort': 3,\n",
              "          'pigeonhole_sort': 6,\n",
              "          'my_min': 12,\n",
              "          'my_max': 6,\n",
              "          'size': 87,\n",
              "          'holes': 12,\n",
              "          'only': 5,\n",
              "          'order': 25,\n",
              "          'stoogesort': 15,\n",
              "          'difference': 33,\n",
              "          'h1': 13,\n",
              "          'm1': 15,\n",
              "          'h2': 9,\n",
              "          'm2': 15,\n",
              "          't1': 22,\n",
              "          't2': 20,\n",
              "          'Both': 6,\n",
              "          'same': 14,\n",
              "          'diff': 17,\n",
              "          '24': 61,\n",
              "          '23': 46,\n",
              "          'convert24': 11,\n",
              "          'AM': 16,\n",
              "          '00': 14,\n",
              "          'PM': 13,\n",
              "          '08': 6,\n",
              "          '05': 5,\n",
              "          'calcAngle': 10,\n",
              "          'hh': 25,\n",
              "          'mm': 86,\n",
              "          'hour_angle': 10,\n",
              "          'minute_angle': 10,\n",
              "          'angle': 51,\n",
              "          '360': 5,\n",
              "          'printTime': 9,\n",
              "          'valid': 17,\n",
              "          '90.0': 4,\n",
              "          'counter': 8,\n",
              "          'fn': 38,\n",
              "          'inner': 32,\n",
              "          'kwargs': 38,\n",
              "          'nonlocal': 13,\n",
              "          \"f'Function\": 2,\n",
              "          'fn.__name': 6,\n",
              "          'was': 19,\n",
              "          'called': 9,\n",
              "          '    \\n    ': 42,\n",
              "          'remove_duplicatesinlist': 2,\n",
              "          'lst': 166,\n",
              "          'timed': 2,\n",
              "          'perf_counter': 10,\n",
              "          'wraps': 4,\n",
              "          '@wraps': 2,\n",
              "          ' \\n    ': 529,\n",
              "          'elapsed': 4,\n",
              "          '\\n\\n        ': 71,\n",
              "          'kwargs.items': 3,\n",
              "          'all_args': 4,\n",
              "          'args_str': 4,\n",
              "          '.join': 159,\n",
              "          'comma': 4,\n",
              "          'delimited': 2,\n",
              "          'took': 2,\n",
              "          'seconds': 9,\n",
              "          'input_string': 6,\n",
              "          'element': 101,\n",
              "          'separated': 5,\n",
              "          'space': 17,\n",
              "          'input_string.split': 4,\n",
              "          ' \\n': 624,\n",
              "          'stringlist_to_intlist': 2,\n",
              "          'sList': 4,\n",
              "          ' \\n  ': 30,\n",
              "          'map_values': 2,\n",
              "          'nextSquare': 2,\n",
              "          'An': 5,\n",
              "          ...}),\n",
              " 'itos': ['<unk>',\n",
              "  '<pad>',\n",
              "  '<sos>',\n",
              "  '<eos>',\n",
              "  ' ',\n",
              "  '(',\n",
              "  ')',\n",
              "  ',',\n",
              "  '=',\n",
              "  ':',\n",
              "  '\"',\n",
              "  \"'\",\n",
              "  '[',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  '  ',\n",
              "  '\\n    ',\n",
              "  'print',\n",
              "  '1',\n",
              "  'i',\n",
              "  'in',\n",
              "  '\\n        ',\n",
              "  '0',\n",
              "  '+',\n",
              "  'def',\n",
              "  'return',\n",
              "  'for',\n",
              "  '-',\n",
              "  '*',\n",
              "  'if',\n",
              "  '2',\n",
              "  'n',\n",
              "  'a',\n",
              "  'x',\n",
              "  '{',\n",
              "  '}',\n",
              "  'is',\n",
              "  '\\n\\n',\n",
              "  '3',\n",
              "  '/',\n",
              "  'range',\n",
              "  '\\n            ',\n",
              "  'len',\n",
              "  'num',\n",
              "  '5',\n",
              "  'else',\n",
              "  '_',\n",
              "  '4',\n",
              "  '>',\n",
              "  'j',\n",
              "  'list',\n",
              "  '%',\n",
              "  '#',\n",
              "  'import',\n",
              "  'b',\n",
              "  'str',\n",
              "  'res',\n",
              "  '<',\n",
              "  ' \\n',\n",
              "  '\\n   ',\n",
              "  's',\n",
              "  '10',\n",
              "  'y',\n",
              "  'the',\n",
              "  'of',\n",
              "  '6',\n",
              "  ' \\n    ',\n",
              "  'key',\n",
              "  'float',\n",
              "  'int',\n",
              "  'The',\n",
              "  'and',\n",
              "  'str1',\n",
              "  '\\n  ',\n",
              "  'input',\n",
              "  '.',\n",
              "  '7',\n",
              "  'string',\n",
              "  '!',\n",
              "  'd',\n",
              "  'number',\n",
              "  'result',\n",
              "  '8',\n",
              "  'alist',\n",
              "  ' \\n        ',\n",
              "  'sum',\n",
              "  'count',\n",
              "  'c',\n",
              "  'while',\n",
              "  'r',\n",
              "  'test_list',\n",
              "  'k',\n",
              "  'arr',\n",
              "  'not',\n",
              "  'l',\n",
              "  '9',\n",
              "  '\\n\\n    ',\n",
              "  'list1',\n",
              "  'end',\n",
              "  'from',\n",
              "  'self',\n",
              "  'to',\n",
              "  'True',\n",
              "  'num1',\n",
              "  'word',\n",
              "  'elif',\n",
              "  'num2',\n",
              "  '\\n       ',\n",
              "  'ele',\n",
              "  'value',\n",
              "  'temp',\n",
              "  'f',\n",
              "  '\\n                ',\n",
              "  ' \\n  \\n',\n",
              "  ';',\n",
              "  '12',\n",
              "  '\\n\\t',\n",
              "  'Enter',\n",
              "  'original',\n",
              "  '\\n      ',\n",
              "  'li',\n",
              "  'False',\n",
              "  \"''\",\n",
              "  'set',\n",
              "  'lambda',\n",
              "  'idx',\n",
              "  '20',\n",
              "  ' \\n\\n',\n",
              "  'or',\n",
              "  'A',\n",
              "  'N',\n",
              "  'start',\n",
              "  '100',\n",
              "  'class',\n",
              "  'index',\n",
              "  'lst',\n",
              "  'char',\n",
              "  'val',\n",
              "  '.join',\n",
              "  'words',\n",
              "  'sub',\n",
              "  'year',\n",
              "  '\\n\\n\\n',\n",
              "  ' \\n            ',\n",
              "  'break',\n",
              "  't',\n",
              "  'name',\n",
              "  'None',\n",
              "  'length',\n",
              "  '\\n     ',\n",
              "  'numbers',\n",
              "  'random',\n",
              "  'mid',\n",
              "  'radius',\n",
              "  'nums',\n",
              "  'sorted',\n",
              "  'are',\n",
              "  'tuple',\n",
              "  'data',\n",
              "  '?',\n",
              "  'item',\n",
              "  '11',\n",
              "  'datetime',\n",
              "  'p',\n",
              "  'K',\n",
              "  'as',\n",
              "  'with',\n",
              "  'X',\n",
              "  'dict',\n",
              "  'm',\n",
              "  'h',\n",
              "  'dictionary',\n",
              "  'list2',\n",
              "  '\\n  \\n',\n",
              "  'zip',\n",
              "  's1',\n",
              "  'max',\n",
              "  'pi',\n",
              "  'test_dict',\n",
              "  'l1',\n",
              "  'height',\n",
              "  'Y',\n",
              "  'function',\n",
              "  'greater',\n",
              "  'math',\n",
              "  'after',\n",
              "  '\\n \\n    ',\n",
              "  'check',\n",
              "  'my_list',\n",
              "  'element',\n",
              "  'map',\n",
              "  'test_str',\n",
              "  'z',\n",
              "  'base',\n",
              "  'init',\n",
              "  'largest',\n",
              "  'Hello',\n",
              "  '\\n           ',\n",
              "  '&',\n",
              "  'best',\n",
              "  'printing',\n",
              "  'l2',\n",
              "  'size',\n",
              "  '\\\\',\n",
              "  'args',\n",
              "  'letter',\n",
              "  'mm',\n",
              "  'time',\n",
              "  'left',\n",
              "  '\\n         ',\n",
              "  'first',\n",
              "  'values',\n",
              "  'tup',\n",
              "  'B',\n",
              "  'open',\n",
              "  'two',\n",
              "  'Number',\n",
              "  'e',\n",
              "  'sentence',\n",
              "  '15',\n",
              "  '50',\n",
              "  '...',\n",
              "  'right',\n",
              "  '30',\n",
              "  'C',\n",
              "  'raise',\n",
              "  '  \\n',\n",
              "  'v',\n",
              "  'an',\n",
              "  'factorial',\n",
              "  'isinstance',\n",
              "  'total',\n",
              "  '\\n ',\n",
              "  '.format',\n",
              "  'upper',\n",
              "  '\\n\\n        ',\n",
              "  'min',\n",
              "  '45',\n",
              "  'iterable',\n",
              "  'lower',\n",
              "  'row',\n",
              "  '60',\n",
              "  'reverse',\n",
              "  '\\n\\t\\t',\n",
              "  'area',\n",
              "  'line',\n",
              "  'ord',\n",
              "  'found',\n",
              "  'python',\n",
              "  'text',\n",
              "  'lcm',\n",
              "  '\\n \\n',\n",
              "  'String',\n",
              "  's2',\n",
              "  'sum1',\n",
              "  '  \\n    ',\n",
              "  'digit',\n",
              "  'filter',\n",
              "  'vowels',\n",
              "  '\\n          ',\n",
              "  'itertools',\n",
              "  '|',\n",
              "  '24',\n",
              "  're',\n",
              "  '40',\n",
              "  'all',\n",
              "  'this',\n",
              "  '3.14',\n",
              "  'side',\n",
              "  'write',\n",
              "  '16',\n",
              "  'Gfg',\n",
              "  'List',\n",
              "  'fname',\n",
              "  'num_list',\n",
              "  'ValueError',\n",
              "  '-=',\n",
              "  'all_freq',\n",
              "  'it',\n",
              "  ' \\n      \\n    ',\n",
              "  'by',\n",
              "  'leap',\n",
              "  'pass',\n",
              "  'u',\n",
              "  '21',\n",
              "  'Input',\n",
              "  'n1',\n",
              "  'num3',\n",
              "  'angle',\n",
              "  'enumerate',\n",
              "  'n2',\n",
              "  'prime',\n",
              "  'type',\n",
              "  'yield',\n",
              "  '25',\n",
              "  'final',\n",
              "  'E',\n",
              "  'gfg',\n",
              "  ' \\n             ',\n",
              "  'I',\n",
              "  'items',\n",
              "  'my_str',\n",
              "  '\\n    \\n    ',\n",
              "  'flag',\n",
              "  'object',\n",
              "  'test_list1',\n",
              "  ' \\n  \\n    ',\n",
              "  '23',\n",
              "  'This',\n",
              "  'elements',\n",
              "  'file',\n",
              "  'pos',\n",
              "  'res.append',\n",
              "  'smaller',\n",
              "  'str2',\n",
              "  'terms',\n",
              "  'volume',\n",
              "  '22',\n",
              "  'sorted_list',\n",
              "  '\\n\\n   ',\n",
              "  '\\n \\n \\n',\n",
              "  'fact',\n",
              "  'you',\n",
              "  'Geeks',\n",
              "  'Please',\n",
              "  'array',\n",
              "  'no_punct',\n",
              "  'product',\n",
              "  ' \\n\\n    ',\n",
              "  '    \\n    ',\n",
              "  'World',\n",
              "  '\\\\n',\n",
              "  'age',\n",
              "  'g',\n",
              "  'geeks',\n",
              "  'letters',\n",
              "  'newList',\n",
              "  'power',\n",
              "  '  \\n   ',\n",
              "  '   \\n    ',\n",
              "  '0.5',\n",
              "  'M',\n",
              "  'dd',\n",
              "  'exp',\n",
              "  'x1',\n",
              "  'Sorted',\n",
              "  'keys',\n",
              "  'myList',\n",
              "  'next',\n",
              "  'rows',\n",
              "  'set1',\n",
              "  'w',\n",
              "  '\\n      \\n    ',\n",
              "  '18',\n",
              "  'P',\n",
              "  'bin',\n",
              "  'day',\n",
              "  'dec',\n",
              "  'digitCount',\n",
              "  'except',\n",
              "  'matrix',\n",
              "  'test_list2',\n",
              "  '13',\n",
              "  '17',\n",
              "  '2020',\n",
              "  '32',\n",
              "  'fn',\n",
              "  'kwargs',\n",
              "  'source',\n",
              "  'times',\n",
              "  'date',\n",
              "  'iterate',\n",
              "  '.append',\n",
              "  '.split',\n",
              "  '^\\\\s',\n",
              "  'do',\n",
              "  'mass',\n",
              "  'no',\n",
              "  'o',\n",
              "  'rev',\n",
              "  'url',\n",
              "  '   ',\n",
              "  'D',\n",
              "  'Fibonacci',\n",
              "  'characters',\n",
              "  'good',\n",
              "  'hcf',\n",
              "  'initializing',\n",
              "  'raw_input',\n",
              "  'try',\n",
              "  'tsai',\n",
              "  'x2',\n",
              "  'No',\n",
              "  '^',\n",
              "  'at',\n",
              "  'enter',\n",
              "  'even',\n",
              "  'reversed',\n",
              "  'tuples',\n",
              "  'Invalid',\n",
              "  'be',\n",
              "  'between',\n",
              "  'difference',\n",
              "  'given',\n",
              "  'hello',\n",
              "  'input_array',\n",
              "  'last',\n",
              "  'list_to_be_sorted',\n",
              "  'present',\n",
              "  'your',\n",
              "  '\\n                    ',\n",
              "  '  \\n       ',\n",
              "  '35',\n",
              "  '70',\n",
              "  'It',\n",
              "  'filename',\n",
              "  'inner',\n",
              "  'q',\n",
              "  'regex',\n",
              "  'round',\n",
              "  '  \\n        ',\n",
              "  '54',\n",
              "  'ctr',\n",
              "  'dict1',\n",
              "  'mylist',\n",
              "  'palindrome',\n",
              "  'punctuations',\n",
              "  'set2',\n",
              "  ' \\n  ',\n",
              "  ' \\n       ',\n",
              "  '   \\n',\n",
              "  '200',\n",
              "  'any',\n",
              "  'character',\n",
              "  'digits',\n",
              "  'nterms',\n",
              "  'test_dict.items',\n",
              "  ' \\n                ',\n",
              "  '  \\n  \\n',\n",
              "  '14',\n",
              "  '2000',\n",
              "  '44',\n",
              "  'collections',\n",
              "  'dict2',\n",
              "  'distance',\n",
              "  'empty',\n",
              "  'input_list',\n",
              "  'lists',\n",
              "  'reduce',\n",
              "  'through',\n",
              "  'unique',\n",
              "  'width',\n",
              "  '\\n  \\n    ',\n",
              "  ' \\n              ',\n",
              "  '1000',\n",
              "  '88',\n",
              "  'L',\n",
              "  'celsius',\n",
              "  'code',\n",
              "  'destination',\n",
              "  'gap',\n",
              "  'kilometers',\n",
              "  'maximum',\n",
              "  'operation',\n",
              "  'os',\n",
              "  'password',\n",
              "  'year\".format',\n",
              "  '~',\n",
              "  'Dict',\n",
              "  'choice',\n",
              "  'i%2',\n",
              "  'integer',\n",
              "  'json',\n",
              "  'limit',\n",
              "  'low',\n",
              "  'sampleList',\n",
              "  'second',\n",
              "  'src_dir_path',\n",
              "  'str1.split',\n",
              "  'target',\n",
              "  'timedelta',\n",
              "  '/=',\n",
              "  'Original',\n",
              "  'R',\n",
              "  'binary',\n",
              "  'foo',\n",
              "  'no_swap',\n",
              "  'nth',\n",
              "  'one',\n",
              "  'rate',\n",
              "  'sign',\n",
              "  'st',\n",
              "  'sub_str',\n",
              "  'theta',\n",
              "  'top',\n",
              "  \"'d\",\n",
              "  'Counter',\n",
              "  'a_list',\n",
              "  'chr',\n",
              "  'func',\n",
              "  'gcd',\n",
              "  'global',\n",
              "  'hh',\n",
              "  'marks',\n",
              "  'order',\n",
              "  'position',\n",
              "  'var',\n",
              "  'world',\n",
              "  '\\n\\t    ',\n",
              "  ' \\n   ',\n",
              "  '19',\n",
              "  '400',\n",
              "  '65',\n",
              "  'Best',\n",
              "  'abs',\n",
              "  'countDict',\n",
              "  'equal',\n",
              "  'f\"The',\n",
              "  'input_dict',\n",
              "  'ip_str',\n",
              "  'month',\n",
              "  'new',\n",
              "  'new_str',\n",
              "  'odd',\n",
              "  'org_intervals',\n",
              "  'pool',\n",
              "  'random.choice',\n",
              "  'random.sample',\n",
              "  'repeat',\n",
              "  'returns',\n",
              "  'vow_list',\n",
              "  '\\n \\n ',\n",
              "  'Not',\n",
              "  'apple',\n",
              "  'col',\n",
              "  'factors',\n",
              "  'find',\n",
              "  'given_date',\n",
              "  'high',\n",
              "  'main',\n",
              "  'math.sqrt',\n",
              "  'move',\n",
              "  'node',\n",
              "  'obj',\n",
              "  'percentage',\n",
              "  'self.length',\n",
              "  'seq',\n",
              "  'sequence',\n",
              "  'smallest',\n",
              "  'substring',\n",
              "  '\\n\\n  ',\n",
              "  '  \\n            ',\n",
              "  '120',\n",
              "  'Python',\n",
              "  'aeiou',\n",
              "  'breadth',\n",
              "  'days',\n",
              "  'does',\n",
              "  'each',\n",
              "  'email',\n",
              "  'exist',\n",
              "  'iterator',\n",
              "  'positive',\n",
              "  'pow',\n",
              "  'random.randint',\n",
              "  'res_list',\n",
              "  'sentence.split',\n",
              "  't1',\n",
              "  'will',\n",
              "  ' \\n     ',\n",
              "  '.lower',\n",
              "  '0.0',\n",
              "  '26',\n",
              "  'Area',\n",
              "  'columns',\n",
              "  'curr',\n",
              "  'del',\n",
              "  'dig',\n",
              "  'eval',\n",
              "  'fahrenheit',\n",
              "  'how',\n",
              "  'key1',\n",
              "  'max1',\n",
              "  'mean',\n",
              "  'multiply',\n",
              "  'names',\n",
              "  'org',\n",
              "  're.findall',\n",
              "  'sp',\n",
              "  'than',\n",
              "  'y1',\n",
              "  'y2',\n",
              "  ' \\n      \\n',\n",
              "  '  \\n  \\n    ',\n",
              "  '155',\n",
              "  'Armstrong',\n",
              "  'Value',\n",
              "  'add',\n",
              "  'bool',\n",
              "  'bottom',\n",
              "  'd.items',\n",
              "  'd2',\n",
              "  'fib',\n",
              "  'flatten',\n",
              "  'get',\n",
              "  'groupby',\n",
              "  'have',\n",
              "  'ip',\n",
              "  'its',\n",
              "  'line.split',\n",
              "  'miles',\n",
              "  'new_list',\n",
              "  'now',\n",
              "  'program',\n",
              "  'queue',\n",
              "  'quick',\n",
              "  'script',\n",
              "  'self.list',\n",
              "  'self.radius',\n",
              "  'sine',\n",
              "  'square',\n",
              "  'steps',\n",
              "  't2',\n",
              "  'time.upper',\n",
              "  'using',\n",
              "  'word_list',\n",
              "  'yy',\n",
              "  '\\n          \\n    ',\n",
              "  ' \\n         ',\n",
              "  ' \\n          ',\n",
              "  '180',\n",
              "  'Dictionary',\n",
              "  'F',\n",
              "  'Person',\n",
              "  'S',\n",
              "  '\\\\w',\n",
              "  'ans',\n",
              "  'dt',\n",
              "  'frequency',\n",
              "  'guess',\n",
              "  'lines',\n",
              "  'lis',\n",
              "  'my',\n",
              "  \"n't\",\n",
              "  'pair',\n",
              "  're.search',\n",
              "  'self.cache',\n",
              "  'side_length',\n",
              "  'speed',\n",
              "  'str_list',\n",
              "  'test_tup1',\n",
              "  'triangle',\n",
              "  'was',\n",
              "  '\\n\\n\\t',\n",
              "  '$',\n",
              "  '55',\n",
              "  '66',\n",
              "  '@#$%^',\n",
              "  'CS',\n",
              "  'Is',\n",
              "  'JSON',\n",
              "  'PI',\n",
              "  'Total',\n",
              "  'aList',\n",
              "  'arr1',\n",
              "  'auxiliary',\n",
              "  'banana',\n",
              "  'brown',\n",
              "  'f\"String',\n",
              "  'files_in_dir',\n",
              "  'fox',\n",
              "  'inner_list',\n",
              "  'interest',\n",
              "  'list_of_nums',\n",
              "  'math.pi',\n",
              "  'math.sin',\n",
              "  'minimum',\n",
              "  'msg',\n",
              "  'my_list1',\n",
              "  'no_of_sides',\n",
              "  'num_words',\n",
              "  'numpy',\n",
              "  'pd',\n",
              "  'person_dict',\n",
              "  'resList',\n",
              "  'self.queue',\n",
              "  'sep',\n",
              "  'shuffle',\n",
              "  'start_at',\n",
              "  'sub_set',\n",
              "  'sys',\n",
              "  'test_tup2',\n",
              "  'use',\n",
              "  '\\n              ',\n",
              "  ' \\n\\t',\n",
              "  ' \\n\\t\\t',\n",
              "  ' \\n  \\n\\n',\n",
              "  '01',\n",
              "  'Convert',\n",
              "  'First',\n",
              "  'Move',\n",
              "  'bar',\n",
              "  'cache',\n",
              "  'ch',\n",
              "  'compute_lcm',\n",
              "  'd1',\n",
              "  'diff',\n",
              "  'functools',\n",
              "  'into',\n",
              "  'iter',\n",
              "  'math.exp',\n",
              "  'replace',\n",
              "  'root',\n",
              "  's.split',\n",
              "  'self.head',\n",
              "  'si',\n",
              "  'space',\n",
              "  'valid',\n",
              "  'variable',\n",
              "  'z0',\n",
              "  '\\n\\t\\t\\t',\n",
              "  '\\n\\n ',\n",
              "  '\\n\\n            ',\n",
              "  '  \\n           ',\n",
              "  '   \\n        ',\n",
              "  '90',\n",
              "  '93',\n",
              "  'AM',\n",
              "  'CASE',\n",
              "  'For',\n",
              "  'H',\n",
              "  'Kelly',\n",
              "  'Nikhil',\n",
              "  'Return',\n",
              "  'You',\n",
              "  'bisect',\n",
              "  'bmi',\n",
              "  'circumradius',\n",
              "  'conv_fac',\n",
              "  'conversion',\n",
              "  'count.get',\n",
              "  'current',\n",
              "  'degree',\n",
              "  'delta',\n",
              "  'el',\n",
              "  'has',\n",
              "  'highestnumber',\n",
              "  'https',\n",
              "  'ini_tuple',\n",
              "  'make',\n",
              "  'math.cos',\n",
              "  'math.floor',\n",
              "  'maxnum',\n",
              "  'minutes',\n",
              "  'numberList',\n",
              "  'perm',\n",
              "  'pop',\n",
              "  'radians',\n",
              "  'ratio',\n",
              "  'res_date',\n",
              "  'result_perms',\n",
              "  'seen',\n",
              "  'self.items',\n",
              "  'shift',\n",
              "  'test_tup',\n",
              "  'tot',\n",
              "  'totalMarks',\n",
              "  '\\n\\n\\n    ',\n",
              "  '\\n        \\n    ',\n",
              "  \"'s\",\n",
              "  '..',\n",
              "  '2.0',\n",
              "  '78',\n",
              "  '900',\n",
              "  'Akshat',\n",
              "  'Date',\n",
              "  'Reverse',\n",
              "  'T',\n",
              "  'Yay',\n",
              "  'bigger',\n",
              "  'case',\n",
              "  'cp',\n",
              "  \"f'Area\",\n",
              "  'great',\n",
              "  'head',\n",
              "  'i%7',\n",
              "  'ini_string',\n",
              "  'intersection',\n",
              "  'key2',\n",
              "  'len_list',\n",
              "  'm1',\n",
              "  'm2',\n",
              "  'min_idx',\n",
              "  'must',\n",
              "  'negative',\n",
              "  'np',\n",
              "  'num_lines',\n",
              "  'path',\n",
              "  'prefix',\n",
              "  'rectangle',\n",
              "  'removing',\n",
              "  'said',\n",
              "  'start1',\n",
              "  'start2',\n",
              "  'stoogesort',\n",
              "  'student',\n",
              "  'temp_dict',\n",
              "  'timeit',\n",
              "  'tup1',\n",
              "  ' \\n\\n        ',\n",
              "  '  \\n                ',\n",
              "  '.upper',\n",
              "  '00',\n",
              "  '29',\n",
              "  '34',\n",
              "  '3x4',\n",
              "  'DIGITS',\n",
              "  'Emma',\n",
              "  'Good',\n",
              "  'O',\n",
              "  'Stack',\n",
              "  'Sum',\n",
              "  'TowerOfHanoi',\n",
              "  'Valid',\n",
              "  'Z',\n",
              "  'arr2',\n",
              "  'calc_fib',\n",
              "  'deque',\n",
              "  'dist',\n",
              "  'filepath',\n",
              "  'i%5',\n",
              "  'isPalindrome',\n",
              "  'lcm.multiple',\n",
              "  'loop',\n",
              "  'lowercase',\n",
              "  'match',\n",
              "  'output',\n",
              "  'principle',\n",
              "  'q1',\n",
              "  'q2',\n",
              "  'random.random',\n",
              "  'result.append',\n",
              "  'rowsA',\n",
              "  'same',\n",
              "  'summation',\n",
              "  'that',\n",
              "  'zero',\n",
              "  ' \\n \\n',\n",
              "  '1.8',\n",
              "  '300',\n",
              "  '99',\n",
              "  '@',\n",
              "  'Akash',\n",
              "  'American',\n",
              "  'India',\n",
              "  'Of',\n",
              "  'PM',\n",
              "  'Strings',\n",
              "  'Yes',\n",
              "  'amount',\n",
              "  'animals',\n",
              "  'astro_sign',\n",
              "  'attr',\n",
              "  'chain',\n",
              "  'compute_hcf',\n",
              "  'continue',\n",
              "  'copy',\n",
              "  'date_string',\n",
              "  'h1',\n",
              "  'json.loads',\n",
              "  'my_list2',\n",
              "  'my_string',\n",
              "  'nonlocal',\n",
              "  'player',\n",
              "  'punctuation',\n",
              "  'recur_fibo',\n",
              "  'surface_area',\n",
              "  'swap',\n",
              "  'test_str.split',\n",
              "  'test_tuple1',\n",
              "  'test_tuple2',\n",
              "  'three',\n",
              "  'tuple1',\n",
              "  'user',\n",
              "  '−',\n",
              "  '\\n             ',\n",
              "  '\\n               ',\n",
              "  \"'S\",\n",
              "  '0.1f',\n",
              "  '1.5',\n",
              "  '2a',\n",
              "  '500',\n",
              "  '80',\n",
              "  '89',\n",
              "  '999',\n",
              "  'After',\n",
              "  'Circle',\n",
              "  'Classes',\n",
              "  'IndexError',\n",
              "  'LETTERS',\n",
              "  'Lfirst',\n",
              "  'Lsecond',\n",
              "  'New',\n",
              "  'Order',\n",
              "  'Password',\n",
              "  'Remove',\n",
              "  'Rfirst',\n",
              "  'Rsecond',\n",
              "  'To',\n",
              "  'W',\n",
              "  'accelration',\n",
              "  'assert',\n",
              "  'avg',\n",
              "  'bisect_left',\n",
              "  'carry',\n",
              "  'chunkSize',\n",
              "  'cu_list',\n",
              "  'data_list',\n",
              "  'dateFormat',\n",
              "  'date_1',\n",
              "  'date_2',\n",
              "  'decimal_num',\n",
              "  'disk',\n",
              "  'div',\n",
              "  'dup_items',\n",
              "  'evenNumbers',\n",
              "  'exception',\n",
              "  'extracted',\n",
              "  'feet',\n",
              "  'first_array',\n",
              "  'guess2',\n",
              "  'here',\n",
              "  'holes',\n",
              "  'indexes',\n",
              "  'initial_velocity',\n",
              "  'inner_dict',\n",
              "  'input_num',\n",
              "  'islice',\n",
              "  'listOne',\n",
              "  'list_of_dicts',\n",
              "  'markList',\n",
              "  'mask',\n",
              "  'math.log',\n",
              "  'max_key',\n",
              "  'max_length',\n",
              "  'mid_idx',\n",
              "  'middleIndex',\n",
              "  'my_dict',\n",
              "  'my_inverted_dict',\n",
              "  'my_min',\n",
              "  'my_tup',\n",
              "  'n_list',\n",
              "  'new_min',\n",
              "  'objects',\n",
              "  'pressure',\n",
              "  'prev',\n",
              "  'printSubArrays',\n",
              "  'push',\n",
              "  'r2',\n",
              "  'remainder',\n",
              "  'remove',\n",
              "  'removeValue',\n",
              "  'revs_number',\n",
              "  'roll_again',\n",
              "  'rom_val',\n",
              "  'second_array',\n",
              "  'self.rear',\n",
              "  'self.size',\n",
              "  'ser',\n",
              "  'sin',\n",
              "  'sort_key',\n",
              "  'status',\n",
              "  'string1',\n",
              "  'studentJson',\n",
              "  'sumDigits',\n",
              "  'swapping',\n",
              "  'thisdict',\n",
              "  'time.perf_counter',\n",
              "  'tup2',\n",
              "  'tuplex',\n",
              "  'vowel',\n",
              "  '\\n    \\n',\n",
              "  ' \\n\\t\\t\\t',\n",
              "  '  \\n             ',\n",
              "  '0.2f',\n",
              "  '31',\n",
              "  '6.3',\n",
              "  '67',\n",
              "  '83',\n",
              "  'ASCII',\n",
              "  'Case',\n",
              "  'Celsius',\n",
              "  'END',\n",
              "  'English',\n",
              "  'Even',\n",
              "  'Filtered',\n",
              "  'Jon',\n",
              "  'Key',\n",
              "  'LCM',\n",
              "  'Maximum',\n",
              "  ...],\n",
              " 'stoi': defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fe17a1c85d0>>,\n",
              "             {'<unk>': 0,\n",
              "              '<pad>': 1,\n",
              "              '<sos>': 2,\n",
              "              '<eos>': 3,\n",
              "              ' ': 4,\n",
              "              '(': 5,\n",
              "              ')': 6,\n",
              "              ',': 7,\n",
              "              '=': 8,\n",
              "              ':': 9,\n",
              "              '\"': 10,\n",
              "              \"'\": 11,\n",
              "              '[': 12,\n",
              "              ']': 13,\n",
              "              '\\n': 14,\n",
              "              '  ': 15,\n",
              "              '\\n    ': 16,\n",
              "              'print': 17,\n",
              "              '1': 18,\n",
              "              'i': 19,\n",
              "              'in': 20,\n",
              "              '\\n        ': 21,\n",
              "              '0': 22,\n",
              "              '+': 23,\n",
              "              'def': 24,\n",
              "              'return': 25,\n",
              "              'for': 26,\n",
              "              '-': 27,\n",
              "              '*': 28,\n",
              "              'if': 29,\n",
              "              '2': 30,\n",
              "              'n': 31,\n",
              "              'a': 32,\n",
              "              'x': 33,\n",
              "              '{': 34,\n",
              "              '}': 35,\n",
              "              'is': 36,\n",
              "              '\\n\\n': 37,\n",
              "              '3': 38,\n",
              "              '/': 39,\n",
              "              'range': 40,\n",
              "              '\\n            ': 41,\n",
              "              'len': 42,\n",
              "              'num': 43,\n",
              "              '5': 44,\n",
              "              'else': 45,\n",
              "              '_': 46,\n",
              "              '4': 47,\n",
              "              '>': 48,\n",
              "              'j': 49,\n",
              "              'list': 50,\n",
              "              '%': 51,\n",
              "              '#': 52,\n",
              "              'import': 53,\n",
              "              'b': 54,\n",
              "              'str': 55,\n",
              "              'res': 56,\n",
              "              '<': 57,\n",
              "              ' \\n': 58,\n",
              "              '\\n   ': 59,\n",
              "              's': 60,\n",
              "              '10': 61,\n",
              "              'y': 62,\n",
              "              'the': 63,\n",
              "              'of': 64,\n",
              "              '6': 65,\n",
              "              ' \\n    ': 66,\n",
              "              'key': 67,\n",
              "              'float': 68,\n",
              "              'int': 69,\n",
              "              'The': 70,\n",
              "              'and': 71,\n",
              "              'str1': 72,\n",
              "              '\\n  ': 73,\n",
              "              'input': 74,\n",
              "              '.': 75,\n",
              "              '7': 76,\n",
              "              'string': 77,\n",
              "              '!': 78,\n",
              "              'd': 79,\n",
              "              'number': 80,\n",
              "              'result': 81,\n",
              "              '8': 82,\n",
              "              'alist': 83,\n",
              "              ' \\n        ': 84,\n",
              "              'sum': 85,\n",
              "              'count': 86,\n",
              "              'c': 87,\n",
              "              'while': 88,\n",
              "              'r': 89,\n",
              "              'test_list': 90,\n",
              "              'k': 91,\n",
              "              'arr': 92,\n",
              "              'not': 93,\n",
              "              'l': 94,\n",
              "              '9': 95,\n",
              "              '\\n\\n    ': 96,\n",
              "              'list1': 97,\n",
              "              'end': 98,\n",
              "              'from': 99,\n",
              "              'self': 100,\n",
              "              'to': 101,\n",
              "              'True': 102,\n",
              "              'num1': 103,\n",
              "              'word': 104,\n",
              "              'elif': 105,\n",
              "              'num2': 106,\n",
              "              '\\n       ': 107,\n",
              "              'ele': 108,\n",
              "              'value': 109,\n",
              "              'temp': 110,\n",
              "              'f': 111,\n",
              "              '\\n                ': 112,\n",
              "              ' \\n  \\n': 113,\n",
              "              ';': 114,\n",
              "              '12': 115,\n",
              "              '\\n\\t': 116,\n",
              "              'Enter': 117,\n",
              "              'original': 118,\n",
              "              '\\n      ': 119,\n",
              "              'li': 120,\n",
              "              'False': 121,\n",
              "              \"''\": 122,\n",
              "              'set': 123,\n",
              "              'lambda': 124,\n",
              "              'idx': 125,\n",
              "              '20': 126,\n",
              "              ' \\n\\n': 127,\n",
              "              'or': 128,\n",
              "              'A': 129,\n",
              "              'N': 130,\n",
              "              'start': 131,\n",
              "              '100': 132,\n",
              "              'class': 133,\n",
              "              'index': 134,\n",
              "              'lst': 135,\n",
              "              'char': 136,\n",
              "              'val': 137,\n",
              "              '.join': 138,\n",
              "              'words': 139,\n",
              "              'sub': 140,\n",
              "              'year': 141,\n",
              "              '\\n\\n\\n': 142,\n",
              "              ' \\n            ': 143,\n",
              "              'break': 144,\n",
              "              't': 145,\n",
              "              'name': 146,\n",
              "              'None': 147,\n",
              "              'length': 148,\n",
              "              '\\n     ': 149,\n",
              "              'numbers': 150,\n",
              "              'random': 151,\n",
              "              'mid': 152,\n",
              "              'radius': 153,\n",
              "              'nums': 154,\n",
              "              'sorted': 155,\n",
              "              'are': 156,\n",
              "              'tuple': 157,\n",
              "              'data': 158,\n",
              "              '?': 159,\n",
              "              'item': 160,\n",
              "              '11': 161,\n",
              "              'datetime': 162,\n",
              "              'p': 163,\n",
              "              'K': 164,\n",
              "              'as': 165,\n",
              "              'with': 166,\n",
              "              'X': 167,\n",
              "              'dict': 168,\n",
              "              'm': 169,\n",
              "              'h': 170,\n",
              "              'dictionary': 171,\n",
              "              'list2': 172,\n",
              "              '\\n  \\n': 173,\n",
              "              'zip': 174,\n",
              "              's1': 175,\n",
              "              'max': 176,\n",
              "              'pi': 177,\n",
              "              'test_dict': 178,\n",
              "              'l1': 179,\n",
              "              'height': 180,\n",
              "              'Y': 181,\n",
              "              'function': 182,\n",
              "              'greater': 183,\n",
              "              'math': 184,\n",
              "              'after': 185,\n",
              "              '\\n \\n    ': 186,\n",
              "              'check': 187,\n",
              "              'my_list': 188,\n",
              "              'element': 189,\n",
              "              'map': 190,\n",
              "              'test_str': 191,\n",
              "              'z': 192,\n",
              "              'base': 193,\n",
              "              'init': 194,\n",
              "              'largest': 195,\n",
              "              'Hello': 196,\n",
              "              '\\n           ': 197,\n",
              "              '&': 198,\n",
              "              'best': 199,\n",
              "              'printing': 200,\n",
              "              'l2': 201,\n",
              "              'size': 202,\n",
              "              '\\\\': 203,\n",
              "              'args': 204,\n",
              "              'letter': 205,\n",
              "              'mm': 206,\n",
              "              'time': 207,\n",
              "              'left': 208,\n",
              "              '\\n         ': 209,\n",
              "              'first': 210,\n",
              "              'values': 211,\n",
              "              'tup': 212,\n",
              "              'B': 213,\n",
              "              'open': 214,\n",
              "              'two': 215,\n",
              "              'Number': 216,\n",
              "              'e': 217,\n",
              "              'sentence': 218,\n",
              "              '15': 219,\n",
              "              '50': 220,\n",
              "              '...': 221,\n",
              "              'right': 222,\n",
              "              '30': 223,\n",
              "              'C': 224,\n",
              "              'raise': 225,\n",
              "              '  \\n': 226,\n",
              "              'v': 227,\n",
              "              'an': 228,\n",
              "              'factorial': 229,\n",
              "              'isinstance': 230,\n",
              "              'total': 231,\n",
              "              '\\n ': 232,\n",
              "              '.format': 233,\n",
              "              'upper': 234,\n",
              "              '\\n\\n        ': 235,\n",
              "              'min': 236,\n",
              "              '45': 237,\n",
              "              'iterable': 238,\n",
              "              'lower': 239,\n",
              "              'row': 240,\n",
              "              '60': 241,\n",
              "              'reverse': 242,\n",
              "              '\\n\\t\\t': 243,\n",
              "              'area': 244,\n",
              "              'line': 245,\n",
              "              'ord': 246,\n",
              "              'found': 247,\n",
              "              'python': 248,\n",
              "              'text': 249,\n",
              "              'lcm': 250,\n",
              "              '\\n \\n': 251,\n",
              "              'String': 252,\n",
              "              's2': 253,\n",
              "              'sum1': 254,\n",
              "              '  \\n    ': 255,\n",
              "              'digit': 256,\n",
              "              'filter': 257,\n",
              "              'vowels': 258,\n",
              "              '\\n          ': 259,\n",
              "              'itertools': 260,\n",
              "              '|': 261,\n",
              "              '24': 262,\n",
              "              're': 263,\n",
              "              '40': 264,\n",
              "              'all': 265,\n",
              "              'this': 266,\n",
              "              '3.14': 267,\n",
              "              'side': 268,\n",
              "              'write': 269,\n",
              "              '16': 270,\n",
              "              'Gfg': 271,\n",
              "              'List': 272,\n",
              "              'fname': 273,\n",
              "              'num_list': 274,\n",
              "              'ValueError': 275,\n",
              "              '-=': 276,\n",
              "              'all_freq': 277,\n",
              "              'it': 278,\n",
              "              ' \\n      \\n    ': 279,\n",
              "              'by': 280,\n",
              "              'leap': 281,\n",
              "              'pass': 282,\n",
              "              'u': 283,\n",
              "              '21': 284,\n",
              "              'Input': 285,\n",
              "              'n1': 286,\n",
              "              'num3': 287,\n",
              "              'angle': 288,\n",
              "              'enumerate': 289,\n",
              "              'n2': 290,\n",
              "              'prime': 291,\n",
              "              'type': 292,\n",
              "              'yield': 293,\n",
              "              '25': 294,\n",
              "              'final': 295,\n",
              "              'E': 296,\n",
              "              'gfg': 297,\n",
              "              ' \\n             ': 298,\n",
              "              'I': 299,\n",
              "              'items': 300,\n",
              "              'my_str': 301,\n",
              "              '\\n    \\n    ': 302,\n",
              "              'flag': 303,\n",
              "              'object': 304,\n",
              "              'test_list1': 305,\n",
              "              ' \\n  \\n    ': 306,\n",
              "              '23': 307,\n",
              "              'This': 308,\n",
              "              'elements': 309,\n",
              "              'file': 310,\n",
              "              'pos': 311,\n",
              "              'res.append': 312,\n",
              "              'smaller': 313,\n",
              "              'str2': 314,\n",
              "              'terms': 315,\n",
              "              'volume': 316,\n",
              "              '22': 317,\n",
              "              'sorted_list': 318,\n",
              "              '\\n\\n   ': 319,\n",
              "              '\\n \\n \\n': 320,\n",
              "              'fact': 321,\n",
              "              'you': 322,\n",
              "              'Geeks': 323,\n",
              "              'Please': 324,\n",
              "              'array': 325,\n",
              "              'no_punct': 326,\n",
              "              'product': 327,\n",
              "              ' \\n\\n    ': 328,\n",
              "              '    \\n    ': 329,\n",
              "              'World': 330,\n",
              "              '\\\\n': 331,\n",
              "              'age': 332,\n",
              "              'g': 333,\n",
              "              'geeks': 334,\n",
              "              'letters': 335,\n",
              "              'newList': 336,\n",
              "              'power': 337,\n",
              "              '  \\n   ': 338,\n",
              "              '   \\n    ': 339,\n",
              "              '0.5': 340,\n",
              "              'M': 341,\n",
              "              'dd': 342,\n",
              "              'exp': 343,\n",
              "              'x1': 344,\n",
              "              'Sorted': 345,\n",
              "              'keys': 346,\n",
              "              'myList': 347,\n",
              "              'next': 348,\n",
              "              'rows': 349,\n",
              "              'set1': 350,\n",
              "              'w': 351,\n",
              "              '\\n      \\n    ': 352,\n",
              "              '18': 353,\n",
              "              'P': 354,\n",
              "              'bin': 355,\n",
              "              'day': 356,\n",
              "              'dec': 357,\n",
              "              'digitCount': 358,\n",
              "              'except': 359,\n",
              "              'matrix': 360,\n",
              "              'test_list2': 361,\n",
              "              '13': 362,\n",
              "              '17': 363,\n",
              "              '2020': 364,\n",
              "              '32': 365,\n",
              "              'fn': 366,\n",
              "              'kwargs': 367,\n",
              "              'source': 368,\n",
              "              'times': 369,\n",
              "              'date': 370,\n",
              "              'iterate': 371,\n",
              "              '.append': 372,\n",
              "              '.split': 373,\n",
              "              '^\\\\s': 374,\n",
              "              'do': 375,\n",
              "              'mass': 376,\n",
              "              'no': 377,\n",
              "              'o': 378,\n",
              "              'rev': 379,\n",
              "              'url': 380,\n",
              "              '   ': 381,\n",
              "              'D': 382,\n",
              "              'Fibonacci': 383,\n",
              "              'characters': 384,\n",
              "              'good': 385,\n",
              "              'hcf': 386,\n",
              "              'initializing': 387,\n",
              "              'raw_input': 388,\n",
              "              'try': 389,\n",
              "              'tsai': 390,\n",
              "              'x2': 391,\n",
              "              'No': 392,\n",
              "              '^': 393,\n",
              "              'at': 394,\n",
              "              'enter': 395,\n",
              "              'even': 396,\n",
              "              'reversed': 397,\n",
              "              'tuples': 398,\n",
              "              'Invalid': 399,\n",
              "              'be': 400,\n",
              "              'between': 401,\n",
              "              'difference': 402,\n",
              "              'given': 403,\n",
              "              'hello': 404,\n",
              "              'input_array': 405,\n",
              "              'last': 406,\n",
              "              'list_to_be_sorted': 407,\n",
              "              'present': 408,\n",
              "              'your': 409,\n",
              "              '\\n                    ': 410,\n",
              "              '  \\n       ': 411,\n",
              "              '35': 412,\n",
              "              '70': 413,\n",
              "              'It': 414,\n",
              "              'filename': 415,\n",
              "              'inner': 416,\n",
              "              'q': 417,\n",
              "              'regex': 418,\n",
              "              'round': 419,\n",
              "              '  \\n        ': 420,\n",
              "              '54': 421,\n",
              "              'ctr': 422,\n",
              "              'dict1': 423,\n",
              "              'mylist': 424,\n",
              "              'palindrome': 425,\n",
              "              'punctuations': 426,\n",
              "              'set2': 427,\n",
              "              ' \\n  ': 428,\n",
              "              ' \\n       ': 429,\n",
              "              '   \\n': 430,\n",
              "              '200': 431,\n",
              "              'any': 432,\n",
              "              'character': 433,\n",
              "              'digits': 434,\n",
              "              'nterms': 435,\n",
              "              'test_dict.items': 436,\n",
              "              ' \\n                ': 437,\n",
              "              '  \\n  \\n': 438,\n",
              "              '14': 439,\n",
              "              '2000': 440,\n",
              "              '44': 441,\n",
              "              'collections': 442,\n",
              "              'dict2': 443,\n",
              "              'distance': 444,\n",
              "              'empty': 445,\n",
              "              'input_list': 446,\n",
              "              'lists': 447,\n",
              "              'reduce': 448,\n",
              "              'through': 449,\n",
              "              'unique': 450,\n",
              "              'width': 451,\n",
              "              '\\n  \\n    ': 452,\n",
              "              ' \\n              ': 453,\n",
              "              '1000': 454,\n",
              "              '88': 455,\n",
              "              'L': 456,\n",
              "              'celsius': 457,\n",
              "              'code': 458,\n",
              "              'destination': 459,\n",
              "              'gap': 460,\n",
              "              'kilometers': 461,\n",
              "              'maximum': 462,\n",
              "              'operation': 463,\n",
              "              'os': 464,\n",
              "              'password': 465,\n",
              "              'year\".format': 466,\n",
              "              '~': 467,\n",
              "              'Dict': 468,\n",
              "              'choice': 469,\n",
              "              'i%2': 470,\n",
              "              'integer': 471,\n",
              "              'json': 472,\n",
              "              'limit': 473,\n",
              "              'low': 474,\n",
              "              'sampleList': 475,\n",
              "              'second': 476,\n",
              "              'src_dir_path': 477,\n",
              "              'str1.split': 478,\n",
              "              'target': 479,\n",
              "              'timedelta': 480,\n",
              "              '/=': 481,\n",
              "              'Original': 482,\n",
              "              'R': 483,\n",
              "              'binary': 484,\n",
              "              'foo': 485,\n",
              "              'no_swap': 486,\n",
              "              'nth': 487,\n",
              "              'one': 488,\n",
              "              'rate': 489,\n",
              "              'sign': 490,\n",
              "              'st': 491,\n",
              "              'sub_str': 492,\n",
              "              'theta': 493,\n",
              "              'top': 494,\n",
              "              \"'d\": 495,\n",
              "              'Counter': 496,\n",
              "              'a_list': 497,\n",
              "              'chr': 498,\n",
              "              'func': 499,\n",
              "              'gcd': 500,\n",
              "              'global': 501,\n",
              "              'hh': 502,\n",
              "              'marks': 503,\n",
              "              'order': 504,\n",
              "              'position': 505,\n",
              "              'var': 506,\n",
              "              'world': 507,\n",
              "              '\\n\\t    ': 508,\n",
              "              ' \\n   ': 509,\n",
              "              '19': 510,\n",
              "              '400': 511,\n",
              "              '65': 512,\n",
              "              'Best': 513,\n",
              "              'abs': 514,\n",
              "              'countDict': 515,\n",
              "              'equal': 516,\n",
              "              'f\"The': 517,\n",
              "              'input_dict': 518,\n",
              "              'ip_str': 519,\n",
              "              'month': 520,\n",
              "              'new': 521,\n",
              "              'new_str': 522,\n",
              "              'odd': 523,\n",
              "              'org_intervals': 524,\n",
              "              'pool': 525,\n",
              "              'random.choice': 526,\n",
              "              'random.sample': 527,\n",
              "              'repeat': 528,\n",
              "              'returns': 529,\n",
              "              'vow_list': 530,\n",
              "              '\\n \\n ': 531,\n",
              "              'Not': 532,\n",
              "              'apple': 533,\n",
              "              'col': 534,\n",
              "              'factors': 535,\n",
              "              'find': 536,\n",
              "              'given_date': 537,\n",
              "              'high': 538,\n",
              "              'main': 539,\n",
              "              'math.sqrt': 540,\n",
              "              'move': 541,\n",
              "              'node': 542,\n",
              "              'obj': 543,\n",
              "              'percentage': 544,\n",
              "              'self.length': 545,\n",
              "              'seq': 546,\n",
              "              'sequence': 547,\n",
              "              'smallest': 548,\n",
              "              'substring': 549,\n",
              "              '\\n\\n  ': 550,\n",
              "              '  \\n            ': 551,\n",
              "              '120': 552,\n",
              "              'Python': 553,\n",
              "              'aeiou': 554,\n",
              "              'breadth': 555,\n",
              "              'days': 556,\n",
              "              'does': 557,\n",
              "              'each': 558,\n",
              "              'email': 559,\n",
              "              'exist': 560,\n",
              "              'iterator': 561,\n",
              "              'positive': 562,\n",
              "              'pow': 563,\n",
              "              'random.randint': 564,\n",
              "              'res_list': 565,\n",
              "              'sentence.split': 566,\n",
              "              't1': 567,\n",
              "              'will': 568,\n",
              "              ' \\n     ': 569,\n",
              "              '.lower': 570,\n",
              "              '0.0': 571,\n",
              "              '26': 572,\n",
              "              'Area': 573,\n",
              "              'columns': 574,\n",
              "              'curr': 575,\n",
              "              'del': 576,\n",
              "              'dig': 577,\n",
              "              'eval': 578,\n",
              "              'fahrenheit': 579,\n",
              "              'how': 580,\n",
              "              'key1': 581,\n",
              "              'max1': 582,\n",
              "              'mean': 583,\n",
              "              'multiply': 584,\n",
              "              'names': 585,\n",
              "              'org': 586,\n",
              "              're.findall': 587,\n",
              "              'sp': 588,\n",
              "              'than': 589,\n",
              "              'y1': 590,\n",
              "              'y2': 591,\n",
              "              ' \\n      \\n': 592,\n",
              "              '  \\n  \\n    ': 593,\n",
              "              '155': 594,\n",
              "              'Armstrong': 595,\n",
              "              'Value': 596,\n",
              "              'add': 597,\n",
              "              'bool': 598,\n",
              "              'bottom': 599,\n",
              "              'd.items': 600,\n",
              "              'd2': 601,\n",
              "              'fib': 602,\n",
              "              'flatten': 603,\n",
              "              'get': 604,\n",
              "              'groupby': 605,\n",
              "              'have': 606,\n",
              "              'ip': 607,\n",
              "              'its': 608,\n",
              "              'line.split': 609,\n",
              "              'miles': 610,\n",
              "              'new_list': 611,\n",
              "              'now': 612,\n",
              "              'program': 613,\n",
              "              'queue': 614,\n",
              "              'quick': 615,\n",
              "              'script': 616,\n",
              "              'self.list': 617,\n",
              "              'self.radius': 618,\n",
              "              'sine': 619,\n",
              "              'square': 620,\n",
              "              'steps': 621,\n",
              "              't2': 622,\n",
              "              'time.upper': 623,\n",
              "              'using': 624,\n",
              "              'word_list': 625,\n",
              "              'yy': 626,\n",
              "              '\\n          \\n    ': 627,\n",
              "              ' \\n         ': 628,\n",
              "              ' \\n          ': 629,\n",
              "              '180': 630,\n",
              "              'Dictionary': 631,\n",
              "              'F': 632,\n",
              "              'Person': 633,\n",
              "              'S': 634,\n",
              "              '\\\\w': 635,\n",
              "              'ans': 636,\n",
              "              'dt': 637,\n",
              "              'frequency': 638,\n",
              "              'guess': 639,\n",
              "              'lines': 640,\n",
              "              'lis': 641,\n",
              "              'my': 642,\n",
              "              \"n't\": 643,\n",
              "              'pair': 644,\n",
              "              're.search': 645,\n",
              "              'self.cache': 646,\n",
              "              'side_length': 647,\n",
              "              'speed': 648,\n",
              "              'str_list': 649,\n",
              "              'test_tup1': 650,\n",
              "              'triangle': 651,\n",
              "              'was': 652,\n",
              "              '\\n\\n\\t': 653,\n",
              "              '$': 654,\n",
              "              '55': 655,\n",
              "              '66': 656,\n",
              "              '@#$%^': 657,\n",
              "              'CS': 658,\n",
              "              'Is': 659,\n",
              "              'JSON': 660,\n",
              "              'PI': 661,\n",
              "              'Total': 662,\n",
              "              'aList': 663,\n",
              "              'arr1': 664,\n",
              "              'auxiliary': 665,\n",
              "              'banana': 666,\n",
              "              'brown': 667,\n",
              "              'f\"String': 668,\n",
              "              'files_in_dir': 669,\n",
              "              'fox': 670,\n",
              "              'inner_list': 671,\n",
              "              'interest': 672,\n",
              "              'list_of_nums': 673,\n",
              "              'math.pi': 674,\n",
              "              'math.sin': 675,\n",
              "              'minimum': 676,\n",
              "              'msg': 677,\n",
              "              'my_list1': 678,\n",
              "              'no_of_sides': 679,\n",
              "              'num_words': 680,\n",
              "              'numpy': 681,\n",
              "              'pd': 682,\n",
              "              'person_dict': 683,\n",
              "              'resList': 684,\n",
              "              'self.queue': 685,\n",
              "              'sep': 686,\n",
              "              'shuffle': 687,\n",
              "              'start_at': 688,\n",
              "              'sub_set': 689,\n",
              "              'sys': 690,\n",
              "              'test_tup2': 691,\n",
              "              'use': 692,\n",
              "              '\\n              ': 693,\n",
              "              ' \\n\\t': 694,\n",
              "              ' \\n\\t\\t': 695,\n",
              "              ' \\n  \\n\\n': 696,\n",
              "              '01': 697,\n",
              "              'Convert': 698,\n",
              "              'First': 699,\n",
              "              'Move': 700,\n",
              "              'bar': 701,\n",
              "              'cache': 702,\n",
              "              'ch': 703,\n",
              "              'compute_lcm': 704,\n",
              "              'd1': 705,\n",
              "              'diff': 706,\n",
              "              'functools': 707,\n",
              "              'into': 708,\n",
              "              'iter': 709,\n",
              "              'math.exp': 710,\n",
              "              'replace': 711,\n",
              "              'root': 712,\n",
              "              's.split': 713,\n",
              "              'self.head': 714,\n",
              "              'si': 715,\n",
              "              'space': 716,\n",
              "              'valid': 717,\n",
              "              'variable': 718,\n",
              "              'z0': 719,\n",
              "              '\\n\\t\\t\\t': 720,\n",
              "              '\\n\\n ': 721,\n",
              "              '\\n\\n            ': 722,\n",
              "              '  \\n           ': 723,\n",
              "              '   \\n        ': 724,\n",
              "              '90': 725,\n",
              "              '93': 726,\n",
              "              'AM': 727,\n",
              "              'CASE': 728,\n",
              "              'For': 729,\n",
              "              'H': 730,\n",
              "              'Kelly': 731,\n",
              "              'Nikhil': 732,\n",
              "              'Return': 733,\n",
              "              'You': 734,\n",
              "              'bisect': 735,\n",
              "              'bmi': 736,\n",
              "              'circumradius': 737,\n",
              "              'conv_fac': 738,\n",
              "              'conversion': 739,\n",
              "              'count.get': 740,\n",
              "              'current': 741,\n",
              "              'degree': 742,\n",
              "              'delta': 743,\n",
              "              'el': 744,\n",
              "              'has': 745,\n",
              "              'highestnumber': 746,\n",
              "              'https': 747,\n",
              "              'ini_tuple': 748,\n",
              "              'make': 749,\n",
              "              'math.cos': 750,\n",
              "              'math.floor': 751,\n",
              "              'maxnum': 752,\n",
              "              'minutes': 753,\n",
              "              'numberList': 754,\n",
              "              'perm': 755,\n",
              "              'pop': 756,\n",
              "              'radians': 757,\n",
              "              'ratio': 758,\n",
              "              'res_date': 759,\n",
              "              'result_perms': 760,\n",
              "              'seen': 761,\n",
              "              'self.items': 762,\n",
              "              'shift': 763,\n",
              "              'test_tup': 764,\n",
              "              'tot': 765,\n",
              "              'totalMarks': 766,\n",
              "              '\\n\\n\\n    ': 767,\n",
              "              '\\n        \\n    ': 768,\n",
              "              \"'s\": 769,\n",
              "              '..': 770,\n",
              "              '2.0': 771,\n",
              "              '78': 772,\n",
              "              '900': 773,\n",
              "              'Akshat': 774,\n",
              "              'Date': 775,\n",
              "              'Reverse': 776,\n",
              "              'T': 777,\n",
              "              'Yay': 778,\n",
              "              'bigger': 779,\n",
              "              'case': 780,\n",
              "              'cp': 781,\n",
              "              \"f'Area\": 782,\n",
              "              'great': 783,\n",
              "              'head': 784,\n",
              "              'i%7': 785,\n",
              "              'ini_string': 786,\n",
              "              'intersection': 787,\n",
              "              'key2': 788,\n",
              "              'len_list': 789,\n",
              "              'm1': 790,\n",
              "              'm2': 791,\n",
              "              'min_idx': 792,\n",
              "              'must': 793,\n",
              "              'negative': 794,\n",
              "              'np': 795,\n",
              "              'num_lines': 796,\n",
              "              'path': 797,\n",
              "              'prefix': 798,\n",
              "              'rectangle': 799,\n",
              "              'removing': 800,\n",
              "              'said': 801,\n",
              "              'start1': 802,\n",
              "              'start2': 803,\n",
              "              'stoogesort': 804,\n",
              "              'student': 805,\n",
              "              'temp_dict': 806,\n",
              "              'timeit': 807,\n",
              "              'tup1': 808,\n",
              "              ' \\n\\n        ': 809,\n",
              "              '  \\n                ': 810,\n",
              "              '.upper': 811,\n",
              "              '00': 812,\n",
              "              '29': 813,\n",
              "              '34': 814,\n",
              "              '3x4': 815,\n",
              "              'DIGITS': 816,\n",
              "              'Emma': 817,\n",
              "              'Good': 818,\n",
              "              'O': 819,\n",
              "              'Stack': 820,\n",
              "              'Sum': 821,\n",
              "              'TowerOfHanoi': 822,\n",
              "              'Valid': 823,\n",
              "              'Z': 824,\n",
              "              'arr2': 825,\n",
              "              'calc_fib': 826,\n",
              "              'deque': 827,\n",
              "              'dist': 828,\n",
              "              'filepath': 829,\n",
              "              'i%5': 830,\n",
              "              'isPalindrome': 831,\n",
              "              'lcm.multiple': 832,\n",
              "              'loop': 833,\n",
              "              'lowercase': 834,\n",
              "              'match': 835,\n",
              "              'output': 836,\n",
              "              'principle': 837,\n",
              "              'q1': 838,\n",
              "              'q2': 839,\n",
              "              'random.random': 840,\n",
              "              'result.append': 841,\n",
              "              'rowsA': 842,\n",
              "              'same': 843,\n",
              "              'summation': 844,\n",
              "              'that': 845,\n",
              "              'zero': 846,\n",
              "              ' \\n \\n': 847,\n",
              "              '1.8': 848,\n",
              "              '300': 849,\n",
              "              '99': 850,\n",
              "              '@': 851,\n",
              "              'Akash': 852,\n",
              "              'American': 853,\n",
              "              'India': 854,\n",
              "              'Of': 855,\n",
              "              'PM': 856,\n",
              "              'Strings': 857,\n",
              "              'Yes': 858,\n",
              "              'amount': 859,\n",
              "              'animals': 860,\n",
              "              'astro_sign': 861,\n",
              "              'attr': 862,\n",
              "              'chain': 863,\n",
              "              'compute_hcf': 864,\n",
              "              'continue': 865,\n",
              "              'copy': 866,\n",
              "              'date_string': 867,\n",
              "              'h1': 868,\n",
              "              'json.loads': 869,\n",
              "              'my_list2': 870,\n",
              "              'my_string': 871,\n",
              "              'nonlocal': 872,\n",
              "              'player': 873,\n",
              "              'punctuation': 874,\n",
              "              'recur_fibo': 875,\n",
              "              'surface_area': 876,\n",
              "              'swap': 877,\n",
              "              'test_str.split': 878,\n",
              "              'test_tuple1': 879,\n",
              "              'test_tuple2': 880,\n",
              "              'three': 881,\n",
              "              'tuple1': 882,\n",
              "              'user': 883,\n",
              "              '−': 884,\n",
              "              '\\n             ': 885,\n",
              "              '\\n               ': 886,\n",
              "              \"'S\": 887,\n",
              "              '0.1f': 888,\n",
              "              '1.5': 889,\n",
              "              '2a': 890,\n",
              "              '500': 891,\n",
              "              '80': 892,\n",
              "              '89': 893,\n",
              "              '999': 894,\n",
              "              'After': 895,\n",
              "              'Circle': 896,\n",
              "              'Classes': 897,\n",
              "              'IndexError': 898,\n",
              "              'LETTERS': 899,\n",
              "              'Lfirst': 900,\n",
              "              'Lsecond': 901,\n",
              "              'New': 902,\n",
              "              'Order': 903,\n",
              "              'Password': 904,\n",
              "              'Remove': 905,\n",
              "              'Rfirst': 906,\n",
              "              'Rsecond': 907,\n",
              "              'To': 908,\n",
              "              'W': 909,\n",
              "              'accelration': 910,\n",
              "              'assert': 911,\n",
              "              'avg': 912,\n",
              "              'bisect_left': 913,\n",
              "              'carry': 914,\n",
              "              'chunkSize': 915,\n",
              "              'cu_list': 916,\n",
              "              'data_list': 917,\n",
              "              'dateFormat': 918,\n",
              "              'date_1': 919,\n",
              "              'date_2': 920,\n",
              "              'decimal_num': 921,\n",
              "              'disk': 922,\n",
              "              'div': 923,\n",
              "              'dup_items': 924,\n",
              "              'evenNumbers': 925,\n",
              "              'exception': 926,\n",
              "              'extracted': 927,\n",
              "              'feet': 928,\n",
              "              'first_array': 929,\n",
              "              'guess2': 930,\n",
              "              'here': 931,\n",
              "              'holes': 932,\n",
              "              'indexes': 933,\n",
              "              'initial_velocity': 934,\n",
              "              'inner_dict': 935,\n",
              "              'input_num': 936,\n",
              "              'islice': 937,\n",
              "              'listOne': 938,\n",
              "              'list_of_dicts': 939,\n",
              "              'markList': 940,\n",
              "              'mask': 941,\n",
              "              'math.log': 942,\n",
              "              'max_key': 943,\n",
              "              'max_length': 944,\n",
              "              'mid_idx': 945,\n",
              "              'middleIndex': 946,\n",
              "              'my_dict': 947,\n",
              "              'my_inverted_dict': 948,\n",
              "              'my_min': 949,\n",
              "              'my_tup': 950,\n",
              "              'n_list': 951,\n",
              "              'new_min': 952,\n",
              "              'objects': 953,\n",
              "              'pressure': 954,\n",
              "              'prev': 955,\n",
              "              'printSubArrays': 956,\n",
              "              'push': 957,\n",
              "              'r2': 958,\n",
              "              'remainder': 959,\n",
              "              'remove': 960,\n",
              "              'removeValue': 961,\n",
              "              'revs_number': 962,\n",
              "              'roll_again': 963,\n",
              "              'rom_val': 964,\n",
              "              'second_array': 965,\n",
              "              'self.rear': 966,\n",
              "              'self.size': 967,\n",
              "              'ser': 968,\n",
              "              'sin': 969,\n",
              "              'sort_key': 970,\n",
              "              'status': 971,\n",
              "              'string1': 972,\n",
              "              'studentJson': 973,\n",
              "              'sumDigits': 974,\n",
              "              'swapping': 975,\n",
              "              'thisdict': 976,\n",
              "              'time.perf_counter': 977,\n",
              "              'tup2': 978,\n",
              "              'tuplex': 979,\n",
              "              'vowel': 980,\n",
              "              '\\n    \\n': 981,\n",
              "              ' \\n\\t\\t\\t': 982,\n",
              "              '  \\n             ': 983,\n",
              "              '0.2f': 984,\n",
              "              '31': 985,\n",
              "              '6.3': 986,\n",
              "              '67': 987,\n",
              "              '83': 988,\n",
              "              'ASCII': 989,\n",
              "              'Case': 990,\n",
              "              'Celsius': 991,\n",
              "              'END': 992,\n",
              "              'English': 993,\n",
              "              'Even': 994,\n",
              "              'Filtered': 995,\n",
              "              'Jon': 996,\n",
              "              'Key': 997,\n",
              "              'LCM': 998,\n",
              "              'Maximum': 999,\n",
              "              ...}),\n",
              " 'unk_index': 0,\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI5CfaO-9TLQ"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "#device = 'cpu'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k21kKd69aNY",
        "outputId": "b35525ce-8658-4346-bbde-44f1386eec3f"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "     (train, valid, test), \r\n",
        "     batch_size = BATCH_SIZE,\r\n",
        "     sort_key=lambda x : len(x.src),\r\n",
        "     sort_within_batch=False,\r\n",
        "     device = device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7nCNjlx-P2S"
      },
      "source": [
        "# Create Model\r\n",
        "___________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfzQspK-FEZ"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 input_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,\r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = MAX_SEQ_LEN):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim,\r\n",
        "                                                  dropout, \r\n",
        "                                                  device) \r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        batch_size = src.shape[0]\r\n",
        "        src_len = src.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "        \r\n",
        "        #pos = [batch size, src len]\r\n",
        "        \r\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            src = layer(src, src_mask)\r\n",
        "            \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "            \r\n",
        "        return src\r\n",
        "\r\n",
        "\r\n",
        "class EncoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,  \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        #src_mask = [batch size, 1, 1, src len] \r\n",
        "                \r\n",
        "        #self attention\r\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _src = self.positionwise_feedforward(src)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        return src\r\n",
        "\r\n",
        "\r\n",
        "class MultiHeadAttentionLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert hid_dim % n_heads == 0\r\n",
        "        \r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_heads = n_heads\r\n",
        "        self.head_dim = hid_dim // n_heads\r\n",
        "        \r\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, query, key, value, mask = None):\r\n",
        "        \r\n",
        "        batch_size = query.shape[0]\r\n",
        "        \r\n",
        "        #query = [batch size, query len, hid dim]\r\n",
        "        #key = [batch size, key len, hid dim]\r\n",
        "        #value = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = self.fc_q(query)\r\n",
        "        K = self.fc_k(key)\r\n",
        "        V = self.fc_v(value)\r\n",
        "        \r\n",
        "        #Q = [batch size, query len, hid dim]\r\n",
        "        #K = [batch size, key len, hid dim]\r\n",
        "        #V = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        \r\n",
        "        #Q = [batch size, n heads, query len, head dim]\r\n",
        "        #K = [batch size, n heads, key len, head dim]\r\n",
        "        #V = [batch size, n heads, value len, head dim]\r\n",
        "                \r\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\r\n",
        "        \r\n",
        "        #energy = [batch size, n heads, query len, key len]\r\n",
        "        \r\n",
        "        if mask is not None:\r\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\r\n",
        "        \r\n",
        "        attention = torch.softmax(energy, dim = -1)\r\n",
        "                \r\n",
        "        #attention = [batch size, n heads, query len, key len]\r\n",
        "                \r\n",
        "        x = torch.matmul(self.dropout(attention), V)\r\n",
        "        \r\n",
        "        #x = [batch size, n heads, query len, head dim]\r\n",
        "        \r\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\r\n",
        "        \r\n",
        "        #x = [batch size, query len, n heads, head dim]\r\n",
        "        \r\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        x = self.fc_o(x)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        return x, attention\r\n",
        "\r\n",
        "\r\n",
        "class PositionwiseFeedforwardLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\r\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, pf dim]\r\n",
        "        \r\n",
        "        x = self.fc_2(x)\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 output_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = MAX_SEQ_LEN):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim, \r\n",
        "                                                  dropout, \r\n",
        "                                                  device)\r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "                \r\n",
        "        batch_size = trg.shape[0]\r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "                            \r\n",
        "        #pos = [batch size, trg len]\r\n",
        "            \r\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\r\n",
        "                \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        output = self.fc_out(trg)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "            \r\n",
        "        return output, attention\r\n",
        "\r\n",
        "\r\n",
        "class DecoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        #self attention\r\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "            \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "            \r\n",
        "        #encoder attention\r\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\r\n",
        "        # query, key, value\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "                    \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _trg = self.positionwise_feedforward(trg)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return trg, attention\r\n",
        "\r\n",
        "\r\n",
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 encoder, \r\n",
        "                 decoder, \r\n",
        "                 src_pad_idx, \r\n",
        "                 trg_pad_idx, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.src_pad_idx = src_pad_idx\r\n",
        "        self.trg_pad_idx = trg_pad_idx\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def make_src_mask(self, src):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        \r\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "\r\n",
        "        return src_mask\r\n",
        "    \r\n",
        "    def make_trg_mask(self, trg):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        \r\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "        \r\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
        "        \r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\r\n",
        "        \r\n",
        "        #trg_sub_mask = [trg len, trg len]\r\n",
        "            \r\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
        "        \r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        return trg_mask\r\n",
        "\r\n",
        "    def forward(self, src, trg):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "                \r\n",
        "        src_mask = self.make_src_mask(src)\r\n",
        "        trg_mask = self.make_trg_mask(trg)\r\n",
        "        \r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        enc_src = self.encoder(src, src_mask)\r\n",
        "        \r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "                \r\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return output, attention"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wk8MssTQzNO",
        "outputId": "5ffec2e2-8773-4093-db9c-8e4b04d02e64"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1603, 5125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju30y3V0-RmY"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "HID_DIM = 512\r\n",
        "ENC_LAYERS = 3\r\n",
        "DEC_LAYERS = 3\r\n",
        "ENC_HEADS = 8\r\n",
        "DEC_HEADS = 8\r\n",
        "ENC_PF_DIM = 1024\r\n",
        "DEC_PF_DIM = 1024\r\n",
        "ENC_DROPOUT = 0.2\r\n",
        "DEC_DROPOUT = 0.2\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              ENC_LAYERS, \r\n",
        "              ENC_HEADS, \r\n",
        "              ENC_PF_DIM, \r\n",
        "              ENC_DROPOUT, \r\n",
        "              device)\r\n",
        "\r\n",
        "dec = Decoder(OUTPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              DEC_LAYERS, \r\n",
        "              DEC_HEADS, \r\n",
        "              DEC_PF_DIM, \r\n",
        "              DEC_DROPOUT, \r\n",
        "              device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJLaOXoY-YPA"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\r\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naDIiOcqY6g2",
        "outputId": "ea1b9258-f988-420f-f527-9b38ac0ac46d"
      },
      "source": [
        "model"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(1603, 256)\n",
              "    (pos_embedding): Embedding(256, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(5125, 256)\n",
              "    (pos_embedding): Embedding(256, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=5125, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RzAayA_-icQ",
        "outputId": "9b90309f-745d-42ef-f891-643486e4ae7b"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 7,124,229 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmZchBou-pOg"
      },
      "source": [
        "def initialize_weights(m):\r\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\r\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf_t_OWi-rHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d534191-55e2-401a-991e-fbaaa11c35d6"
      },
      "source": [
        "model.apply(initialize_weights)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(1603, 256)\n",
              "    (pos_embedding): Embedding(256, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(5125, 256)\n",
              "    (pos_embedding): Embedding(256, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=5125, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-nO9pWN-0ko"
      },
      "source": [
        "LEARNING_RATE = 0.0005\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBVNuTnG-2aQ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxivJepz-57A"
      },
      "source": [
        "\r\n",
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "\r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "\r\n",
        "    errors = 1\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "\r\n",
        "        src = batch.src\r\n",
        "        trg = batch.trg\r\n",
        "        #print(trg.shape)\r\n",
        "        seq_len = trg.shape[1] -1 \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output, _ = model(src, trg[:,:-1])\r\n",
        "                \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "        output = output.contiguous().view(-1, output_dim)\r\n",
        "        trg = trg[:,1:].contiguous().view(-1)\r\n",
        "                \r\n",
        "        #output = [batch size * trg len - 1, output dim]\r\n",
        "        #trg = [batch size * trg len - 1]\r\n",
        "        #print(output.shape,trg.shape)    \r\n",
        "        loss = criterion(output, trg)\r\n",
        "\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "      \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "\r\n",
        "        epoch_loss += loss.item()/ seq_len\r\n",
        "\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        errors += 1\r\n",
        "\r\n",
        "          \r\n",
        "        \r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)\r\n",
        "\r\n",
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.src\r\n",
        "            trg = batch.trg\r\n",
        "            seq_len = trg.shape[1] -1\r\n",
        "\r\n",
        "            output, _ = model(src, trg[:,:-1])\r\n",
        "            \r\n",
        "            #output = [batch size, trg len - 1, output dim]\r\n",
        "            #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output.contiguous().view(-1, output_dim)\r\n",
        "            trg = trg[:,1:].contiguous().view(-1)\r\n",
        "            \r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()/seq_len\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2-MdEl---15"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt09cUqE-_uY",
        "outputId": "38d88914-3480-4082-ff36-86edd6604480"
      },
      "source": [
        "N_EPOCHS = 50\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'gdrive/MyDrive/END/eng_to_python/model1.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 15s\n",
            "\tTrain Loss: 0.024 | Train PPL:   1.024\n",
            "\t Val. Loss: 0.085 |  Val. PPL:   1.089\n",
            "Epoch: 02 | Time: 0m 16s\n",
            "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
            "\t Val. Loss: 0.069 |  Val. PPL:   1.071\n",
            "Epoch: 03 | Time: 0m 15s\n",
            "\tTrain Loss: 0.013 | Train PPL:   1.013\n",
            "\t Val. Loss: 0.055 |  Val. PPL:   1.057\n",
            "Epoch: 04 | Time: 0m 15s\n",
            "\tTrain Loss: 0.012 | Train PPL:   1.012\n",
            "\t Val. Loss: 0.046 |  Val. PPL:   1.047\n",
            "Epoch: 05 | Time: 0m 15s\n",
            "\tTrain Loss: 0.011 | Train PPL:   1.011\n",
            "\t Val. Loss: 0.039 |  Val. PPL:   1.040\n",
            "Epoch: 06 | Time: 0m 15s\n",
            "\tTrain Loss: 0.010 | Train PPL:   1.010\n",
            "\t Val. Loss: 0.034 |  Val. PPL:   1.035\n",
            "Epoch: 07 | Time: 0m 15s\n",
            "\tTrain Loss: 0.009 | Train PPL:   1.009\n",
            "\t Val. Loss: 0.033 |  Val. PPL:   1.033\n",
            "Epoch: 08 | Time: 0m 16s\n",
            "\tTrain Loss: 0.008 | Train PPL:   1.008\n",
            "\t Val. Loss: 0.029 |  Val. PPL:   1.029\n",
            "Epoch: 09 | Time: 0m 15s\n",
            "\tTrain Loss: 0.008 | Train PPL:   1.008\n",
            "\t Val. Loss: 0.028 |  Val. PPL:   1.028\n",
            "Epoch: 10 | Time: 0m 15s\n",
            "\tTrain Loss: 0.007 | Train PPL:   1.007\n",
            "\t Val. Loss: 0.028 |  Val. PPL:   1.029\n",
            "Epoch: 11 | Time: 0m 15s\n",
            "\tTrain Loss: 0.006 | Train PPL:   1.007\n",
            "\t Val. Loss: 0.020 |  Val. PPL:   1.020\n",
            "Epoch: 12 | Time: 0m 15s\n",
            "\tTrain Loss: 0.006 | Train PPL:   1.006\n",
            "\t Val. Loss: 0.022 |  Val. PPL:   1.022\n",
            "Epoch: 13 | Time: 0m 15s\n",
            "\tTrain Loss: 0.006 | Train PPL:   1.006\n",
            "\t Val. Loss: 0.019 |  Val. PPL:   1.020\n",
            "Epoch: 14 | Time: 0m 16s\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "\t Val. Loss: 0.018 |  Val. PPL:   1.018\n",
            "Epoch: 15 | Time: 0m 15s\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "\t Val. Loss: 0.020 |  Val. PPL:   1.021\n",
            "Epoch: 16 | Time: 0m 15s\n",
            "\tTrain Loss: 0.005 | Train PPL:   1.005\n",
            "\t Val. Loss: 0.020 |  Val. PPL:   1.020\n",
            "Epoch: 17 | Time: 0m 15s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "\t Val. Loss: 0.016 |  Val. PPL:   1.016\n",
            "Epoch: 18 | Time: 0m 15s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "\t Val. Loss: 0.015 |  Val. PPL:   1.015\n",
            "Epoch: 19 | Time: 0m 16s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "Epoch: 20 | Time: 0m 15s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n",
            "Epoch: 21 | Time: 0m 15s\n",
            "\tTrain Loss: 0.004 | Train PPL:   1.004\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n",
            "Epoch: 22 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 23 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "Epoch: 24 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.015 |  Val. PPL:   1.015\n",
            "Epoch: 25 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 26 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 27 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n",
            "Epoch: 28 | Time: 0m 15s\n",
            "\tTrain Loss: 0.003 | Train PPL:   1.003\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 29 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 30 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.008 |  Val. PPL:   1.008\n",
            "Epoch: 31 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.008 |  Val. PPL:   1.008\n",
            "Epoch: 32 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n",
            "Epoch: 33 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.014 |  Val. PPL:   1.014\n",
            "Epoch: 34 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.006 |  Val. PPL:   1.006\n",
            "Epoch: 35 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.006 |  Val. PPL:   1.006\n",
            "Epoch: 36 | Time: 0m 16s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.008 |  Val. PPL:   1.008\n",
            "Epoch: 37 | Time: 0m 16s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "Epoch: 38 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.009 |  Val. PPL:   1.009\n",
            "Epoch: 39 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n",
            "Epoch: 40 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.007 |  Val. PPL:   1.007\n",
            "Epoch: 41 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.008 |  Val. PPL:   1.008\n",
            "Epoch: 42 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.013 |  Val. PPL:   1.013\n",
            "Epoch: 43 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 44 | Time: 0m 15s\n",
            "\tTrain Loss: 0.002 | Train PPL:   1.002\n",
            "\t Val. Loss: 0.016 |  Val. PPL:   1.016\n",
            "Epoch: 45 | Time: 0m 15s\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n",
            "Epoch: 46 | Time: 0m 15s\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.012 |  Val. PPL:   1.012\n",
            "Epoch: 47 | Time: 0m 15s\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.010 |  Val. PPL:   1.010\n",
            "Epoch: 48 | Time: 0m 15s\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.008 |  Val. PPL:   1.008\n",
            "Epoch: 49 | Time: 0m 15s\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.007 |  Val. PPL:   1.007\n",
            "Epoch: 50 | Time: 0m 15s\n",
            "\tTrain Loss: 0.001 | Train PPL:   1.001\n",
            "\t Val. Loss: 0.011 |  Val. PPL:   1.011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6AooAVGHlca"
      },
      "source": [
        "#torch.save(model.state_dict(), 'gdrive/MyDrive/END/eng_to_python/model1.pt')\r\n",
        "#model.load_state_dict(torch.load('gdrive/MyDrive/END/eng_to_python/model1.pt'))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5w1g2wAf64t"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 100):\r\n",
        "    # For Prediction\r\n",
        "  # Set the model in evaluation mode to deactivate the DropOut modules\r\n",
        "  # This is IMPORTANT to have reproducible results during evaluation!\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('en')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    src_mask = model.make_src_mask(src_tensor)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
        "\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        if i % 100 == 0: print(i)\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-uh3c0Qc5nB"
      },
      "source": [
        "## Randomly predict python code for 20 test samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ2HsF56zmjQ",
        "outputId": "cd5cd2a1-5e71-409d-b1a6-94c581af00dd"
      },
      "source": [
        "import random\r\n",
        "samples = random.sample(range(100), 20)\r\n",
        "\r\n",
        "for i in samples:\r\n",
        "    src = vars(test.examples[i])['src']\r\n",
        "    trg = vars(test.examples[i])['trg']\r\n",
        "    print(\" \".join(src))\r\n",
        "    print(\" \".join(trg))\r\n",
        "\r\n",
        "    translation, attention = translate_sentence(src, SRC, TRG, model, device, max_len=256)\r\n",
        "    \r\n",
        "    print(f'\\npredicted trg: \\n', \" \".join(translation))\r\n",
        "\r\n",
        "    print(\"\\n\\n----------------------------------------------------------------------------------\\n\\n\")\r\n",
        "\r\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  write a python program to implement shell sort and print the sorted list for the below list\n",
            "def gaps ( size )   : \n",
            "     length   =   size.bit_length (   ) \n",
            "     for k in range ( length   -   1 ,   0 ,    - 1 )   : \n",
            "         yield 2 *   * k   -   1 \n",
            " \n",
            " \n",
            " def shell_sort ( alist )   : \n",
            "     def insertion_sort_with_gap ( gap )   : \n",
            "         for i in range ( gap ,   len ( alist )   )   : \n",
            "             temp   =   alist [ i ] \n",
            "             j   =   i   -   gap \n",
            "             while   ( j   > =   0 and temp   <   alist [ j ]   )   : \n",
            "                 alist [ j   +   gap ]    =   alist [ j ] \n",
            "                 j   =   j   -   gap \n",
            "             alist [ j   +   gap ]    =   temp \n",
            " \n",
            "     for g in gaps ( len ( alist )   )   : \n",
            "         insertion_sort_with_gap ( g ) \n",
            " \n",
            " \n",
            " alist   =    [ 2 ,   3 ,   5 ,   6 ,   4 ,   5 ] \n",
            " shell_sort ( alist ) \n",
            " print ( ' Sorted list :   ' ,   end = '' ) \n",
            " print ( alist )\n",
            "0\n",
            "100\n",
            "200\n",
            "\n",
            "predicted trg: \n",
            " def gaps ( size )   : \n",
            "     length   =   size.bit_length (   ) \n",
            "     for k in range ( length   -   1 ,   0 ,    - 1 )   : \n",
            "         yield 2 *   * k   -   1 \n",
            " \n",
            " \n",
            " def shell_sort ( alist )   : \n",
            "     def insertion_sort_with_gap ( gap )   : \n",
            "         for i in range ( gap ,   len ( alist )   )   : \n",
            "             temp   =   alist [ i ] \n",
            "             j   =   i   -   gap \n",
            "             while   ( j   > =   0 and temp   <   alist [ j ]   )   : \n",
            "                 alist [ j   +   gap ]    =   alist [ j ] \n",
            "                 j   gap \n",
            "             alist [ j   +   gap ]    =   1 \n",
            " \n",
            " \n",
            " alist   =    [ 2 ,   3 ,   5 ,   6 ,   4 ,   5 ] \n",
            " shell_sort ( alist ) \n",
            " print ( ' Sorted list :   ' ,   end = '' ) \n",
            " print ( alist ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  97 write a program to copy odd lines of one file to another file\n",
            "file1   =   open ( ' file1.txt ' ,   ' r ' )  \n",
            " file2   =   open ( ' file2.txt ' ,   ' w ' )  \n",
            "\n",
            " lines   =   file1.readlines (   )  \n",
            " type ( lines )  \n",
            " for i in range ( 0 ,   len ( lines )   )   :  \n",
            "\t if ( i % 2   ! =   0 )   :  \n",
            "\t\t file2.write ( lines [ i ]   )  \n",
            "\n",
            " file1.close (   ) \n",
            " file2.close (   )  \n",
            "\n",
            " file1   =   open ( ' file1.txt ' ,   ' r ' )  \n",
            " file2   =   open ( ' file2.txt ' ,   ' r ' )  \n",
            "\n",
            " str1   =   file1.read (   ) \n",
            " str2   =   file2.read (   ) \n",
            "\n",
            " print ( \" file1 content ... \" ) \n",
            " print ( str1 ) \n",
            "\n",
            " print (   )   # to print new line \n",
            "\n",
            " print ( \" file2 content ... \" ) \n",
            " print ( str2 ) \n",
            "\n",
            " file1.close (   ) \n",
            " file2.close (   )\n",
            "0\n",
            "100\n",
            "200\n",
            "\n",
            "predicted trg: \n",
            " file1   =   open ( ' file1.txt ' ,   ' r ' )  \n",
            " file2   =   open ( ' file2.txt ' ,   ' w ' )  \n",
            "\n",
            " lines   =   <unk> (   )  \n",
            " type ( lines )  \n",
            " for i in range ( 0 ,   len ( lines )   )   :  \n",
            "\t if ( lines [ i ]   % 2   ! =   0 )   :  \n",
            "\t\t <unk> ( lines [ i ]   )  \n",
            "\n",
            " file1.close (   ) \n",
            " file2.close (   )  \n",
            "\n",
            " file1   =   open ( ' file1.txt ' ,   ' r ' )  \n",
            "\n",
            " file1   =   open ( ' file2.txt ' ,   ' r ' ) \n",
            "\n",
            " str1   =   <unk> (   ) \n",
            " str2   =   <unk> (   ) \n",
            "\n",
            " print ( \" file1 content ... \" ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file1.close (   ) \n",
            " file2.close (   ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file2.close (   ) \n",
            "\n",
            " file1 content ... \" ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file2.close (   ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file1.close (   ) \n",
            "\n",
            " file2.close (   ) \n",
            "\n",
            " file2.close (   ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a program to compute the frequency of the words from the input . the output should output after sorting the key alphanumerically .\n",
            "freq   =    {   }     # frequency of words in text \n",
            " line   =   input (   ) \n",
            " for word in line.split (   )   : \n",
            "     freq [ word ]    =   freq.get ( word , 0 )   + 1 \n",
            "\n",
            " words   =   freq.keys (   ) \n",
            " words.sort (   ) \n",
            "\n",
            " for w in words : \n",
            "     print ( \" % s : % d \" %   ( w , freq [ w ]   )   )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " freq   =    {   }   \n",
            " line   =   raw_input (   ) \n",
            " for word in line.split (   )   : \n",
            "     freq [ word ]    =   freq.get ( word , 0 )   + 1 \n",
            " words   =   freq.keys (   ) \n",
            " words.sort (   ) \n",
            " for w in words : \n",
            "     print \" % s : % d \" %   ( w , freq [ w ]   ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "   fibonacci series up to 100\n",
            "n   =   100 \n",
            " result   =    [   ] \n",
            " a ,   b   =   0   ,   1 \n",
            " while b   <   n : \n",
            "   result . append (   b ) \n",
            "   a ,   b   =   b ,   a   +   b \n",
            " final   =   result \n",
            " print ( f\"Fibonacci series up to 100 :   { final } \" )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " n   =   100 \n",
            " result   =    [   ] \n",
            " a ,   b   =   0   ,   1 \n",
            " while b   <   n : \n",
            "   result . append (   b ) \n",
            "   a ,   b   =   b ,   a   +   b \n",
            " final   =   result \n",
            " print ( f\"Fibonacci series up to 100 :   { final } \" ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python program to remove the characters of odd index values in a string\n",
            "def modify ( string )   :   \n",
            "     final   =   \" \"   \n",
            "     for i in range ( len ( string )   )   :   \n",
            "         if i % 2   = =   0 :   \n",
            "             final   =   final   +   string [ i ]   \n",
            "     return final\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def modify ( string )   :   \n",
            "     final   =   \"   \n",
            "     for i in range ( len ( string )   )   :   \n",
            "         if i % 2   = =   0 :   \n",
            "             final   =   final   +   string [ i ]   \n",
            "     return final <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a function that returns gets the derivative of exponential of x\n",
            "def derivative_exp ( x : float )    -   >   float : \n",
            "     import math \n",
            "     return math.exp ( x )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def derivative_exp ( x : float )    -   >   float : \n",
            "     import math \n",
            "     return math.exp ( x ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function that takes in a list and returns a list containing the squares of the elements of the input list\n",
            "def square_list_elements ( list_to_be_squared )   : \n",
            "     return list ( map ( lambda x :   x *   * 2 ,   list_to_be_squared )   )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def square_list_elements ( list_to_be_squared )   : \n",
            "     return list (   map ( lambda x :   x *   * 2 ,   list_to_be_squared )    ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function to split word into chars\n",
            "def split ( word )   :  \n",
            "     return   [ char for char in word ]\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def split ( word )   :  \n",
            "     return   [ char for char in word ] <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  61 write a python function to reverse the bits of an integer ( 32 bits unsigned ) .\n",
            "def reverse_Bits ( n )   : \n",
            "         result   =   0 \n",
            "         for i in range ( 32 )   : \n",
            "             result   <   < =   1 \n",
            "             result | =   n   &   1 \n",
            "             n   >   > =   1 \n",
            "         return result\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def reverse_Bits ( n )   : \n",
            "         result   =   0 \n",
            "         for i in range ( 32 )   : \n",
            "             result   <   < =   1 \n",
            "             result | =   n   &   1 \n",
            "             n   > =   1 \n",
            "         return result <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function to check whether a number is a power of another number or not\n",
            "def power_checker ( a , b )   : \n",
            "\t import math \n",
            "\t s = math.log ( a , b ) \n",
            "\t p = round ( s ) \n",
            "\t if   ( b *   * p )   = = a : \n",
            "\t     return f ' { a }   is the power of   { b } . ' \n",
            "\t else : \n",
            "\t     return f ' { a }   is NOT the power of   { b } . '\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def power_checker ( a , b )   : \n",
            "\t import math \n",
            "\t s = math.log ( a , b ) \n",
            "\t p = round ( s ) \n",
            "\t if   ( b *   * p )   = = a and s [ 2 ]   = = a : \n",
            "\t     return f ' { a }   is the power of   { b } . ' \n",
            "\t else : \n",
            "\t     return f ' { a }   is NOT the power of   { b } . ' <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function to rotate the given list by n times toward left\n",
            "def rotate ( lst ,   offset )   : \n",
            "   return lst [ offset :   ]    +   lst [   : offset ]\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def rotate ( lst ,   offset )   : \n",
            "   return lst [ offset :   ]    +   lst [   : offset ] <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  38 . python program to find sum of natural numbers using recursion\n",
            "def recur_sum ( n )   : \n",
            "    if n   < =   1 : \n",
            "        return n \n",
            "    else : \n",
            "        return n   +   recur_sum ( n - 1 ) \n",
            "\n",
            " # change this value for a different result \n",
            " num   =   16 \n",
            "\n",
            " if num   <   0 : \n",
            "    print ( \" Enter a positive number \" ) \n",
            " else : \n",
            "    print ( \" The sum is \" , recur_sum ( num )   )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def recur_sum ( n )   : \n",
            "    if n   < =   1 : \n",
            "        return n \n",
            "    else : \n",
            "        return n   +   recur_sum ( n - 1 ) \n",
            "\n",
            " # change this value for a different result \n",
            " num   =   16 \n",
            "\n",
            " if num   <   0 : \n",
            "    print ( \" Enter a positive number \" ) \n",
            " else : \n",
            "    print ( \" The sum is \" , recur_sum ( num )   ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  86 write a program which accepts a string and counts the number of words in it\n",
            "def num_of_words ( st )   : \n",
            "     return len ( st.split (   )   )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def <unk> ( st )   : \n",
            "     return len ( st ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function to sort list using heapq\n",
            "def heapsort ( iterable )   : \n",
            "     from heapq import heappush ,   heappop \n",
            "     h   =    [   ] \n",
            "     for value in iterable : \n",
            "         heappush ( h ,   value ) \n",
            "     return   [ heappop ( h )   for i in range ( len ( h )   )   ]\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def heapsort ( iterable )   : \n",
            "     from heapq import heappush ,   heappop \n",
            "     h   =    [   ] \n",
            "     for value in iterable : \n",
            "         heappush ( h ,   value ) \n",
            "     return   [ heappop ( h )   for i in range ( len ( h )   )   ] <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  93 write a program to find sum of all digits of a number\n",
            "def sumDigits ( num )   : \n",
            "   if num   = =   0 : \n",
            "     return 0 \n",
            "   else : \n",
            "     return num % 10   +   sumDigits ( int ( num   /   10 )   ) \n",
            "\n",
            " x   =   0 \n",
            " print ( \" Number :   \" ,   x ) \n",
            " print ( \" Sum of digits :   \" ,   sumDigits ( x )   ) \n",
            " print (   )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def sumDigits ( num )   : \n",
            "   if num   = =   0 : \n",
            "     return 0 \n",
            "   else : \n",
            "     return num % 10   +   sumDigits ( int ( num   /   10 )   ) \n",
            "\n",
            " x   =   0 \n",
            " print ( \" Number :   \" ,   x ) \n",
            " print ( \" Sum of digits :   \" ,   sumDigits ( x )   ) \n",
            " print (   ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  76 write a python function to converting an integer to a string in any base .\n",
            "def to_string ( n , base )   : \n",
            "    conver_tString   =   \" 0123456789ABCDEF \" \n",
            "    if n   <   base : \n",
            "       return conver_tString [ n ] \n",
            "    else : \n",
            "       return to_string ( n /   / base , base )    +   conver_tString [ n % base\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def to_string ( n , base )   : \n",
            "    conver_tString   =   \" 0123456789ABCDEF \" \n",
            "    if n   <   base : \n",
            "       return conver_tString [ n ] \n",
            "    else : \n",
            "       return to_string ( n /   / base , base )    +   conver_tString [ n % base <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function that takes two numbers . the function divides the first number by the second and returns the answer . the function returns none , if the second number is 0\n",
            "def divide ( num1 ,   num2 )   : \n",
            "     if num2   = =   0 : \n",
            "         return \n",
            "     else : \n",
            "         return num1   /   num2\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def divide ( num1 ,   num2 )   : \n",
            "     if num2   = =   0 : \n",
            "         return \n",
            "     else : \n",
            "         return num1   /   num2 <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python function to copy the contents of one file into another\n",
            "def copy ( from_file ,   to_file )   : \n",
            "     with open ( from_file )   as f : \n",
            "         with open ( to_file ,   \" w \" )   as f1 : \n",
            "             for line in f : \n",
            "                 f1.write ( line )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " def copy ( from_file ,   to_file )   : \n",
            "     with open ( from_file )   as f : \n",
            "         with open ( to_file ,   \" w \" )   as f1 : \n",
            "             for line in f : \n",
            "                 f1.write ( line ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  44 . python program to multiply two matrices using nested list comprehension\n",
            "X   =    [   [ 12 , 7 , 3 ]   , \n",
            "      [ 4   , 5 , 6 ]   , \n",
            "      [ 7   , 8 , 9 ]   ] \n",
            "\n",
            " # 3x4 matrix \n",
            " Y   =    [   [ 5 , 8 , 1 , 2 ]   , \n",
            "      [ 6 , 7 , 3 , 0 ]   , \n",
            "      [ 4 , 5 , 9 , 1 ]   ] \n",
            "\n",
            " # result is 3x4 \n",
            " result   =    [   [ sum ( a * b for a , b in zip ( X_row , Y_col )   )   for Y_col in zip (   * Y )   ]   for X_row in X ] \n",
            "\n",
            " for r in result : \n",
            "    print ( r )\n",
            "0\n",
            "100\n",
            "\n",
            "predicted trg: \n",
            " X   =    [   [ 12 , 7 , 3 ]   , \n",
            "      [ 4   , 5 , 6 ]   , \n",
            "      [ 7   , 8 , 9 ]   ] \n",
            "\n",
            " # 3x4 matrix \n",
            " Y   =    [   [ 5 , 8 , 1 , 2 ]   , \n",
            "      [ 6 , 7 , 3 , 0 ]   , \n",
            "      [ 4 , 5 , 9 , 1 ]   ] \n",
            "\n",
            " # result is 3x4 \n",
            " result   =    [   [ sum ( a * b for a , b in zip ( X_row , Y_col )   for Y_col in zip (   * Y )   ]   for X_row in X ] \n",
            "\n",
            " for r in result : \n",
            "    print ( r ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "  write a python program to calculate factorial sum using list comprehensive\n",
            "n   =   5 \n",
            " print ( functools.reduce ( lambda x ,   y :   x   *   y ,   range ( 1 ,   n   +   1 )   )   )\n",
            "0\n",
            "\n",
            "predicted trg: \n",
            " n   =   5 \n",
            " print ( functools.reduce ( lambda x ,   y :   x   *   y ,   y ,   range ( 1 ,   n   +   1 )   )   ) <eos>\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyT1OP_-7jbh"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 4, n_rows = 2, n_cols = 2):\r\n",
        "    \r\n",
        "    assert n_rows * n_cols == n_heads\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(15,25))\r\n",
        "    \r\n",
        "    for i in range(n_heads):\r\n",
        "        \r\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\r\n",
        "        # print('attn',attention.shape)\r\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\r\n",
        "\r\n",
        "        cax = ax.matshow(_attention, cmap='bone')\r\n",
        "\r\n",
        "        ax.tick_params(labelsize=12)\r\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                           rotation=45)\r\n",
        "        ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nxTFy0NTGkFb",
        "outputId": "1bb90785-523f-4db3-beb7-3a4d6e533a67"
      },
      "source": [
        "src = vars(test.examples[10])['src']\r\n",
        "trg = vars(test.examples[10])['trg']\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device, max_len=256)\r\n",
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4kAAAT6CAYAAAD4Pya0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZwcdZn48c+TDAm5D8B4ICAg6HIIGIXVVRAPPNcTFfHCg1XAE9H12PVe9bfqKoIKeOGqrLreK6KuCoIiEASRW2BRkMghBEgCOcjz++NbXXRGEjI9M1XdM5/36zWvma6u7udbU8fTT/W3vhWZiSRJkiRJAFPaboAkSZIkqX9YJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkStJGRETc09+SJE125siJyyJRkjYgIoYyMzt/A3NabpIkSX3BHDmxRbVuJUldImJKZq6LiCnAf1NOqs0BvpyZJ7bbOkmS2mOOnPiG2m6AJPWjKvkF8HPgGuDjwDbAdyLipsz8YasNlCSpJebIic8iUZI2bDdgXWa+BCAiXgpcBJwSEbMyc0WrrZMkqT3myAnMaxIlqRIRU4dNugMYioi5EXEi8HhgcWbeBRwZEds33khJklpgjpxcLBIliZL8MvOuiJgSEW+MiJ2AW4DpwGnAzsBembkqIt4IPBVY2WKTJUlqhDly8rFIlCSgk/yA84E9gamZeRPwNmAH4PvAkyPiLcC/AK/JzL+01mBJkhpijpx8HN1UkioR8Wlgy8x8/rDp+wIvAOYDtwKfzszft9BESZJaYY6cXBy4RpLuNpMylDcRMR1YA2RmnkbpTkNETMvM1e01UZKkVpgjJxG7m0qalKpuM8NtBTwbIDNXAVMyMyPi1dX1F1CSoiRJE5Y5UhaJkiad6gL8dVFsHxEPqp76MLBlRPwzQGaujYjXAm8Ebq+m2UdfkjRhmSMFXpMoaZKJiClV8psCnAVMA1YAJ2XmpyLi1cDLgC2Bc4D9gGdm5m/barMkSU0wR6rDIlHSpNFJftXfnwQ2A/4DeCzwduAzmfmxiFgAvBS4ArgkM69qq82SJDXBHKluDlwjadLoSn5HAXtQhuj+Q0T8mXK/p49FxOaZ+UHgky02VZKkRpkj1c1rEiVNKhExl3JPp4dQhuwmM1cCJwNvAo6KiLe210JJktphjlSH3U0lTWgRMZSZa6u/p1Y3BJ5N6Trzd8B3gP+sRmjbHHgCcGlmXtFeqyVJGn/mSG2IRaKkCasr4U0B/h24D/Bb4MeUayneD2wPfB/4iqOySZImC3OkNsbuppImrK7kdyawNfALYDfg85TuNB8CrgReQtWtRpKkycAcqY2xSJQ04Qy7CfABwI2Z+YLM/AKwEFgLXJGZyyhJ8DfAGc23VJKkZpkjtSksEiVNKF03AZ4aEVsCW1GN5BwRJ1LOju6fmWsi4tmZeSvw7sy8tsVmS5I07syR2lQWiZImjOoeT3dFRACXUW74ezowJyLOpIzW9rAq+b0DeGVEzPU6C0nSRGeO1EhYJEqaMDr3eAIOBn6emR8DlgI/BBYBJ1ZnUN9MGcr7HZl5WzutlSSpOeZIjcRQ2w2QpLEUEe+jnB29sOpWc2dEfBW4ATg8Ip4KzAKekJkXtNlWSZKaZI7UpvIWGJIGWtV9Zl3X4y2Bj1Du7/SvwM86z1f3eApgamYub6O9kiQ1xRypXlkkShpYnZsAV9dXbA3MycyLI2IOcBylt8RngV9UNwIOr62QJE0G5kiNhkWitAHDD5YePPvLsJsA/wpYBuxNSXhfA/5IudfTWuBE4CeuP0kaPfNj/zNHarQcuEa6B9XZt6z+nhkR06uzbFPbbttkFhEPj4hPVw873We+DVydmU8B/gE4FDgwM28H/glYQLkJ8Iym2ytJE435sX+ZIzWWHLhGGqbqv7+2Ovv2M2AFMCMiXpyZS4f371czImIr4JvAZwC6zngGcFj19+GUkdreFxELMvOWiHgRMDMzVzbdZkmaSMyP/cscqbHmN4lSl2EJ7jjKaF/HVr9/FxHbVsNDu+80737Amsz8d4CIeEFEDAEPBg6IiM8CjwYemZl3AUdGxBMy85bM/HN7zZakwWd+7HvmSI0pd2SpS9cIX28DtgIOyswfZeZBwMnAuRGxjYmwedVQ3BdExK8j4iJgj8xcCxwPvB04IDP3yMw7IuJw4EXAlS02WZImDPNjfzNHaqw5cI00TETsCbwLeArw/Mz8n67nPge8Atg2M69pqYmTTmdQhIjYAbgUuCUz71M9tzvwOmAO8BdgOWUdPS0zz2urzZI00Zgf+5M5UuPBaxI16XVGAOs8zszzIuLdlGstDomImzLzN9Vzr4qIVXiBd2OGdXHaiTIq28yIOAN4RmZeEBH/DtwfOBC4Dtg/My9tp8WSNDGYH/ufOVLjxW8SNakNGyL6EEoXmjOA84AHAEcBc4GPZ+ZZ7bV0curc46n6e25m3lb9fT/gc8BC4EnVKG2SpDFifux/5kiNJ4tETUrdZ0erBHgucBWwBaUrxgrKKGD3oXTT2A74l8xc0kqDJ7FqWPUfUj6g/AL4Wmb+NiK2BY4B5lG6zZgEJ5muD7Heo00aI+bHwWKO1D0Zi/zohcWj1Lk4OyKmdU2L9lqkjYmIBwN0d58B3gRcn5nPzcz9gI8AdwL/mpkXA/8FXEIZNloNGDbowXHATcA7gJ2BwyJi/8z8I+WDCsA33e8mnyoBzgcOjojtWm6OhjE/Dhbz4+AwR+rejEV+9JrE0dssIu4DvDEiLs7Mz3tGuz9VB9XPRMSXMvMrXU+tA67pzJOZp1ddNY6KiIWZeVpEnJ2Zd7TR7rHU3TVl2PS++SZmWPeZLSgX4Z+YmTdGxB8po7S9JCLWZeap1T2e+qb9akZE7AvsCBwBPIzyYfaTrTZKw5kfB4T5sTBHaiIYq/xod9NRqHa8XYD9gb2BL2bmK9ttlTYmIqZl5uruC70j4lDg34GHZObSatpmwK+AQzLzovZaPHY6y1x9GPgU5czjtZl5QvV860mka4S2qcDPgTWU/esfgR9VZ8YeQrkWZh7wycw8vb0Wq2kRsR/wdMo28R1ge8pAGS/MzOUtNk1dzI+DZzLnRzBHavCNdX60u+kIRcTUiDgiIj4DfBy4Fvgm8HngA9U8fqXfJ7rXRXVwXV09/FRE/AkgM48HfgCcHhF/FxFzgJdRhou+vuk2j4eu5BeUxPJ3lBvvHh4RHwOoEk9r227Vxk4CfjdwM/DPwFmU6152qua5lLLv3QBc0UpjJ7nh20kT201ELIqIU4A3Uq6Fek5mvg34JeWaqTvDe7O1yvw4WMyPdzNHaqxMpPzoN4kjEBFzga8CdwFnAv+VmX+MiBcDzwIOz8wJcdDshzNmYykiHpyZf6j+fiJwPiXxTcnMR1Y78QmUsy8XUkZuOygzf9tWm8dK97qMiNcAe2bmP0XE5sDfA58GTsnMNw2fv422At8H/gx8MDOvqab9L+WM6RuBy6tkvllmrmmjnZPZ8O5YTW0vEbE1Zfj2k4Bbs9wQ+hHA94AXZeap490GbZj5cXBN5vwI5kiNnYmWHy0SRygiHpWZv+466/QQ4EfAUZn53223byzE+v3d19vABzE5RsRhwGHAq4EvAt/IzH+NiHmUA+u6zNy7mncx5ezcysz8S1ttHitx9+hWQ5Tk8aLqqcdm5vIoA0o8lnLW8azMfHULbey+xxMR8T3gGcDjMvO0atoQZfS2ecBLM/PyQdwWB12s3x3rP4HVlLPtR45Xt7PqA9DW2XVz7mraVOBfKR9k3+X20D7z4+Btg5M5P4I5UmNnIuZHu+ZsgoiYEhGvBsjMX1eTO/+7XYGTKdX6wKsOmGurZT4G+HpEvD0ingylu0XLTRyxzPw0cDEl4f0xM/+1mn4r8ETKPtW5GfCSzLxqIiTA6oB1V3XA+A6l68k3KMOXvzgiNq+6F/2S0mVl94hY1HQ7O118IuLZ1eNnUkbM+1qnPdWHsqdTujfdWU0buG1xkFVJptMd60xgM0o3wguA8yJin3GIOYVy7dO7I2JGVzsSmEbZfy8Et4e2mB/Nj4PKHKmxMlHzo0XivYhycfBZwHOi3HMGqHdIgLcAN02Ur/S7DphnAPMp3RpmAUdHxGNbbdwIVeuu43LgamB6RDwsIqYDZOYyyo40LyJ+0Xwrx0/XAesw4K+Z+WXgo5T7KD0ReHlETK+S4E8pZyXb6g52MPCWiHht1fYXUQ6053UlwTWZ+czM/FNLbZx0IuIBEfHU6sNSJ8k8grI9PT8zz6imXQqc3fW6UV+DUSXAs4E/AK/NavTErna8nHLs/a/RxlJvzI/mx0FmjtRoTIb8aJF4704BLsrMp2S5vmLLiJhenUncDbgsM98Ng31Bfqx/QesTgBWZ+eIsQ2E/BLgROCMiZrXSwBHq6kIyJSIOAk7KzF2A6yjXF+zelSTnA4+h7FQTzTuBdwGnQ/3h7d+Aiygjor02yoh2azJzZVONGvYBBUpS/gHw5Ig4vGrr8yhncP8UEVs11Tat5w2UbehJnQ+OlDOUD4iIGRFxIvBkSmIkIt5SfagaizPYTwSWZebLMnNNRBwZEUdHxGFRRlf8BuXs/vDjl5pjfjQ/DjpzpHo14fOjiXUjovTJvxX4bPX4GOBrlG4Zj8rM31M2kIG8FqGjShjrug5KMygXQBMRX6bcnHW/LH3inxHlvjx9q1oXd1U7xnnAc4HOWZYXUUbc+ziwd0S8DTgeWJPlxrMD7R4Sy+8oif9lnQmZeSclCV4D7AXMbKyBd7fhrqr7zI7V9vdn4EvAb4ADogweQGa+kNKtZn7TbRRk5luB3wKvAZ5SJcKrgT9RvkXZPTN3z8xVlPsxPQeYO0bhb6CMyPaRiPgm8GJgGfAx4IDMvCmr6zyy63odNcP8aH4cROZIjZXJkB8duGYjoozWdjTlwtO1wBbAKyg3pLw6W7iAeaxVZ6RuAL5F2ag/SDlg/pxygfoaygXcayPin4H9KPdbWdZOizdd9aFlfma+uHrcPYLZicAiylng52bmue21dGxVZ+xfB/w0My+JiP0pH9b+CByadw+6MB2Ym5k3Ntm2rnXwIeCpwEuBC6ukuIhy9utxwAmZeWxTbdP6qrPnq6u/jwF2AD6Tmd+PiNdRhmA/ivIha1/KNvb4zPzdKOPOpRxvVwGHU46/dwHvrc6Yngj8MjM/P5o4Gh3zo/lxUJkjNVqTJT8OjcWbTCTVweMfgOWUMwLvoNwIeAj4drWT/oRyP5qBHF44IuZn5rKImA/sDiwAPgKcmZlnVvN8GHgPpX/+zCgDExwJPGFAEuBUyjDd364eD1WJfCpltLaXRcQ2lG5Df22zrePgIZSR6h4UEZ/JzJ9Xy/0G4LiIeE3VdWYVpZtUI7rWQVAS79ujjH74UeCoiLgoM6+PiB9RLsBfHBELM/PmptqoolpXq6tuKzMy84iI+BTlnmF3ZeanImIV8EjKtTI3MsoEWH2z8U3K8WgNcHpmdu6t19l23gQ8DXj/6JZQvTA/mh8nCHOkejap8mNm+lP9ULrfnkm5KP1cyqhAj+96fohyBmcZ5Wvk1ts8wuWLagP7K7BrNe2+lGS/FHh617z3oXw1/jvKqF8/6udlpgzzO3za54D3AtM6y1/9fgGwsO02j+GyT72HaY+knO3+JPDgatoTKNddHNtwW6Kzfqp97JfAW4HNq2n/A/wE+Pvq8YspXZy2aPt/Oxl/7mFdHQXMqqYdW62rp3XNPwOYPsqYQRkY4nOUouNFwJWUe+0B7ERJfNcBe7X9P5qMP+ZH8+Og/vRLjtxQfuxeR+bI/v6ZbPmx9X94P/0AxwFfqv7egXJm8A7K1/pDlJHazqHcaLX19o5iOTsJcCqli9AhwP+jXE/ykmHzDlW/Z7fd7o0sT6eNQTlDOL16fAhl9Kcnd5Ie8HrgCmBR2+0eo2XvJJgA3jnsuX2qg9hxwLbVtP2ABzawHh5NuVh7bte0AH5dbWdTgM26XvsNyiiJv6Zc57Rr2//byfxzD+tqqOu5Yyn343pB50PMGMTbnlKAbNE1bWfg95QzsZsBzwMe1Pb/ZrL+mB/Nj4P40y858t7yY9dz5sg+/5lM+dHupuubD5xa/X1VZn6sujj/0Mz8RUR8B/hyZt7QWgtHoerCMDUzL6wmnQr8Z2YeHxELKd1nnhYRazPzpIh4ITAdOJFy36C+U/Xf73STOZ2S1JdGxKcy84sRsT3wdmBWRFxMGRHqadneMNZjptOdq+qG8ADg/RHxoMx8FUBm/iYi3km5T9mMiPhAZp46Tm3prIfOfXsAbgceHBH/mJm/j4g9gFuzDI5ARGRUo+xl5vMj4gBgIbAkM/8wHu0cSzHsBseDrrMuqocP42/X1ZTMXJeZh0fEFyhJ6YdjFH4VJfHuDvyiOlZdBZxPSXxrgAlxM/YBZn40Pw6UfsmR95Ifn5V3d0O8p+PuQOZI8+PEyI+ObgpERGfkqluBB8J69xq5HJhXTbtyUBNgpXOgmhYRO1K6KxwTEYdk6dP+QeAvwMFVn/ejgSXQnzdlrXbKTrveTblfzKMpZ1deHBGvyMx/Ad5IObtzCmXUvd+20uAxFBFHUEaf2wz4CrAlsBvw9Ij4Yme+zDwd+BllRK1bxqs9XevhM5Rh7/+ecoZ6AeVain2AdVWbt6/m7dzIeMuI2DYzf5yZJw1A8ts6IracYAmwsy6mbWRdravW1aLMfAVwRGYuH2XcGdWfSykjwh1ZFR5UiW8ZZUjxgb6FwiAzP5ofB1E/5ch7yo+Z+SRKfnzTvRx3BypHmh8nVn6c1N8kVmd1jqd8jf8T4LvASRFxBfDdKjHMA9ZFxKzM7MuzhZuic2Fr9fAc4ILMfEl1AP18RFCdWfwApbvFrsBbshpCt09ltWP8gPIB5v9l5k0RcSTl7OizqnX8lcw8r82GjqWImA0cQBkxa0/KWcXzqueeAPwsIr4CvA04kDLIxJtznEdoq85WbwV8OiKGgM9TrufZndI17c2Uez3tHxE3ZeZt1UsPoZzJ/mD2+UAXEbEL5fqjVwM/brk5o1btH1O6jg1nU66zOpINr6t5EfHu0XzbUMX9MrBlRFxN+Z++iHJs+ipwUUSsrKY9Gvrzg/hEZn40Pw6qfsyRXfnx2Or//iVKfnwV5Zh7HqVgH9gcaX6cePlx0haJcfc9gq4GzqnOFJwcEa+l3B/npRFxC/D3wJMHOQFCuUFstczPpQz7/JZq+heqExCfj4h1mXki5Wvrvu3a1dX9ojNM9DLKzvJD4HdZRp36N8ogCgdV83we2v2gWXU5GVX86j2WR8TLKAerKZT74gCQmRdWZ7pOoQzbvg1lwIUxP8N/D91JtqF8GJlNOWO6B/Bhyn2mVlGSdue+XNtGxDnAgykjJO7bz8kP6mPGW4EfZ+aPq8ebZRkBb6BExAMy88/V+ltXLcvzKMeGo6p5Nrau7trQe29C7KB05bua8g3Hoyk38D4YeBRlv70v5Sz7vpl5aa+x1Bvzo/mxDRMpR95DfhyijEo5h3IN5MMog+c8B7gNOLUq4gcyR5ofJ2h+zD64CLSNH0rXkS93PT4A2J8yatm2lItODwG2b7utY7jML6F8TX4x5QzwEHdfMP3y6rkXtt3OTVyWAF7V9fizlGGG9+iaNo1ypnDrFtr3N6OYjcF7do+qtS3l5qxfBr5ebb/dF09PAbYGthrjNnQuvp/RNW17SuL7OqU4XANcQrm30zpKV4lrgB2r+Q8FTqBchP9t4GFtb08jWP7XUc7q7QGcBOzTdpt6WIbOunpS17SDqnV1IV0jG47HuqKc2f9p1+OvVe8/vXu/6d6e/Wl8GzE/mh/Hu40TLkduKD9Wv+dQTrysrfLj5l3H3dXAw7teM5A50vw48fJj6yukhQ1gi+r3uyj3HFlUbcy/B/6X8hXyRBzZ678oZz2eWG3sz6mmT+ma92DgoW23+R6W4W9GiAKeVCXz93VN+wJwU3cibKm9Uzv/W0rR9FlK15Id6RqtbITv2T0y2jZUo1hVB46vVtvy46tpz6bcAHmsl2sRZeS7nbtin0E5W3s28Pxq+jur/enTlMESEjjyHt5vJtXw64PyQxlR7HOUD1w/a7s9PS7DNO7+4BJd0/+pOjY8ezzWFWXQjKCMKHhONe3z1bayWfX4VcA2w9vmT2PbhvnR/NhEmydcjryX/HgWpZvy9sPy4wmU6yDH7bjb8Ho1P/Yety/z42QcuObrEfFsygFjJ8o1F9MoXeLeSfnaf+BV/d/JamuidDU5hnIm5FDgG1FG1ep8lU5mfjUzL2mlwRsQEbsDH4mI+w97agml29Njq+tEyHKx8HeA30bEbs22tKi6utxVdRk4l3INwq+B7ShdTB7fmW+E79npDnUmZZs9NyI+AjyUcvBaC7w+Ir5FSTwXbvANe5Slj/15wC8jYgfKWcM/Uj5YXQ68KiL+kXKG9DZK//njKDei/nBEPGvY+63MzNVj3c7x0LU/XUY5Q70KuDoidmq1YT3IzNWZeVX18H0R8d1q+nGUa5W+MU7r6iTgmZTtgoi4EtglM3fLMgLhUcArgJVVTK9BbJ750fw4riZqjryX/PgHSlfEXTPzg5TCcR/gNMq+NZ7H3XFnfpzA+bHtqr3JH8oFyt/n7huUzgHux91dFF5DOXDcp+22jtHyBiXhde6B9G/Ax6u/31htbM9voV1bA1tuwnxbUroqvrF6PJXSJ7tzn6f5lJvKnga8t+t1xwA7tbBcnbOjQbkH0g+HPX9c1dZN7ibA+t0Lvs/dN0/dmXJW+P3V47mURPh+xvD+Sax/Jq2zn3wBuJmSaB/C3WdwP0k5e/0JyiAXn+t67dsow8Q3vr2Nwf+gs3xTKfeHeynlhrafoJyhHvebaG/qPjOCZZlSbS8vp3xwHNd1VR17v0d1Pzng6cAFlG8RdqAk3/W6w/nT7I/5sT/yYxX/Xvf3QcuPnTZ2/e8HPkduSn6spg1V+fGnlJFkX9nEcbehddp6fqzijzpHmh/voW1tb2CNLmwZsvrjlDOj3X3T7wf8R7Vj79V2O8dgOTtdaN5L+Xr8DMpF0i+hnCHeu+v5G2joRsDVjveLqj03AC8DZm5k/i2rg/7DqqRyGuWM49O5OxHOo4yaeTXwgRb/5y+hdDmYArwPeAOlG8l9hs13NcNuyLyx/1f1e1p10P0Cd3+gOZbSDWEqsKCB5XtptXxBOUP6tWrbelrXur2g6+d9lGsTPt+1Pb6nye1tjJa70/Yp1Xb7P8B1lLPC76uOJ//JON3YeKT7zAiW5QLK2fa9qv1pXNdV97G3qw17U04mfItyDchuba/vyfyD+bHV/FjF3OT9nQHKj1VbJmyOZCP5cdhx90bgespJiHE/7jawTlvNj12xR50jMT/ec9va3sgaW9Cyoq8FHtw1bSrwfMpFtke3tRLGcBlj2OM51Qb2O0o/8TdTuj38pGueLZpqG/AbynDq8yhfm19FdSPfDbxmIeVGxZ8DLqN8Hf+x6kD0DO4+470PpXvN92jhLDfl+ocbKWdoL6ca8IEyAt5bu5evWv4DNuE9u8+OXkz58HIe5czwcZSbqM6onv8A1bUW47x8x1KuuTixmv5Z4K+U6yy+QhlKHcqIpttREuTJ1cG2c3BtZHsbh//B/1DOik6ljBT46a596jPVtjem1yv1ss9s4vvW66qzrY3nurqnY281vXtggIG57mYi/tzTOsL82OjxaqT7OwOSH6s2TNgcySbkx+rxV6qfD1evGdfjbsPrt/H8WMUd8xyJ+XH99rW9cY37At7dveEtwDurvx9GGfXqnGrj2rnNlTAOy/wB4EXV38+qdtTnVTvvGZQzXO+onp/SUJuew/qj5R1D6Srze8pZpw0VijtRbqvwf1QDJlQJ4AfcPVDKSyhnEOe1+D/fHbidkgA7Z4PeRBnx6pOUoeJfRznLtkkjAlYHwOcAn60eH1r9v67umufw6qA4rqMMDlu+6V3TO11rTgaeUE3rfDjZDPhHyoAXxza5vY3xsk+jnLHfrWvaPtWx4/nAYykfEO4/xnF72mc24X2/2cS62oRj7/eour3hIDWt/GzCOjI/NteuEe/vDEh+rNoxYXMk954ft2/quNvCem0lP1ZxxjxHNrWeNuHY2xf5sfUNrJGFLN0yfkvpI31odRD6KHB4220bh2WdTxmZ7mbKQAPPopwZ2b96fkfKSG6NDl1OGbmpM7LYcZSbFXd26turHeNvdrqqvV+sdpgvALtw932PzqCcLbyJloeIBh5YJbqLqt9bUK5DOKj6/59DuR5hk7trUc7gr6vec371vzie0vXgU5Rh6q8D9mx4+T5B1whblGsvkuq6l2r9dPr2v5oyauAD2lw/o1z2uZQuUEd0lrn6/XHg29XfPXUBvZe4Pe0zG3m/oHSJuhh4UxPrajIdewf1ZzKto37Nj1XsEe/vg5Ifq7ZO2By5ofxYPfeZqo2XN3XcbXi9tpIfq/cdsxxpftxAG9tuwLgvYFnJR1Y76dcpX4M/Zfg8bbdzHJZ7L+An1QZ3DnAp8HfVc2N+f6JNbFNQ7rP1486ORrkI+Bju5V5N1UH4FEr3modW77UnZTSovrlXF+Ws+6WUM2cLqmmPotxj7G+GKt+E93skpSvCgdXjrYF9qwT4GqoL41tYvqOpzgxW29oS4ErgGV3zHgb8kgkw0AWlG8uFw5bvHdV6GLezfKPZZzbyni+l3KdrXNfVZD32DtLPZF1H/Zgfq9g97e+Dkh+rtk7YHLmR/PgdSrfacT/utrROW8mPVZwxzZHmx/V/OhX/hBYR21AOFv8B3JmZt7fcpEZUw2I/nnLPpIMpCfHtwLpsacVXbbqYcluElZSv2v8+M6/dhNfuQDnoLAWOy8yzx7OtvYqIXSldFk6nDLv9bMpgCH/q8f32pfTv/2fge5m5dqza2mN7Osv3S8oB7h+Bx1BusP0GynKvAJ4MPDUzf9tSU8dMRMwGXk85M/m/wHJKV5r9M/OCcY7d8z6zgfebRVmWcV9Xk/XYO0gm6zrqx/zY1a4R7++Dkh9hYufIDeTHxZTbxzRy3G1am/mxij9mOdL8uL5JUSR2qyGuguIAACAASURBVO6nM2kWurrX0BDlYunjMvPylptERLyCcp3AKuD1mblkBK/dAfgy5Sv6ozLzzvFp5ehExN9Rzj7NBz6WmeeN8v32pXRbeT+lC8eq0bdyVO35m+Wr7pX0KMqHrqXATzPzDy02c0xFxGaU6yueRRmh7tuZeXFDsXveZzbwfo2vq8l27B1Ek20d9WN+hN7390HJjzCxc+SGlm0i58g282MVf8xypPnxbpOuSJxs+nbDi5hD2f5GfHPmiHgQsDYzrxn7lo2diBiiLOOaMXq/JwAfopyda/2M01gvnzZuNPuMpL/Vr/kRet/fByU/wsTOkebH5pkjx55FojRAImJmZq5sux2SJPUbc6Q0diwSJUmSJEm1KW03QJIkSZLUPywSJUmSJEk1i0RJkiRJUs0icSMi4tDJELOtuMaceHGNOfHiTpaYGrnJsm1MlphtxTXmxIs7WWK2FbepmBaJG9fGBtfWh6PJsqyTJWZbcY058eJOlpgaucmybUyWmG3FNebEiztZYrYV1yJRkiRJktSsCX8LjBkzZuWcuQt6eu0dd6xgxoxZI37daP6jd96xgs17iAlw15q1PcddtWol06fPHPHrpgxN7Tlmr8s6JaLnmL2u07vW3tVzzDtXrWTzHv63AFveb2HPcZfdfAvzF45827/lpt7vQ9vr/3fl8t7ve7xmzWo222xaT6+dM39eT69buWI5M2fN7um1a9eMYlvqcZ/ZatFotqObmb+wt9cvveaGnl7X6/EIYNmy62/KzK16evEkNHvu3Fy41X16eu3y225j9ty5Pbyy92P48ttuZfbc3vbbVSvv7Ol1d6xcwYyZveXlO1b0dsu+1avvZNq0zXt67fQZM3p6HfR+jLlzZe+3JlyzZhWbbTa9p9f2+hl2NDGjx88go4k5d+H8nl4HsGL5bcya3ct+CsuX9ZabV6++g2nTetsO77prTU+vG81nga0esKin1wHcfuutzJnX2zFpaGpvn6FvXbaMefNHvk3csHQpt95yyyZvwEMjjjBg5sxdwPMOfl2jMdeta6fw/uvSvzYec+7COY3HnD6jt4PsaCy78dbGYwK86u0HNx7zOyee0njMJaed1nhMgP2e9bTGY9689ObGY772zS9qPCbAB448uvGY3/rWx//YeNABtnCr+3DUhz/eaMxeP2SP1hXnXdF4zAvOPLfxmDvtvmvjMS89/3eNx4RSeDWt10JvNJ74wuZzFcDp3z218Zi33npT4zFf+29vajwmwJYLeisue/WGF43ss4DdTSVJkiRJNYtESZIkSVLNIlGSJEmSVLNIlCRJkiTVLBIlSZIkSTWLREmSJElSzSJRkiRJklSzSJQkSZIk1SwSJUmSJEm1visSI+JLEfGBTZhv54g4PyJuj4jXN9E2SZLaYn6UJDVlqO0GjMJbgV9k5h5tN0SSpD5ifpQkjUrffZM4AtsCF7XdCEmS+oz5UZI0Kq0XiRGxZ0T8tuoW83Vg867nnl51mVkWEb+OiN2r6T8HHgccExHLI2KnlpovSdK4MD9KktrSapEYEdOA7wL/CSwEvgk8t3puT+ALwD8BWwDHAd+PiOmZuT9wOnBEZs7OzMuHve+hEbEkIpbccceK5hZIkqQxMF75sXp9nSOX33ZbMwskSRoobX+TuA+wGfCJzFyTmf8NnFM9dyhwXGaelZl3ZeaJwKrqNRuVmcdn5uLMXDxjxqxxa7wkSeNkXPIjrJ8jZ8+dOy6NlyQNtraLxPsDf87M7Jr2x+r3tsCRVVeaZRGxDHhg9RpJkiYy86MkqTVtF4lLgQdERHRN26b6fQ3wwcyc3/UzMzNPar6ZkiQ1yvwoSWpN20XimcBa4PURsVlEPAd4ZPXcCcBrImLvKGZFxNMiYk5rrZUkqRnmR0lSa1otEjNzNfAc4OXAzcALgG9Xzy0BXg0cA9wCXFHNJ0nShGZ+lCS1aajtBlTJbs8NPHcKcMoGnttvHJslSVKrzI+SpLa03d1UkiRJktRHLBIlSZIkSTWLREmSJElSzSJRkiRJklSzSJQkSZIk1SwSJUmSJEk1i0RJkiRJUq31+ySOt5nzZrLXkx7eaMwb/nRDo/E6Vt6+svGYD93noY3H/M0PftN4zEsuOavxmAC3rHh24zHb2H5nzJzbeEyAdWvvajzmjnvu2HjM315+ZeMxAS699OxW4mrT3X7z7fz8a79oNOZ7PvmmRuN17LPXLo3HfNl3v9V4zNce9LrGY978l5sbjwnw0L0f0njMLx/9icZj3nbTYxqPCXD++T9rPOYWWzyg8Zh/uuSaxmMCXHr7ZY3GW37bihHN7zeJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqFomSJEmSpJpFoiRJkiSp1nqRGBFfiogPtN0OSZL6jTlSktSG1otESZIkSVL/GFWRGBGLxqohG3j/rSIixjOGJEnjwRwpSRpUIy4SI2J+RLw2Is4GvlRNy4jYsWueuntMROwXEddGxJERcUNELI2IQzbw3nMi4hcRcXSV+F4B/F9EvDciHtTLAkqS1BRzpCRpItikIjEipkTEkyLiJOCPwJOADwL/uIlx7gvMAx4AvBI4NiIWDIuxBfAz4FeZ+fosPgK8ELgPsKRKji+JiJn30t5DI2JJRCy5/dZbN7GJkiSN3CDnyFWr7hjJokqSJol7LRIj4gjgauDDwJnADpn57Mz8Xmau2cQ4a4D3ZeaazDwZWA7s3PX8/YHTgG9m5ru6X5iZv8nM11bzfAY4CLg2Ij63oWCZeXxmLs7MxXPmzdvEJkqSNDKDniOnT5+xiU2UJE0mm/JN4oOABcD5wO+Av/YQ56+Zubbr8UpgdtfjpwEzgM9u6A0ycxVwQdWO1cCuPbRDkqSxZI6UJE0491okZuaRwA7AhcCnKNc/vD8iHtw120qgu3vLfUfYjhOAU4CTI2JW9xMRsUVEHFFd3/FzYCrwuMzcZ4QxJEkaU+ZISdJEtEnXJGbmDZn58czcHXguMB84MyK+UM1yPvCiiJgaEU8G9u2hLUcAlwE/iIgZABHxSko3nn2B9wIPzMy3ZeYlPby/JEljzhwpSZpoRjy6aWaem5mvo1z/0On68gbgGcAy4GDguz28bwKHAtcC34uIzSnXd2ybmQdm5g8z866Rvq8kSU0xR0qSJoKhXl+YmauBs6u/lwC7bGC+U4Gth03bruvvl3f9vQ54adesF/faPkmS2mKOlCQNshF/kyhJkiRJmrgsEiVJkiRJNYtESZIkSVLNIlGSJEmSVLNIlCRJkiTVLBIlSZIkSTWLREmSJElSref7JA6KO5bfycW/bvZWUjNmz2g0XseyG25uPOZl51zeeMwF913YeMxZf5rXeEyA6/98Y+Mx524xt/GYi7Zd1HhMgIc9bo/GY571w7Maj/nnP1zbeEyAJz3nwMZjXnTRGY3HHGRr1qzmxhv/1GjM5z/xeY3G67jssrMbj7l8+S2Nx7xt2fLGY1591UWNxwR4xmHPaDzm4kce0HjM+YsWNB4T4BGPeErjMS+8sPlj+KP326vxmAA/O/nXzQaMGNHsfpMoSZIkSapZJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqA10kRsSHIuKNbbdDkqR+Yn6UJI3GUNsN6FVEbAW8FNix7bZIktQvzI+SpNEa5G8SXw6cnJl3tN0QSZL6yMsxP0qSRmGQi8SnAKe13QhJkvqM+VGSNCqDXCTuBlx2T09ExKERsSQiltyxcnnDzZIkqVUbzI+wfo5cu3ZVg82SJA2KQS4S5wO339MTmXl8Zi7OzMUzZs5uuFmSJLVqg/kR1s+RQ0PTG2yWJGlQDHKReAswp+1GSJLUZ8yPkqRRGeQi8QJgp7YbIUlSnzE/SpJGZZCLxJOBfdtuhCRJfcb8KEkalYG9TyLwZeD8iJjhMN+SJNXMj5KkURnYbxIz8yZKIvynttsiSVK/MD9KkkZrkL9JJDPf0XYbJEnqN+ZHSdJoDOw3iZIkSZKksWeRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqA32fxE0xfcY0HrTbdo3GnLvF3EbjdVx7+bWNx9xy6y0bj/mNEz7TeMzHPfl5jccEWLFsReMxt/27bRuPedKxn208JsDSK69rPObOez+k8Zjzt5rXeEyA665c2kpcbbrNZ85k590e1mjMoUumNRqv48Of+6/GYz7+yc9vPOYFp13QeMyFC+/XeEyAay75U+Mxd37Ezo3HXHnbysZjAhz4lhc2HnOrry1qPOa3vnRy4zEBfvjNLzca7+YbbhjR/H6TKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqFomSJEmSpJpFoiRJkiSpZpEoSZIkSao1XiRGxHYRkRExVD3+UUS8rOl2SJLUb8yRkqR+MNR2AzLzKW23QZKkfmSOlCS1YdTfJHbOdkqSpPWZIyVJg6inIjEiro6It0XEBcCKiHhXRFwZEbdHxMUR8eyueadGxEcj4qaIuAp42rD3OjUiXlX9/Z6I+ErXc8O73bw8Iq6q4vxfRBzcS/slSRov5khJ0qAbzRnOgyjJ7Cbg6cBjgL8ABwJfiYgdM3Mp8Orq+T2BFcC3egkWEbOAo4FHZOZlEXE/YOEG5j0UOBRgwZZb9RJOkqTRGIgcOWv2vF7CSZImuNF0Nz06M6/JzDsy85uZeV1mrsvMrwN/AB5Zzfd84BPVvDcDHxpFzHXArhExIzOXZuZF9zRTZh6fmYszc/HsuXNHEU6SpJ4MRI7cfMasUYSTJE1UoykSr+n8EREvjYjzI2JZRCwDdgW2rJ6+f/e8wB97CZaZK4AXAK8BlkbEDyPiIb01XZKkcWWOlCQNrNEUiQkQEdsCJwBHAFtk5nzgQiCq+ZYCD+x63TYbec8VwMyux/ddL2DmjzPzicD9gEuruJIk9RtzpCRpYI3FfRJnUZLhjQARcQjlLGnHN4DXR8TWEbEA+OeNvNf5wGMjYpuImAe8vfNERCyKiGdW112sApZTutZIktSvzJGSpIEz6iIxMy8GPgacCVwP7Ab8qmuWE4AfA78Dfgt8eyPv9VPg68AFwLnA/wxr65uB64CbgX2B1462/ZIkjRdzpCRpEPU0umlmbjfs8TuBd25g3rXAm6qfjmO7nt9v2PyHA4d3Tep0l1lKSXqSJPUtc6QkadCNRXdTSZIkSdIEYZEoSZIkSapZJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKk2lDbDRhvNy29gc9/8BONxtx73yc2Gq/juYc9s/GYb3nhPzUec/+nHNh4zB332rHxmAB//sO1jcc84Pn7Nx5zxW0vaTwmwIN23a7xmB9/y782HnPZshsajwmw5OJzG4/5H+9/Q+MxB9lm04ZYtN19G435kx98tdF4HVeev2vjMQ887FmNx3ztMw9uPOZOOz2i8ZgAfzj3isZjPvxJezUe8xcnndp4TIAXvuCAxmNuddi8xmP+5L9PbTwmwO23/7XReHfdtXZE8/tNoiRJkiSpZpEoSZIkSapZJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqg10kRgRZ0fELm23Q5KkfmJ+lCSNxkAXicBHgfe13QhJkvqM+VGS1LNBLxK/DzwuIu7bdkMkSeoj5kdJUs8GukjMzDuBc4ED2m6LJEn9wvwoSRqNgS4SK5cAD+ueEBGHRsSSiFiydu3qlpolSVKr/iY/wvo5cuWK5S00S5LU7yZCkXg7ML97QmYen5mLM3Px0NC0lpolSVKr/iY/wvo5cuas2S00S5LU7yZCkTgHWNZ2IyRJ6jPmR0lSTyZCkfhQ4HdtN0KSpD5jfpQk9WSgi8SI2Bx4OPDTttsiSVK/MD9KkkZjoItE4BnAqZl5XdsNkSSpj5gfJUk9G2q7AaP0FuCVbTdCkqQ+Y36UJPVsoIvEzNy77TZIktRvzI+SpNEY9O6mkiRJkqQxZJEoSZIkSapZJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqDfQtMDbFfbe5P0cd8/5GY668bUWj8TqWnHpe4zE3G5rWeMzMbDzmlg/YsvGYAN849guNx5y9YE7jMW/5yy2NxwS45DcXNx5z2rQZjcf82H9/pfGYAMcc941W4mrTZSZrVq1pNOYOO+zZaLyORdstajzmeWdd1HjMQ448qvGY02dMbzwmwA++2PwxZqsHbtV4zCVLTmk8JsCF1x7YeMz/u/DqxmP+/sxzG48J8OhHP7fReKed9vURze83iZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqFomSJEmSpJpFoiRJkiSpZpEoSZIkSapZJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKk2IYvEiDg0IpZExJLbli1ruzmSJPWN7hy5csXytpsjSepDE7JIzMzjM3NxZi6eO39+282RJKlvdOfImbNmt90cSVIfmpBFoiRJkiSpNxaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqFomSJEmSpJpFoiRJkiSpZpEoSZIkSapZJEqSJEmSakNtN2C83fjnGzjhnZ9qNObWD9qx0Xgdb37PqxqPedYpv2o85hUXXdR4zJv+fGPjMQEeuuvixmO+7YgXNx7zo589qfGYAHvsv0fjMX94wprGYx7/zqMbjwnw3MMPbiWuNt2aVWtYeuV1jcacM3dho/E67vug+zYe88rzrmg85pShqY3HXLf2rsZjAjxiv8c0HnPqZs3/fx/84Ic3HhPg+j/d0HjM22++vfGYU6e0Uw7dfvvNjcZbt27tiOb3m0RJkiRJUs0iUZIkSZJUs0iUJEmSJNUsEiVJkiRJNYtESZIkSVLNIlGSJEmSVLNIlCRJkiTVLBIlSZIkSTWLREmSJElSzSJRkiRJklSzSJQkSZIk1SwSJUmSJEk1i0RJkiRJUm2gi8SI+HREfPoeph8aEUsiYsmaNavaaJokSa3ZUH6snqtz5J13rmy6aZKkATDUdgNGIzMP28D044HjAebMWZiNNkqSpJZtKD9Wz9U5cost72eOlCT9jYH+JlGSJEmSNLYsEiVJkiRJNYtESZIkSVJtoIvEiPhsRHy27XZIktRPzI+SpNEY9IFrXtN2GyRJ6jfmR0nSaAz0N4mSJEmSpLFlkShJkiRJqlkkSpIkSZJqFomSJEmSpJpFoiRJkiSpZpEoSZIkSapZJEqSJEmSahaJkiRJkqTaUNsNGG8zZ89iz8fs02zQiGbjVQ574esaj7n4sfs2HnPZDcsaj7nNQ7dpPCbAH5Zc3njMT37hvxuPOW+reY3HBPj5137eeMztd3tw4zGfcOCrGo8J8P3P/6iVuNp0a9es5eYbb2o05vTpMxuNV8tsPOQDW8gd3z/hm43HvO3WZrehjpe97YjGY65ZtbrxmAu2WNR4TIDLzrms8Zg7PXynxmOuvWtN4zEB9tq32frk4kt/OaL5/SZRkiRJklSzSJQkSZIk1SwSJUmSJEk1i0RJkiRJUs0iUZIkSZJUs0iUJEmSJNUsEiVJkiRJNYtESZIkSVLNIlGSJEmSVLNIlCRJkiTVLBIlSZIkSTWLREmSJElSzSJRkiRJklSzSJQkSZIk1SZkkRgRh0bEkohYcsfKFW03R5KkvtGdI1evvrPt5kiS+tCELBIz8/jMXJyZi2fMnNV2cyRJ6hvdOXLatM3bbo4kqQ9NyCJRkiRJktQbi0RJkiRJUs0iUZIkSZJUs0iUJEmSJNUsEiVJkiRJNYtESZIkSVLNIlGSJEmSVLNIlCRJkiTVLBIlSZIkSTWLREmSJElSzSJRkiRJklSzSJQkSZIk1YbabsB4iwimbtbsYu6wxw6Nxuu48ZobG4+59Mqljcc8+6z/aTzmM7Z8ZeMxAV7znkMaj3n9slsbj3nsWz/aeEyAQ/7lsMZj/uAz32885m/mz248JsCdK+5sJa423dSpU5k1a06jMWcvaDZexwW//H3jMXd51C6Nx5w+bUbjMecvWNR4TIClV13XeMxrLr2m8Zg7PXynxmMCvO11L2485qdO/FbjMdeuXd14TIBf/egnjcZbftttI5rfbxIlSZIkSTWLREmSJElSzSJRkiRJklSzSJQkSZIk1SwSJUmSJEk1i0RJkiRJUs0iUZIkSZJUs0iUJEmSJNUsEiVJkiRJNYtESZIkSVLNIlGSJEmSVGukSIyIUyPiVU3EkiRpUJgfJUn9aEyKxIgYGov3aev9JUkaD+ZHSdIg6rlIjIirI+JtEXEBsCIi/iEifh0RyyLidxGxXzXfB4HHAMdExPKIOCYitouI7E5u3WdTI+LlEfGriPiPiPgr8J6I+FJEHBsRP4yI2yPirIjYYVRLL0nSGDM/SpIG3Wi/STwIeBqwPfA94APAQuAtwLciYqvMfCdwOnBEZs7OzCM28b33Bq4CFgEfrKa9EHgvsAC4omv6eiLi0IhYEhFLVq5c3tuSSZLUu77Mj7B+jly1auXIl0ySNOGNtkg8OjOvAV4MnJyZJ2fmusz8KbAEeOoo3vu6zPxUZq7NzDuqad/JzLMzcy3wVWCPe3phZh6fmYszc/HMmbNH0QRJknrSl/kR1s+R06fPHEUzJEkT1WiLxGuq39sCB1ZdaZZFxDLgH4D7jcF7d/tL198rAStASVI/Mj9KkgbWaC94z+r3NcB/Zuar72W+jhXV75nAbdXf972X10iSNCjMj5KkgTVWt8D4CvCMiDggIqZGxOYRsV9EbF09fz3lugwAMvNG4M/Ai6v5XwF4kb0kaaIxP0qSBs6YFInVdRfPBN4B3Eg5c3pU1/t/EnheRNwSEUdX015dzfNXYBfg12PRFkmS+oX5UZI0iHrubpqZ2w17fBaw7wbmPRPYadi0HwEP2sD8XwK+NGzay4c9PhXYGkmS+oj5UZI06Maqu6kkSZIkaQKwSJQkSZIk1SwSJUmSJEk1i0RJkiRJUs0iUZIkSZJUs0iUJEmSJNUsEiVJkiRJtZ7vkzgo5i2Yw1Oe97hGY04bauff+r+3/2/jMSMaD8mChfdrPOajnvmoxmMCnP6zcxqPOX+r+Y3HXLRou8ZjApx8/MmNx5w2bVrjMX/8jW81HhPgCc99VitxtenWrFnN9df/qdGYZ5xxbqPxOg5713saj7nFA7ZoPObqNasaj3nzzdc1HhPgsU/9+8Zj/t9Dtmk85jeP/krjMQHOeVrzn3222/UebxE7rnbcZdfGYwKc+uNmc/OaNatHNL/fJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmoWiZIkSZKkmkWiJEmSJKlmkShJkiRJqlkkSpIkSZJqFomSJEmSpNrAFokR8ZiIuKztdkiS1E/Mj5Kk0RpquwG9yszTgZ3bbockSf3E/ChJGq2B/SZRkiRJkjT2+r5IjIirI+LtEXFxRNwSEV+MiM0jYr+IuLbt9kmS1AbzoyRpvPR9kVg5GDgA2AHYCXjXxmaOiEMjYklELFl2yy1NtE+SpDaMKD/C+jlyzZpV490+SdIAGpQi8ZjMvCYzbwY+CBy0sZkz8/jMXJyZi+cvWNBMCyVJat6I8iOsnyM322z6+LdQkjRwBqVIvKbr7z8C92+rIZIk9RHzoyRpzA1KkfjArr+3Aa5rqyGSJPUR86MkacwNSpF4eERsHRELgXcCX2+7QZIk9QHzoyRpzA1Kkfg14CfAVcCVwAfabY4kSX3B/ChJGnNDbTdgE52TmR8aNu1UYOsW2iJJUr8wP0qSxtygfJMoSZIkSWqARaIkSZIkqdb33U0zc7u22yBJUr8xP0qSxovfJEqSJEmSahaJkiRJkqSaRaIkSZIkqWaRKEmSJEmqWSRKkiRJkmp9P7rpaN10/c188d9PajTmK956UKPxOmYvmN14zEsuWNJ4zN33+ofGY954zY2NxwSYPmN64zGnDjV/7ujmv17XeEyAHXbZpfGYF593buMxt95658ZjAhx08FMbj/mRdzQecqDNmDWT3fZ+RKMxd9/nkY3G65i7xdzGY37vmP/P3p2H2VVVCRt/VxISkhAIEKQFBGV0RLRpRbs/URxwwAFtcQCcWnHAVhBxHlocWtvGEUFAEBS10XbAGW0HBEUBQREQJwRRUEAIQkjItL4/9r4nNyUJqapb59Sten/PU0/VHdc+dYZ117777HNG6zGf/soDW4+5euWq1mMCnPLuT7cec78XP6H1mFdf/cvWYwL81+FHtx5z0823bD3mL37+g9ZjAhx61Ftajff+N79mVM/3m0RJkiRJUsMiUZIkSZLUsEiUJEmSJDUsEiVJkiRJDYtESZIkSVLDIlGSJEmS1LBIlCRJkiQ1LBIlSZIkSQ2LREmSJElSwyJRkiRJktQY2iIxIp4XEQ/vuh2SJE0m5kdJ0njN6roBoxURLwauW3Oz3M7ML3bYLEmSOmV+lCQNyjB+k3gysBPwSuBdwErgjE5bJElS98yPkqSBGMYiESCBqL9X19+NiDgkIi6IiAuWLbuti/ZJktSF9eZHWDtHLr1tSdvtkyQNgWEsEl8A/B74APBGYA7wlP4nZOYJmblnZu658cbzOmiiJEmtu9P8CGvnyLnz5rfcREnSMBi6cxIz83goJ+aXm/nRblskSVL3zI+SpEEZuiKxJzNP6boNkiRNNuZHSdJ4DeNwU0mSLF5C+QAAIABJREFUJEnSBLFIlCRJkiQ1LBIlSZIkSQ2LREmSJElSwyJRkiRJktSwSJQkSZIkNSwSJUmSJEkNi0RJkiRJUsMiUZIkSZLUsEiUJEmSJDUsEiVJkiRJjVldN2CibbpoM/Z9wb6txtzn3vdpNV7PlxZt1nrMuXM3aT3meT86s/WY73jvK1uPCXDGd37Ueswrfn5F6zF3vOe9Wo8JcPH557Yec/789vfTM888ufWYAI+/+PGdxNWGW75sBX/89dWtxly29NZW4/Vss/M2rcd89bte3HrMj73/9NZj/uUPf249JsCu/7hb6zH/8Mt29xeAIFqPCfDct76w9Zj32Pourcd81+FLWo8JcMRBT+sk7obym0RJkiRJUsMiUZIkSZLUsEiUJEmSJDUsEiVJkiRJDYtESZIkSVLDIlGSJEmS1LBIlCRJkiQ1LBIlSZIkSQ2LREmSJElSwyJRkiRJktRovUiMiLtHREbErHr7GxHx3LbbIUnSZGOOlCRNBrO6bkBmPq7rNkiSNBmZIyVJXRj3N4m93k5JkrQ2c6QkaRiNqUiMiCsj4rURcTGwJCLeFBG/i4hbIuKyiNi/77kzI+K/I+KGiLgCeMKI9/p+RLyw/v0fEXFa32Mjh908LyKuqHF+HxEHjqX9kiRNFHOkJGnYjaeH81mUZHYDsB/w/4A/A08HTouInTPzWuBF9fEHAEuAz48lWETMBz4E/FNm/ioi7gpssY7nHgIcArDl1luPJZwkSeMxFDly7twFYwknSZrixjPc9EOZeXVmLs3Mz2XmNZm5OjNPB34DPKg+7wDgA/W5NwL/OY6Yq4H7RsTczLw2My+9oydl5gmZuWdm7rlg4cJxhJMkaUyGIkfOnj13HOEkSVPVeIrEq3t/RMRzIuJnEbE4IhYD9wUW1Ye36X8ucNVYgmXmEuAZwEuAayPiaxFxz7E1XZKkCWWOlCQNrfEUiQkQETsAJwIvB7bMzIXAJUDU510L3K3vdduv5z2XAPP6bv/DWgEzz8zMRwN3BS6vcSVJmmzMkZKkoTWI6yTOpyTD6wEi4vmUXtKezwKviIjtImJz4HXrea+fAQ+LiO0jYjPg9b0HImLriHhyPe/iduBWytAaSZImK3OkJGnojLtIzMzLgKOBc4G/APcDftj3lBOBM4GfAxcCX1jPe30bOB24GPgp8NURbX0VcA1wI7A38NLxtl+SpIlijpQkDaMxzW6amXcfcfuNwBvX8dyVwOH1p+cjfY8/fMTzDwUO7burN1zmWkrSkyRp0jJHSpKG3SCGm0qSJEmSpgiLREmSJElSwyJRkiRJktSwSJQkSZIkNSwSJUmSJEkNi0RJkiRJUsMiUZIkSZLUGNN1EofJLX/9G9/55HdajTlv7satxutZ8rclrce86aa/tB7z4Fe+ovWYnzj9G63HBFh83eLWY26z87atx7zlpltbjwnw4Efs03rMs77xldZjPueQN7QeE2D16uwkrjZcBMyYMbPVmHPmzGs1Xs+mWyxoPeaHj/p46zGf8JL9Wo958VkXtx4TYNmSZa3H3GaXbVqPue12u7YeE+DY1x7desxd77N76zF32/PerccEWL78Ba3G+/GPzxjV8/0mUZIkSZLUsEiUJEmSJDUsEiVJkiRJDYtESZIkSVLDIlGSJEmS1LBIlCRJkiQ1LBIlSZIkSQ2LREmSJElSwyJRkiRJktSwSJQkSZIkNSwSJUmSJEmNoS0SI+J5EfHwrtshSdJkYn6UJI3XrK4bMFoR8WLgujU3y+3M/GKHzZIkqVPmR0nSoAzjN4knAzsBrwTeBawEzui0RZIkdc/8KEkaiGEsEgESiPp7df3diIhDIuKCiLhg2bLbumifJEldWG9+hLVz5O23L227fZKkITCMReILgN8DHwDeCMwBntL/hMw8ITP3zMw9N954XgdNlCSpdXeaH2HtHDlnztyWmyhJGgZDd05iZh4P5cT8cjM/2m2LJEnqnvlRkjQoQ1ck9mTmKV23QZKkycb8KEkar2EcbipJkiRJmiAWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqTGrK4bMNHmb7YJez1xr1Zj7rfHHq3G6/n27O+0HnPOnHmtxzz9uBNaj3nOeWe2HhPg5C9+s/WYl//k8tZj7rj7PVqPCfCFEz/ZesyNN57feswTPvSG1mMCfOqAH3YSV6MTEa3GW7Fyeavxem78802txzzoiGe0HvPLp3yj9ZhXXn5F6zEBdv+X9j9vXX/19a3HvOH6P7YeE+BFbz6y9Zi73bv9zwOnHX166zEBfvjDz7cab+nSW0f1fL9JlCRJkiQ1LBIlSZIkSQ2LREmSJElSwyJRkiRJktSwSJQkSZIkNSwSJUmSJEkNi0RJkiRJUsMiUZIkSZLUsEiUJEmSJDUsEiVJkiRJDYtESZIkSVJjqIrEiJgTESdFxFURcUtE/CwiHtd1uyRJ6pL5UZI0SENVJAKzgKuBvYHNgDcBn42Iu3fYJkmSumZ+lCQNzKyuGzAambkE+I++u74aEb8H/hG4sos2SZLUNfOjJGmQhu2bxLVExNbArsClI+4/JCIuiIgLbv3bzd00TpKkjqwrP9bHmhx5++1L22+cJGnSG9oiMSI2Aj4FnJqZl/c/lpknZOaembnnJptu1k0DJUnqwPryI6ydI+fMmdt+AyVJk95QFokRMQP4JLAceHnHzZEkaVIwP0qSBmGozkkEiIgATgK2Bh6fmSs6bpIkSZ0zP0qSBmXoikTgOOBewKMy05MpJEkqzI+SpIEYquGmEbED8GJgD+DPEXFr/Tmw46ZJktQZ86MkaZCG6pvEzLwKiK7bIUnSZGJ+lCQN0lB9kyhJkiRJmlgWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWrM6roBE+26P13Dh1/39lZjPuA+O7car+fm629uPeYf//ir1mO+65Mfaz3m4Ye9t/WYAA/d/6Gtx5y/6bzWY96+dHnrMQEe/IhHth7z8588tvWYr3/38a3HBNhhq0WdxNWGW716NcuWLWk15t12uXur8XpmzGi/X/zMz3639Zh7Pfkhrce82722bz0mwC9//MvWYy7atv3j2j123L31mABnnPC51mPu+Yj2P/cs+Vu7x8Cevfd+Zqvxzjnn86N6vt8kSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKkxkCIxIrYexPu0/d6SJE0k86MkaRiNuUiMiIUR8dKIOA84pd63TUR8PiKuj4jfR8Qr+p4/JyI+EBHX1J8PRMSc+tiiiPhqRCyOiBsj4uyI6LXtlIg4LyJeEhELx7GskiRNOPOjJGnYjapIjIgZEfGYiPgMcBXwGOCdwJNq0voK8HNgW+CRwGERsW99+RuBvYA9gPsDDwLeVB87AvgjsBWwNfAGIOtjTwLeBewLXBURn46IR/clyTtq5yERcUFEXLBq5YrRLKIkSaM2LPmxtrXJkcuXLxvA0kuSppoNLhIj4uXAlcC7gXOBnTJz/8w8IzNXAP8EbJWZR2Xm8sy8AjgReGZ9iwOBozLzusy8HngbcHB9bAVwV2CHzFyRmWdnZgLU21/KzP2BnYAfA+8Brqxt+juZeUJm7pmZe86ctdFo/h+SJI3KMOXH+romR86evfFg/xmSpClhNN8k3gPYHPgZpTf0ryMe3wHYpg6JWRwRiyk9nr1zJrah9K72XFXvA3gv8FvgWxFxRUS8bh1t+CtwcW3D5rVNkiR1yfwoSZpSNrhIzMwjKD2VlwAfBn4fEW+PiF3qU64Gfp+ZC/t+FmTm4+vj11ASZc/29T4y85bMPCIzd6QMn3lVRDyy98SI2CUi3g78Hvgg8Atgx9omSZI6Y36UJE01ozonsQ6FeV9m7g48DVgInBsRJwPnAbdExGsjYm5EzIyI+0bEP9WXfwZ4U0RsFRGLgLcApwFExH4RsXNEBHAzsApYXR87mTJ8ZyHw1My8f2a+vw7JkSSpc+ZHSdJUMmusL8zMnwI/jYgjgD0yc1VE7AccTenRnAP8ijUn378D2JQyHAbgc/U+gF2AYygn5t8EHJuZ36uPfRR4SWYuH2tbJUlqi/lRkjTsxlwk9tTkdF79+xrgWet43jLgFfVn5GPvB96/jtedN942SpLUNvOjJGlYjfk6iZIkSZKkqcciUZIkSZLUsEiUJEmSJDUsEiVJkiRJDYtESZIkSVLDIlGSJEmS1LBIlCRJkiQ1LBIlSZIkSY3IzK7bMKEi4nrgqjG+fBFwwwCbM1ljdhXXmFMvrjGnXtxhi7lDZm41yMZMZeZIY06CuMacenGnS8yu4o415qjy45QvEscjIi7IzD2nesyu4hpz6sU15tSLO11iavSmy7YxXWJ2FdeYUy/udInZVdy2YjrcVJIkSZLUsEiUJEmSJDUsEtfvhGkSs6u4xpx6cY059eJOl5gavemybUyXmF3FNebUiztdYnYVt5WYnpMoSZIkSWr4TaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomSJEmSpIZFoiRJkiSpYZEoSZIkSWpYJEqSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIaFomStB4REXf0tyRJ0505cuqySJSkdYiIWZmZvb+BBR03SZKkScEcObVFXbeSpD4RMSMzV0fEDOB/KZ1qC4BPZOap3bZOkqTumCOnvlldN0CSJqOa/AL4LnA18D5ge+CLEXFDZn6t0wZKktQRc+TUZ5EoSet2P2B1Zh4MEBHPAS4FvhkR8zNzSaetkySpO+bIKcxzEiWpioiZI+5aCsyKiE0j4lTgkcCembkKOCIidmy9kZIkdcAcOb1YJEoSJfll5qqImBERh0XErsBNwBzgLGA34IGZeXtEHAY8HritwyZLktQKc+T0Y5EoSUAv+QE/Ax4AzMzMG4DXAjsBXwYeGxGvBt4MvCQz/9xZgyVJaok5cvpxdlNJqiLiWGBRZh4w4v69gWcAC4GbgWMz8xcdNFGSpE6YI6cXJ66RpDXmUabyJiLmACuAzMyzKMNpiIjZmbm8uyZKktQJc+Q04nBTSdNSHTYz0lbA/gCZeTswIzMzIl5Uz7+AkhQlSZqyzJGySJQ07dQT8FdHsWNE3KM+9G5gUUS8DiAzV0bES4HDgFvqfY7RlyRNWeZIgeckSppmImJGTX4zgJ8As4ElwGcy88MR8SLgucAi4Hzg4cCTM/PCrtosSVIbzJHqsUiUNG30kl/9+4PARsD7gYcBrweOy8yjI2Jz4DnAb4FfZuYVXbVZkqQ2mCPVz4lrJE0bfcnvSGAPyhTdv4mIP1Gu93R0RGycme8EPthhUyVJapU5Uv08J1HStBIRm1Ku6XRPypTdZOZtwNeBw4EjI+I13bVQkqRumCPV43BTSVNaRMzKzJX175n1gsCbUIbO3Bv4IvDJOkPbxsCjgMsz87fdtVqSpIlnjtS6WCRKmrL6Et4M4L3AXYALgTMp51K8HdgR+DJwmrOySZKmC3Ok1sfhppKmrL7kdy6wHfA94H7ASZThNP8J/A44mDqsRpKk6cAcqfWxSJQ05Yy4CPC+wPWZ+YzMPBnYAlgJ/DYzF1OS4I+Bc9pvqSRJ7TJHakNYJEqaUvouAjwzIhYBW1Fnco6IUym9o/tk5oqI2D8zbwbempl/7LDZkiRNOHOkNpRFoqQpo17jaVVEBPArygV/zwYWRMS5lNna7l+T3xuAf4uITT3PQpI01ZkjNRoWiZKmjN41noADge9m5tHAtcDXgK2BU2sP6qsoU3m/ITP/1k1rJUlqjzlSozGr6wZI0iBFxFGU3tFL6rCaZRHxKeA64NCIeDwwH3hUZl7cZVslSWqTOVIbyktgSBpqdfjM6r7bi4D3UK7v9BbgO73H6zWeApiZmbd20V5JktpijtRYWSRKGlq9iwDX8yu2AxZk5mURsQA4njJa4qPA9+qFgMNzKyRJ04E5UuNhkSitw8iDpQfPyWXERYB/CCwGHkxJeJ8GrqJc62klcCrwLdefJI2f+XHyM0dqvJy4RroDtfct69/zImJO7WWb2XXbprOI+MeIOLbe7A2f+QJwZWY+DvgX4BDg6Zl5C/BiYHPKRYDntt1eSZpqzI+TlzlSg+TENdIIdfz+ytr79h1gCTA3Ig7KzGtHju9XOyJiK+BzwHEAfT2eAbys/n0oZaa2oyJi88y8KSKeDczLzNvabrMkTSXmx8nLHKlB85tEqc+IBHc8Zbavj9TfP4+IHer00O477bsrsCIz3wsQEc+IiFnALsC+EfFR4J+BB2XmKuCIiHhUZt6UmX/qrtmSNPzMj5OeOVID5Y4s9emb4eu1wFbAszLzG5n5LODrwE8jYnsTYfvqVNwXR8SPIuJSYI/MXAmcALwe2Dcz98jMpRFxKPBs4HcdNlmSpgzz4+RmjtSgOXGNNEJEPAB4E/A44IDM/GrfYx8DXgDskJlXd9TEaac3KUJE7ARcDtyUmXepj+0O/DuwAPgzcCtlHT0hMy/qqs2SNNWYHycnc6QmguckatrrzQDWu52ZF0XEWynnWjw/Im7IzB/Xx14YEbfjCd6tGTHEaVfKrGzzIuIc4ImZeXFEvBfYBng6cA2wT2Ze3k2LJWlqMD9OfuZITRS/SdS0NmKK6OdThtCcA1wEbAscCWwKvC8zf9JdS6en3jWe6t+bZubf6t93BT4GbAE8ps7SJkkaEPPj5GeO1ESySNS01N87WhPgT4ErgC0pQzGWUGYBuwtlmMbdgTdn5gWdNHgaq9Oqf43yAeV7wKcz88KI2AE4BtiMMmzGJDjN9H2I9Rpt0oCYH4eLOVJ3ZBD50ROLx6l3cnZEzO67L7prkdYnInYB6B8+AxwO/CUzn5aZDwfeAywD3pKZlwH/A/ySMm20WjBi0oPjgRuANwC7AS+LiH0y8yrKBxWAz7nfTT81AS4EDoyIu3fcHI1gfhwu5sfhYY7UnRlEfvScxPHbKCLuAhwWEZdl5kn2aE9O9aB6XESckpmn9T20Gri695zMPLsO1TgyIrbIzLMi4rzMXNpFuwepf2jKiPsnzTcxI4bPbEk5Cf/UzLw+Iq6izNJ2cESszszv12s8TZr2qx0RsTewM/By4P6UD7Mf7LRRGsn8OCTMj4U5UlPBoPKjw03Hoe549wH2AR4MfDwz/63bVml9ImJ2Zi7vP9E7Ig4B3gvcMzOvrfdtBPwQeH5mXtpdiwent8z1w8CHKT2Pf8zME+vjnSeRvhnaZgLfBVZQ9q8nAd+oPWP3pJwLsxnwwcw8u7sWq20R8XBgP8o28UVgR8pEGc/MzFs7bJr6mB+Hz3TOj2CO1PAbdH50uOkoRcTMiHh5RBwHvA/4I/A54CTgHfU5fqU/SfSvi3pwXV5vfjgi/gCQmScAXwHOjoh7R8QC4LmU6aL/0nabJ0Jf8gtKYrk35cK7h0bE0QA18XS27dY29hLwW4EbgdcBP6Gc97Jrfc7llH3vOuC3nTR2mhu5nbSx3UTE1hHxTeAwyrlQT83M1wI/oJwztSy8NlunzI/Dxfy4hjlSgzKV8qPfJI5CRGwKfApYBZwL/E9mXhURBwFPAQ7NzClx0JwMPWaDFBG7ZOZv6t+PBn5GSXwzMvNBdSc+kdL7cgll5rZnZeaFXbV5UPrXZUS8BHhAZr44IjYGHgIcC3wzMw8f+fwu2gp8GfgT8M7MvLre93+UHtPDgF/XZL5RZq7oop3T2cjhWG1tLxGxHWX69s8AN2e5IPQ/AWcAz87M7090G7Ru5sfhNZ3zI5gjNThTLT9aJI5SRDw0M3/U1+t0T+AbwJGZ+b9dt28QYu3x7mtt4MOYHCPiZcDLgBcBHwc+m5lviYjNKAfW1Zn54PrcPSm9c7dl5p+7avOgxJrZrWZRksez60MPy8xbo0wo8TBKr+NPMvNFHbSx/xpPRMQZwBOBR2TmWfW+WZTZ2zYDnpOZvx7GbXHYxdrDsT4JLKf0th8xUcPO6geg7bLv4tz1vpnAWygfZN/k9tA98+PwbYPTOT+COVKDMxXzo0NzNkBEzIiIFwFk5o/q3b3/3X2Br1Oq9aFXD5gr6zIfA5weEa+PiMdCGW7RcRNHLTOPBS6jJLyrMvMt9f6bgUdT9qnexYAvyMwrpkICrAesVfWA8UXK0JPPUqYvPygiNq7Di35AGbKye0Rs3XY7e0N8ImL/evvJlBnzPt1rT/1Qth9leNOyet/QbYvDrCaZ3nCsc4GNKMMILwYuioi9JiDmDMq5T2+NiLl97UhgNmX/vQTcHrpifjQ/DitzpAZlquZHi8Q7EeXk4J8AT41yzRmg2SEBXg3cMFW+0u87YJ4DLKQMa5gPfCgiHtZp40aprrueXwNXAnMi4v4RMQcgMxdTdqTNIuJ77bdy4vQdsF4G/DUzPwH8N+U6So8GnhcRc2oS/DalV7Kr4WAHAq+OiJfWtj+bcqC9qC8JrsjMJ2fmHzpq47QTEdtGxOPrh6VekvknyvZ0QGaeU++7HDiv73XjPgejJsDzgN8AL806e2JfO55HOfb+z3hjaWzMj+bHYWaO1HhMh/xokXjnvglcmpmPy3J+xaKImFN7Eu8H/Coz3wrDfUJ+rH1C66OAJZl5UJapsO8JXA9RuN5RAAAgAElEQVScExHzO2ngKPUNIZkREc8CPpOZ9wGuoZxfsHtfklwI/D/KTjXVvBF4E3A2NB/e3gVcSpkR7aVRZrRbkZm3tdWoER9QoCTlrwCPjYhDa1v/ldKD+4eI2Kqttmktr6RsQ4/pfXCk9FBuGxFzI+JU4LGUxEhEvLp+qBpED/ajgcWZ+dzMXBERR0TEhyLiZVFmV/wspXd/5PFL7TE/mh+HnTlSYzXl86OJdT2ijMm/GfhovX0M8GnKsIyHZuYvKBvIUJ6L0FMTxuq+g9JcygnQRMQnKBdnfXiWMfFPjHJdnkmrrotVdce4CHga0OtleTZlxr33AQ+OiNcCJwArslx4dqjdQWL5OSXxP7d3R2YuoyTBq4EHAvNaa+CaNqyqw2d2rtvfn4BTgB8D+0aZPIDMfCZlWM3CttsoyMzXABcCLwEeVxPhlcAfKN+i7J6Zu2fm7ZTrMT0V2HRA4a+jzMj2noj4HHAQsBg4Gtg3M2/Iep5H9p2vo3aYH82Pw8gcqUGZDvnRiWvWI8psbR+inHi6EtgSeAHlgpRXZgcnMA9a7ZG6Dvg8ZaN+J+WA+V3KCeorKCdwr4yI1wEPp1xvZXE3Ld5w9UPLwsw8qN7un8HsVGBrSi/w0zLzp921dLBqj/2/A9/OzF9GxD6UD2tXAYfkmkkX5gCbZub1bbatbx38J/B44DnAJTUpbk3p/XoEcGJmfqSttmlttfd8ef37GGAn4LjM/HJE/DtlCvYjKR+y9qZsY4/MzJ+PM+6mlOPt7cChlOPvKuBttcf0VOAHmXnSeOJofMyP5sdhZY7UeE2X/DhrEG8yldSDx78At1J6BN5AuRDwLOALdSf9FuV6NEM5vXBELMzMxRGxENgd2Bx4D3BuZp5bn/Nu4D8o4/PnRZmY4AjgUUOSAGdSpun+Qr09qybymZTZ2p4bEdtThg39tcu2ToB7Umaqu0dEHJeZ363L/Urg+Ih4SR06cztlmFQr+tZBUBLv66PMfvjfwJERcWlm/iUivkE5AX/PiNgiM29sq40q6rpaXoetzM3Ml0fEhynXDFuVmR+OiNuBB1HOlbmecSbA+s3G5yjHoxXA2ZnZu7Zeb9s5HHgC8PbxLaHGwvxofpwizJEas2mVHzPTn/pDGX57LuWk9J9SZgV6ZN/jsyg9OIspXyN33uZRLl/UDeyvwH3rff9ASfbXAvv1PfculK/Gf06Z9esbk3mZKdP8jrzvY8DbgNm95a+/nwFs0XWbB7jsM+/gvgdRers/COxS73sU5byLj7Tcluitn7qP/QB4DbBxve+rwLeAh9TbB1GGOG3Z9f92Ov7cwbo6Ephf7/tIXVdP6Hv+XGDOOGMGZWKIj1GKjmcDv6Ncaw9gV0riuwZ4YNf/o+n4Y340Pw7rz2TJkevKj/3ryBw5uX+mW37s/B8+mX6A44FT6t87UXoGl1K+1p9FmantfMqFVjtv7ziWs5cAZ1KGCD0f+C/K+SQHj3jurPp7k67bvZ7l6bUxKD2Ec+rt51Nmf3psL+kBrwB+C2zddbsHtOy9BBPAG0c8tlc9iB0P7FDvezhwtxbWwz9TTtbetO++AH5Ut7MZwEZ9r/0sZZbEH1HOc7pv1//b6fxzB+tqVt9jH6Fcj+sZvQ8xA4i3I6UA2bLvvt2AX1B6YjcC/hW4R9f/m+n6Y340Pw7jz2TJkXeWH/seM0dO8p/plB8dbrq2hcD3699XZObR9eT8QzLzexHxReATmXldZy0chzqEYWZmXlLv+j7wycw8ISK2oAyfeUJErMzMz0TEM4E5wKmU6wZNOnX8fm+YzNmUpH5tRHw4Mz8eETsCrwfmR8RllBmhnpDdTWM9ML3hXHUYwrbA2yPiHpn5QoDM/HFEvJFynbK5EfGOzPz+BLWltx561+0BuAXYJSKelJm/iIg9gJuzTI5ARGTUWfYy84CI2BfYArggM38zEe0cpBhxgeNh11sX9eb9+ft1NSMzV2fmoRFxMiUpfW1A4W+nJN7dge/VY9UVwM8oiW8FMCUuxj7EzI/mx6EyWXLkneTHp+SaYYh3dNwdyhxpfpwa+dHZTYGI6M1cdTNwN1jrWiO/Bjar9/1uWBNg1TtQzY6InSnDFY6JiOdnGdP+TuDPwIF1zPuHgAtgcl6Ute6UvXa9lXK9mH+m9K4cFBEvyMw3A4dRene+SZl178JOGjxAEfFyyuxzGwGnAYuA+wH7RcTHe8/LzLOB71Bm1LppotrTtx6Oo0x7/xBKD/XmlHMp9gJW1zbvWJ/bu5DxoojYITPPzMzPDEHy2y4iFk2xBNhbF7PXs65W13W1dWa+AHh5Zt46zrhz65/XUmaEO6IWHtTEt5gypfhQX0JhmJkfzY/DaDLlyDvKj5n5GEp+PPxOjrtDlSPNj1MrP07rbxJrr84JlK/xvwV8CfhMRPwW+FJNDJsBqyNifmZOyt7CDdE7sbXePB+4ODMPrgfQkyKC2rP4Dspwi/sCr846he4klXXH+ArlA8x/ZeYNEXEEpXf0KXUdn5aZF3XZ0EGKiE2AfSkzZj2A0qt4UX3sUcB3IuI04LXA0ymTTLwqJ3iGttpbvRVwbETMAk6inM+zO2Vo2qso13raJyJuyMy/1Zc+n9KT/c6c5BNdRMR9KOcfvQg4s+PmjFvdP2b0HRvOo5xndQTrXlebRcRbx/NtQ437CWBRRFxJ+Z8+m3Js+hRwaUTcVu/7Z5icH8SnMvOj+XFYTcYc2ZcfP1L/76dQ8uMLKcfciygF+9DmSPPj1MuP07ZIjDXXCLoSOL/2FHw9Il5KuT7OcyLiJuAhwGOHOQFCuUBsXeanUaZ9fnW9/+TaAXFSRKzOzFMpX1tP2qFdfcMvetNEL6bsLF8Dfp5l1ql3USZReFZ9zknQ7QfNOuRkXPHre9waEc+lHKxmUK6LA0BmXlJ7ur5JmbZ9e8qECwPv4b+D4STbUz6MbELpMd0DeDflOlO3U5J277pcO0TE+cAulBkS957MyQ+aY8ZrgDMz88x6e6MsM+ANlYjYNjP/VNff6ros/0o5NhxZn7O+dbVqXe+9AbGDMpTvSso3HP9MuYD3gcBDKfvtP1B62ffOzMvHGktjY340P3ZhKuXIO8iPsyizUi6gnAN5f8rkOU8F/gZ8vxbxQ5kjzY9TND/mJDgJtIsfytCRT/Td3hfYhzJr2Q6Uk06fD+zYdVsHuMwHU74mv4zSAzyLNSdMP68+9syu27mByxLAC/tuf5QyzfAefffNpvQUbtdB+/5uFrMBvGf/rFo7UC7O+gng9Lr99p88PQPYDthqwG3onXw/t+++HSmJ73RKcbgC+CXl2k6rKUMlrgZ2rs8/BDiRchL+F4D7d709jWL5/53Sq7cH8Blgr67bNIZl6K2rx/Td96y6ri6hb2bDiVhXlJ79b/fd/nR9/zn9+03/9uxP69uI+dH8ONFtnHI5cl35sf5eQOl4WVnz48Z9x93lwD/2vWYoc6T5cerlx85XSAcbwJb195so1xzZum7MvwD+j/IV8lSc2et/KL0ej64b+1Pr/TP6nnsgcK+u23wHy/B3M0QBj6nJ/Ki++04GbuhPhB21d2bvf0spmj5KGVqyM32zlY3yPftnRtueOotVPXB8qm7Lj6z37U+5APKgl2trysx3u/XFPofSW3secEC9/411fzqWMllCAkfcwfvNo06/Piw/lBnFPkb5wPWdrtszxmWYzZoPLtF3/4vrsWH/iVhXlEkzgjKj4Pn1vpPqtrJRvf1CYPuRbfOntW3D/Gh+bKPNUy5H3kl+/AllmPKOI/LjiZTzICfsuNvyejU/jj3upMyP03HimtMjYn/KAWNXyjkXsylD4t5I+dp/6NXx72TdmihDTY6h9IQcAnw2yqxava/SycxPZeYvO2nwOkTE7sB7ImKbEQ9dQBn29LB6nghZThb+InBhRNyv3ZYWdajLqjpk4KeUcxB+BNydMsTkkb3njfI9e8OhzqVssz+NiPcA96IcvFYCr4iIz1MSzyXrfMMxyjLG/iLgBxGxE6XX8CrKB6tfAy+MiCdRekj/Rhk/fzzlQtTvjoinjHi/2zJz+aDbORH69qdfUXqobweujIhdO23YGGTm8sy8ot48KiK+VO8/nnKu0mcnaF19BngyZbsgIn4H3Ccz75dlBsIjgRcAt9WYnoPYPvOj+XFCTdUceSf58TeUoYj3zcx3UgrHvYCzKPvWRB53J5z5cQrnx66r9jZ/KCcof5k1FyhdANyVNUMUXkI5cNyl67YOaHmDkvB610B6F/C++vdhdWM7oIN2bQcs2oDnLaIMVTys3p5JGZPdu87TQspFZc8C3tb3umOAXTtYrl7vaFCugfS1EY8fX9u6wcMEWHt4wZdZc/HU3Si9wm+vtzelJMK3M8DrJ7F2T1pvPzkZuJGSaO/Jmh7cD1J6rz9AmeTiY32vfS1lmvjWt7cB/A96yzeTcn2451AuaPsBSg/1hF9Ee0P3mVEsy4y6vTyP8sFxQtdVPfaeQb2eHLAfcDHlW4SdKMl3reFw/rT7Y36cHPmxxr/T/X3Y8mOvjX3/+6HPkRuSH+t9s2p+/DZlJtl/a+O429I67Tw/1vjjzpHmxztoW9cbWKsLW6asfh+lZ7R/bPpdgffXHfuBXbdzAMvZG0LzNsrX4+dQTpI+mNJD/OC+x6+jpQsB1x3ve7U91wHPBeat5/mL6kH//jWpnEXpcdyPNYlwM8qsmVcC7+jwf34wZcjBDOAo4JWUYSR3GfG8KxlxQeb1/b/q79n1oHsyaz7QfIQyDGEmsHkLy/ecunxB6SH9dN22ntC3bi/u+zmKcm7CSX3b43+0ub0NaLl7bZ9Rt9uvAtdQeoWPqseTTzJBFzYe7T4zimW5mNLb/sC6P03ouuo/9va14cGUzoTPU84BuV/X63s6/2B+7DQ/1pgbvL8zRPmxtmXK5kjWkx9HHHevB/5C6YSY8ONuC+u00/zYF3vcORLz4x23reuNrLUFLSv6j8AufffNBA6gnGT7oa5WwgCXMUbcXlA3sJ9Txom/ijLs4Vt9z9myrbYBP6ZMp74Z5WvzK6gX8l3Ha7agXKj4Y8CvKF/HH10PRE9kTY/3XpThNWfQQS835fyH6yk9tL+mTvhAmQHvNf3LV5d/3w14z/7e0csoH14uovQMH0+5iOrc+vg7qOdaTPDyfYRyzsWp9f6PAn+lnGdxGmUqdSgzmt6dkiC/Xg+2vYNrK9vbBPwPvkrpFZ1JmSnw2L596ri67Q30fKWx7DMb+L7NuuptaxO5ru7o2Fvv758YYGjOu5mKP3e0jjA/tnq8Gu3+zpDkx9qGKZsj2YD8WG+fVn/eXV8zocfdltdv6/mxxh14jsT8uHb7ut64JnwB1wxveDXwxvr3/SmzXp1fN67dulwJE7DM7wCeXf9+St1R/7XuvOdQerjeUB+f0VKbnsras+UdQxkq8wtKr9O6CsVdKZdV+D11woSaAL7CmolSDqb0IG7W4f98d+AWSgLs9QYdTpnx6oOUqeL/ndLLtkEzAtYD4FOBj9bbh9T/15V9zzm0HhQndJbBEcs3p+/+3tCarwOPqvf1PpxsBDyJMuHFR9rc3ga87LMpPfb367tvr3rsOAB4GOUDwjYDjjumfWYD3vdzbayrDTj2nkEd9oaT1HTyswHryPzYXrtGvb8zJPmxtmPK5kjuPD/u2NZxt4P12kl+rHEGniPbWk8bcOydFPmx8w2slYUswzIupIyRPqQehP4bOLTrtk3Asi6kzEx3I2WigadQekb2qY/vTJnJrdWpyykzN/VmFjuecrHi3k59S90x/m6nq+39eN1hTgbuw5rrHp1D6S28gY6niAbuVhPdpfX3lpTzEJ5V///nU85H2ODhWpQe/NX1PRfW/8UJlKEHH6ZMU38N8ICWl+8D9M2wRTn3IqnnvdT10xvb/yLKrIHbdrl+xrnsm1KGQL28t8z19/uAL9S/xzQE9E7ijmmfWc/7BWVI1GXA4W2sq+l07B3Wn+m0jiZrfqyxR72/D0t+rG2dsjlyXfmxPnZcbeOv2zrutrxeO8mP9X0HliPNj+toY9cNmPAFLCv5iLqTnk75GvxxI5/TdTsnYLkfCHyrbnDnA5cD966PDfz6RBvYpqBcZ+vM3o5GOQn4GO7kWk31IPxNyvCae9X3egBlNqhJc60uSq/75ZSes83rfQ+lXGPs76Yq34D3exBlKMLT6+3tgL1rAnwJ9cT4DpbvQ9SewbqtXQD8Dnhi33NfBvyAKTDRBWUYyyUjlu8NdT1MWC/fePaZ9bzncyjX6ZrQdTVdj73D9DNd19FkzI819pj292HJj7WtUzZHric/fpEyrHbCj7sdrdNO8mONM9AcaX5c+6dX8U9pEbE95WDxfmBZZt7ScZNaUafFfiTlmkkHUhLi64HV2dGKr226jHJZhNsoX7U/JDP/uAGv3Yly0LkWOD4zz5vIto5VRNyXMmThbMq02/tTJkP4wxjfb2/K+P7XAWdk5spBtXWM7ekt3w8oB7gnAf+PcoHtV1KWewnwWODxmXlhR00dmIjYBHgFpWfy/4BbKUNp9snMiyc49pj3mXW833zKskz4upqux95hMl3X0WTMj33tGvX+Piz5EaZ2jlxHftyTcvmYVo67besyP9b4A8uR5se1TYsisV+9ns60Weh6raFZlJOlj8/MX3fcJCLiBZTzBG4HXpGZF4zitTsBn6B8RX9kZi6bmFaOT0Tcm9L7tBA4OjMvGuf77U0ZtvJ2yhCO28ffynG15++Wr14r6aGUD13XAt/OzN902MyBioiNKOdXPIUyQ90XMvOylmKPeZ9Zx/u1vq6m27F3GE23dTQZ8yOMfX8flvwIUztHrmvZpnKO7DI/1vgDy5HmxzWmXZE43UzaDS9iAWX7G/XFmSPiHsDKzLx68C0bnIiYRVnGFQN6v0cB/0npneu8x2nQy6f1G88+I+nvTdb8CGPf34clP8LUzpHmx/aZIwfPIlEaIhExLzNv67odkiRNNuZIaXAsEiVJkiRJjRldN0CSJEmSNHlYJEqSJEmSGhaJkiRJkqSGReJ6RMQh0yFmV3GNOfXiGnPqxZ0uMTV602XbmC4xu4przKkXd7rE7CpuWzEtEteviw2uqw9H02VZp0vMruIac+rFnS4xNXrTZduYLjG7imvMqRd3usTsKq5FoiRJkiSpXVP+EhizZs3O2bM3HtNrV65cwaxZGw24RRMXc+nS9q8d+w/bbj/m19625Fbmzd9k1K+78frrxxxz1aqVzJw5a9SvW7jlojHHXLrkVuaOYTkBVq1YOea4y5bdxsYbzxv162bOmjnmmEtvW8LcefNH/boZM8feXzXW7Qhg1cpVY3rdWJcTulnWuQtGvx303LJ4MQsWLhzTa2+9cWzHpKVLlzB37tj+vzdcf80NmbnVmF48Dc2evXHOnbtgTK9dvnwps2fPHXCLJi7m6tVj299XrLidjTaaM6bXLl++dEyvW7VqFTNnju1YvPmisW/+Yz6ejuOj5G233cq8eWM7hs8YY7667dZbmLfJ2Lb7v924eEyvW7nydmbNGtt2tGDhpmN6HYwvR47188CSW25h/oKx/X+vv/bPY3rdWD/fAWx5l7uM6XUAS5bcwvz5YzyGLls+ptctW3obG88dfV6/9ZbFLFt2W2zo88f23xwis2dvzD13e3C7QWOD//8DddFF/9d6zOce+vrWY55+wrGtx3zKQf/WekyAxX8ZWzIaj00XjT0ZjdX8zcZWEIzXzTfc3HrMeeMo2MZq94fv3npMgLNOP6v1mCcd++arWg86xObOXcBDHvLkrpvRii46Uq+88pLWYx7wby9rPWZXXzgs2GJsH87H49unf7n1mA974r6tx4Ru/r8n/ue7W4954KGvaD0mwB9++YdW433tjBNH9XyHm0qSJEmSGhaJkiRJkqSGRaIkSZIkqWGRKEmSJElqWCRKkiRJkhoWiZIkSZKkhkWiJEmSJKlhkShJkiRJalgkSpIkSZIak65IjIhTIuIdG/C83SLiZxFxS0S8oo22SZLUFfOjJKkts7puwDi8BvheZu7RdUMkSZpEzI+SpHGZdN8kjsIOwKVdN0KSpEnG/ChJGpfOi8SIeEBEXFiHxZwObNz32H51yMziiPhRROxe7/8u8AjgmIi4NSJ27aj5kiRNCPOjJKkrnRaJETEb+BLwSWAL4HPA0+pjDwBOBl4MbAkcD3w5IuZk5j7A2cDLM3OTzPz1iPc9JCIuiIgLVq5c0d4CSZI0ABOVH+vrmxy5fPnSdhZIkjRUuv4mcS9gI+ADmbkiM/8XOL8+dghwfGb+JDNXZeapwO31NeuVmSdk5p75/9u78zBL6/JM/PdjF910N0vLIoLIIooy4BZbMWMUonFXXKMxRoNbKyNxw1zGSOIeMzMmGqPGQKLkFyf+1HGLu04mGFdIwyAqyqgsguwgCM3WTX/njz71pmht7K6q/p46xedzXXVVnXPeOvfTLe3T93nf09Xa6qmpHbbb8ACwnWyX/ZjcekcuXbp8uwwPwGQbd0ncJ8lPW2ttxn3njz7vn+S40aU0V1fV1UnuOvoeAFjM7EcAxmbcJfHiJHepqppx336jzxckeWtrbdWMjxWttQ/1HxMAurIfARibcZfEbybZkORlVbVDVT01yYNGj52Y5CVVdXhtsrKqHl9VO49tWgDow34EYGzGWhJbazcneWqSo5NcleSZST4+emxtkhcleXeSnyX50eg4AFjU7EcAxmlq3AOMlt39t/DYF5J8YQuPHbkdxwKAsbIfARiXcV9uCgAAwAKiJAIAADBQEgEAABgoiQAAAAyURAAAAAZKIgAAAAMlEQAAgMHYf07i9rZy513ywIc9vGvmmaee0jVv2sEHr+6eed53zuue+eRnP7975hOf9VvdM5Pkb954UvfMXz/qwd0zX/qUo7pnJslTnvby7pkbN9zSPfPLH/9Y98wkec6rX9o/9L39IyfZsuXLctC979k185rLru6aN235zgd2z7zooh93z/zZpT/rnnnZTy7pnpkku915j+6ZGzdu7J75/W99v3tmklx66XndMzdsWN898+AHHtw9M0kOfch/6pr31a9/ZJuOdyYRAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAAADJREAAICBkggAAMBg7CWxqk6qqreMew4AWGjsSADGYewlEQAAgIVjTiWxqvaar0G28Px7VlVtzwwA2B7sSAAm1TaXxKpaVVXHVNWpSU4a3deq6u4zjhkuj6mqI6vqwqo6rqouq6qLq+p5W3junavqX6vqXaPF9/wk51bVG6vqwNn8AgGgFzsSgMVgq0piVd2hqh5VVR9Kcn6SRyV5a5KjtjLnzkl2TXKXJC9I8p6quuNmGbsn+ZckX2+tvaxt8l+T/E6SOyVZO1qOz6mqFb9i3jVVtbaq1t54w7qtHBEAtt0k78gbrrcjAfhFv7IkVtWxSc5L8udJvpnkoNbaU1prn2qtrd/KnPVJ3tRaW99a+1yS65Lcc8bj+yT5SpKPttaOn/mNrbVvtdaOGR3zN0meleTCqvq7LYW11k5ora1ura3ecfnKrRwRALbNpO/I5SvsSAB+0dacSTwwyR2TnJHk20munEXOla21DTNuX59kpxm3H59keZL3bekJWms3JTlzNMfNSQ6bxRwAMJ/sSAAWnV9ZEltrxyU5KMl3k/x1Nr3/4c1VdY8Zh12fZOblLXfexjlOTPKFJJ+rqlu9rFlVu1fVsaP3d/zvJEuS/GZr7cHbmAEA88qOBGAx2qr3JLbWLmut/WVr7T5JnpZkVZJvVtX7R4eckeR3q2pJVT0myRGzmOXYJGcn+XRVLU+SqnpBNl3Gc0SSNya5a2vtNa2178/i+QFg3tmRACw22/yvm7bWTmut/UE2vf9h+tKXlyd5YpKrkzw7ySdn8bwtyZokFyb5VFXtmE3v79i/tfbbrbXPttZu2dbnBYBe7EgAFoOp2X5ja+3mJKeOvl6b5NAtHHdykn03u++AGV8fPePrjUmeO+PQs2Y7HwCMix0JwCTb5jOJAAAALF5KIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGMz65yROiiVTS7Jqz127Zl5yyTld86b94Tv+vHvmX73mDd0zV656YvfMs3/4k+6ZSbJs+bLumddedW33zEc84jndM5Pkqisu6Z7505/+sHvmQx/Z/89MknzlIyePJZetV1VZumyHrpnHv+2lXfOmPf/p/XMPOeTXu2f+/Xv/tHvm059xXPfMJDn9lJO7Zx6w/2HdM7/zna90z0ySFx//2u6Z//axf+2e+baXvKZ7ZpKcdsbJXfP+24oV23S8M4kAAAAMlEQAAAAGSiIAAAADJREAAICBkggAAMBASQQAAGCgJAIAADBQEgEAABgoiQAAAAyURAAAAAYTXRKr6m1V9YpxzwEAC4n9CMBcTI17gNmqqj2TPDfJ3cc9CwAsFPYjAHM1yWcSj07yudbaDeMeBAAWkKNjPwIwB5NcEh+b5CvjHgIAFhj7EYA5meSSeO8kZ/+yB6pqTVWtraq1N6y7rvNYADBWW9yPyWY78vp1HccCYFJMcklcleTaX/ZAa+2E1trq1trq5St36jwWAIzVFvdjstmOXLGy41gATIpJLok/S7LzuIcAgAXGfgRgTia5JJ6Z5OBxDwEAC4z9CMCcTHJJ/FySI8Y9BAAsMPYjAHMysT8nMcn/l+SMqlrun/kGgIH9CMCcTOyZxNbaFdm0CF887lkAYKGwHwGYq0k+k5jW2h+PewYAWGjsRwDmYmLPJAIAADD/lEQAAAAGSiIAAAADJREAAICBkggAAMBASQQAAGCgJAIAADCY6J+TuDU23nJLrrtmXdfM33zU07rmTTvpz97TPfP+D3h498xT/u1L3TPvcIfxvJ5y8QXnd8885Pp7dc/c/U536p6ZJF3T80oAAB91SURBVLds2Ng9c7c97tw9c/2N67tnJsmDHnN498xPf/rd3TMn2U033JQfffv/ds086sgndc2bdsghv949c8mS/n/NeuWfvLN75vnf67+rkuQ/P/wx3TO/dXL/v4M8c80x3TOT5LMnfbx75q677tk98/gT3949M0le95b3dc376cWXb9PxziQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAAADJREAAICBkggAAMBASQQAAGCgJAIAADBQEgEAABh0L4lVdUBVtaqaGt3+fFX9fu85AGChsSMBWAimxj1Aa+2x454BABYiOxKAcZjzmcTpVzsBgFuzIwGYRLMqiVV1XlW9pqrOTLKuqo6vqh9X1bVVdVZVPWXGsUuq6u1VdUVVnZPk8Zs918lV9cLR12+oqg/OeGzzy26OrqpzRjnnVtWzZzM/AGwvdiQAk24ur3A+K5uW2RVJnpDkoUkuSfLbST5YVXdvrV2c5EWjx++fZF2Sj80mrKpWJnlXkge21s6uqr2T7LaFY9ckWZMkO+28ajZxADAXE7Ejly/faTZxACxyc7nc9F2ttQtaaze01j7aWruotbaxtfbhJD9M8qDRcc9I8s7RsVcledscMjcmOayqlrfWLm6tfe+XHdRaO6G1trq1tnr5ipVziAOAWZmIHbl06fI5xAGwWM2lJF4w/UVVPbeqzqiqq6vq6iSHJdlj9PA+M49Ncv5swlpr65I8M8lLklxcVZ+tqnvNbnQA2K7sSAAm1lxKYkuSqto/yYlJjk2ye2ttVZLvJqnRcRcnueuM79vvNp5zXZIVM27f+VaBrX2xtfbIJHsn+cEoFwAWGjsSgIk1Hz8ncWU2LcPLk6SqnpdNr5JO+0iSl1XVvlV1xyR/dBvPdUaSh1XVflW1a5LXTj9QVXtV1ZNG77u4Kcl12XRpDQAsVHYkABNnziWxtXZWkr9I8s0klya5d5KvzzjkxCRfTPLtJKcn+fhtPNeXk3w4yZlJTkvymc1mfVWSi5JcleSIJMfMdX4A2F7sSAAm0az+ddPW2gGb3X5dktdt4dgNSV45+pj2nhmPH7nZ8S9N8tIZd01fLnNxNi09AFiw7EgAJt18XG4KAADAIqEkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAwax+TuIkWTK1JLvsvkvXzIc8+SFd86Zd/JOfds88ePU9umeu2Hl598xlK5Z1z0ySO9/lrt0zT/ncKd0zTz/9i90zk+SQQ369e+bqR/zn7pnvfOOru2cmye8u+cOx5LL1rrnm8nz+8yf+6gPn0V3vekjXvGnr19/UPfNP3vGK7pnH/u7Lu2cefOj9u2cmybpr1nXPPOy+/ffGv/+vb3TPTJIHHNl/X73s2Gd1z3z+M1/5qw/aDlau2LVr3k3X37hNxzuTCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgMNElsapOrapDxz0HACwk9iMAczHRJTHJ25O8adxDAMACYz8CMGuTXhL/OclvVtWdxz0IACwg9iMAszbRJbG1dmOS05I8etyzAMBCYT8CMBdT4x5gHnw/yX1n3lFVa5KsSZJdVu02jpkAYNx+YT8mt96RAPDLTPSZxJFrk6yaeUdr7YTW2urW2uoVK3ca01gAMFa/sB+TW+/IMcwEwARYDCVx5yRXj3sIAFhg7EcAZmUxlMRDknx73EMAwAJjPwIwKxNdEqtqxyQPSPLlcc8CAAuF/QjAXEx0SUzyxCQnt9YuGvcgALCA2I8AzNqk/+umr07ygnEPAQALjP0IwKxNdElsrR0+7hkAYKGxHwGYi0m/3BQAAIB5pCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAACDaq2Ne4btauXKVe2ww36ja+YDHvLQrnnT7jC1pHvmxg23dM/89imndM/cbbc7d89Mkh/+8LTumXdctVf3zEc+40ndM5Pkhutu7J553c+u7Z75/ve+sXtmktx00w3dM6vqtNba6u7BE2rVqju1hz3smV0zL7/8gq5509av7//nfZdd9uieuXz5Tt0zd951VffMJNltn926Z/7s4p91z3zg4x7YPTNJ7n7IAd0z3/NH7+6eea/V9+6emSSnf/UbXfPOOONfcu21V9XWHu9MIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYLMqSWFVrqmptVa3dsOHmcY8DAAvGzB158803jHscABagRVkSW2sntNZWt9ZWT00tHfc4ALBgzNyRS5cuH/c4ACxAi7IkAgAAMDtKIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgMDXuAba35StX5rAHHN4189zv/7hr3rTff/3zumd+69Pf6p55xFGP6Z65dPnS7plJUmN4HeeAQ+/WPfPNx72we2aSHHXUH3TPPODQA7tn3nLLhu6ZSfKiY986lly23s0335gLL/hB18zr1l3dNW/aqlV36p75sCf/VvfM07+8tnvmuHbkP///f9c98xGPeVb3zC/8w6e7ZybJl770ge6ZZz3jUd0zv/u173bPTJI73Wm/rnlTU9v259SZRAAAAAZKIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwmBr3AHNRVe9Nktbaf9ns/jVJ1iTJyp12HcNkADA+W9qPo8eGHbnDDjt2ngyASTDRJfGXLb/R/SckOSFJ9rjTXVrXoQBgzLa0H0ePDTtyxYpd7EgAfoHLTQEAABgoiQAAAAyURAAAAAYTXRKr6n1V9b5xzwEAC4n9CMBcTPo/XPOScc8AAAuN/QjAXEz0mUQAAADml5IIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGE/1zErfGDkunstf+e3XN/PmVP++aN+3Csy/snnnlRVd1z9yw/pbumSt2XtE9M0m+/4Nvdc9s2dg989nP/ePumUmybOWO3TOvvOjK7pn7739o98wkueaKa8aSy9bbedWqHPnEJ3bNfN/bj++aN22//Q7pnnnN5f3/DKzcZefumT/83hndM5Nk6dLl3TOvuvTy7pn73eOg7plJ8rSnHdc9c4999+ie+aLXPLt7ZpKc8q3v9M077ZPbdLwziQAAAAyURAAAAAZKIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgsChLYlWtqaq1VbX2+nXXjXscAFgwZu7IG663IwH4RYuyJLbWTmitrW6trV6xcqdxjwMAC8bMHbl8hR0JwC9alCURAACA2VESAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGU+MeYHu7cd1NOfvUs7tmTi0dz2/rnx/3iu6ZHzr5i90z/+SFr+2eeej9H9g9M0l2333v7plH/ZendM98/QuO6Z6ZJKsf8Jjumce85UXdM7/yvz7aPTNJDn/cg7pnfvTD3SMn2oab1ufS8y7pmrl06Y5d86ZddtlPumfe5e5P7J658ZaN3TN322e37plJcvrX+p/r2GmXXbtnXnvVtd0zk+TSS8/rnnn4Ew7vnvnxf/xC98wkWbrj0q55G9av36bjnUkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAAADJREAAICBkggAAMBASQQAAGCgJAIAADBQEgEAABh0KYlVdXJVvbBHFgBMCvsRgIVoXkpiVU3Nx/OM6/kBYHuwHwGYRLMuiVV1XlW9pqrOTLKuqn6jqr5RVVdX1ber6sjRcW9N8tAk766q66rq3VV1QFW1mctt5qupVXV0VX29qt5RVVcmeUNVnVRV76mqz1bVtVV1SlUdNKdfPQDMM/sRgEk31zOJz0ry+CR3S/KpJG9JsluSVyf5WFXt2Vp7XZKvJjm2tbZTa+3YrXzuw5Ock2SvJG8d3fc7Sd6Y5I5JfjTj/lupqjVVtbaq1t500/Wz+5UBwOwtyP2Y3HpH3mhHAvBLzLUkvqu1dkGS30vyudba51prG1trX06yNsnj5vDcF7XW/rq1tqG1dsPovk+01k5trW1I8j+S3O+XfWNr7YTW2urW2uply1bMYQQAmJUFuR+TW+/IHe1IAH6JuZbEC0af90/y26NLaa6uqquT/EaSvefhuWe6ZMbX1yfZaQ7PDwDbi/0IwMSa6xve2+jzBUn+sbX2ol9x3LR1o88rkvx89PWdf8X3AMCksB8BmFjz9SMwPpjkiVX16KpaUlU7VtWRVbXv6PFLs+l9GUmS1trlSX6a5PdGxz8/iTfZA7DY2I8ATJx5KYmj9108KckfJ7k8m145/cMZz/9XSZ5eVT+rqneN7nvR6Jgrkxya5BvzMQsALBT2IwCTaNaXm7bWDtjs9ilJjtjCsd9McvBm930+yYFbOP6kJCdtdt/Rm90+Ocm+AYAFxH4EYNLN1+WmAAAALAJKIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGMz65yROivXrb8xFF/143GN08cznvaJ75le+8K3umWef/e/dM3/yk+93z0ySZ77gD7pnnv6l07pn/t4xr+qemSSXX3B598xT/+2M7pmv/7v3dM9Mkn9+zyfHksvW27ix5cZ1N3XNvOaa/n/ukuTAA+/TPfNrn/ha98y73eeg7plXXXxV98wk2Xvvu3XPXH/Tzd0zD7pf//9Nk2T3u+zePXPtF9d2zzzmT4/unpkkr3/JG7rmrfv5ddt0vDOJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGE1sSq+qhVXX2uOcAgIXEfgRgrqbGPcBstda+muSe454DABYS+xGAuZrYM4kAAADMvwVfEqvqvKp6bVWdVVU/q6oPVNWOVXVkVV047vkAYBzsRwC2lwVfEkeeneTRSQ5KcnCS42/r4KpaU1Vrq2rt+vU395gPAMZhm/ZjcusdedNN12/v+QCYQJNSEt/dWrugtXZVkrcmedZtHdxaO6G1trq1tnqHHZb2mRAA+tum/ZjcekcuW7Zi+08IwMSZlJJ4wYyvz0+yz7gGAYAFxH4EYN5NSkm864yv90ty0bgGAYAFxH4EYN5NSkl8aVXtW1W7JXldkg+PeyAAWADsRwDm3aSUxH9K8qUk5yT5cZK3jHccAFgQ7EcA5t3UuAfYSv/eWnvbZvednGTfMcwCAAuF/QjAvJuUM4kAAAB0oCQCAAAwWPCXm7bWDhj3DACw0NiPAGwvziQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAACDBf+vm85Vay3r19/YNfPw33xE17xpVdU98/T//e/dM3/t1x7ZPfP+Dzu8e2aS/NtnP989c/VvPKx75lWXXNU9M0kOvM+B3TO//umvdM+88MKzu2cmyav+8o3dMz/9mfd0z5xkVckdpvq+XvzYx67pmjdtl9127Z5574fdu3vmm/6g/+/v84/90+6ZSXLAYQd0zxzHvvrSxz7WPTNJfu3Xj+yeefgT+v9966kPeXj3zCR54Sv/pGve//3xt7bpeGcSAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGE1sSq+roqjpy3HMAwEJiPwIwV1PjHmBbVdWLk1z2Hzc33W6tfWKMYwHAWNmPAMyXSTyT+P4kByV5eZI/S7IhyafGOhEAjJ/9CMC8mLgziSMtSY0+bxx9HlTVmiRrkmTp0h27DwcAY3Kb+zG59Y5csWLnrsMBMBkm8Uzi85Ocm+SdSV6XZFmSJ888oLV2QmttdWtt9dTU0jGMCADd/cr9mNx6Ry5btqLziABMgok7k9ha+9tk0xvzN91s7xvvRAAwfvYjAPNl4kritNbaSeOeAQAWGvsRgLmaxMtNAQAA2E6URAAAAAZKIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABlPjHmB727Bhfa688qKumT+/4udd86addeap3TOf8Jzf6Z75iff/Q/fM735zWffMJNltt727Z+6yxy7dMy/4wQXdM5Nk1z127Z75gIcf3j3zkn86p3tmkuy4csex5LJtqqpr3vnnfbdr3rRrr92ne+Y4/gw8+Wkv7Z65w447dM9MkuU7L++e+dOvXtg989D7PLh7ZpL8+KyzumdO7dC/mrz6bW/vnpkk//KRL3TNu/7addt0vDOJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAG3UtiVR1QVa2qpka3P19Vv997DgBYaOxIABaCqXEP0Fp77LhnAICFyI4EYBzmfCZx+tVOAODW7EgAJtGsSmJVnVdVr6mqM5Osq6rjq+rHVXVtVZ1VVU+ZceySqnp7VV1RVeckefxmz3VyVb1w9PUbquqDMx7b/LKbo6vqnFHOuVX17NnMDwDbix0JwKSbyyucz8qmZXZFkickeWiSS5L8dpIPVtXdW2sXJ3nR6PH7J1mX5GOzCauqlUneleSBrbWzq2rvJLtt4dg1SdYkyZIlO8wmDgDmYiJ25IoVu8wmDoBFbi6Xm76rtXZBa+2G1tpHW2sXtdY2ttY+nOSHSR40Ou4ZSd45OvaqJG+bQ+bGJIdV1fLW2sWtte/9soNaaye01la31lYvWeJKHwC6m4gduWzZ8jnEAbBYzaUkXjD9RVU9t6rOqKqrq+rqJIcl2WP08D4zj01y/mzCWmvrkjwzyUuSXFxVn62qe81udADYruxIACbWXEpiS5Kq2j/JiUmOTbJ7a21Vku8mqdFxFye564zv2+82nnNdkhUzbt/5VoGtfbG19sgkeyf5wSgXABYaOxKAiTUfPydxZTYtw8uTpKqel02vkk77SJKXVdW+VXXHJH90G891RpKHVdV+VbVrktdOP1BVe1XVk0bvu7gpyXXZdGkNACxUdiQAE2fOJbG1dlaSv0jyzSSXJrl3kq/POOTEJF9M8u0kpyf5+G0815eTfDjJmUlOS/KZzWZ9VZKLklyV5Igkx8x1fgDYXuxIACbRrP5Vl9baAZvdfl2S123h2A1JXjn6mPaeGY8fudnxL03y0hl3TV8uc3E2LT0AWLDsSAAm3XxcbgoAAMAioSQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAAADJREAAIDBrH5O4iRZsmRJdt55t66Zex2wV9e8aT+/6p7dMy8595LumQcf/IDumQ96/OHdM5Pk65/8WvfMyy+4vHvmlZdd1j0zSZZM9X+d7NLzL+2eeeWVP+2emSRf/MAXx5LL1ptaOpU99t2ja+aG/7O+a960Aw8+pHvmnnfds3vmX77+lb/6oHm25hVv7p6ZJBtu3tA9c/e9d++eecpXv9w9M0mOeOxR3TN32X2X7pn/828/0D0zSX7vlcd0zfvhud/cpuOdSQQAAGCgJAIAADBQEgEAABgoiQAAAAyURAAAAAZKIgAAAAMlEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGExsSayqo6vqyHHPAQALif0IwFxNjXuAbVVVL05y2X/c3HS7tfaJMY4FAGNlPwIwXybxTOL7kxyU5OVJ/izJhiSfGutEADB+9iMA82LiziSOtCQ1+rxx9HlQVWuSrEmSHXZY1n04ABiT29yPya135E47r+o6HACTYRLPJD4/yblJ3pnkdUmWJXnyzANaaye01la31lZPTe0whhEBoLtfuR+TW+/I5StWdh4RgEkwcWcSW2t/m2x6Y/6mm+19450IAMbPfgRgvkxcSZzWWjtp3DMAwEJjPwIwV5N4uSkAAADbiZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAAADJREAAICBkggAAMBgatwDbG8bNqzPVVdd1DXz8gsu75o37ZJLzumeeb8j79c98/RvfLV75rJ/XdY9M0luuun67pkrd92pe+by5Tt3z0ySO0wt6Z55p/3u1D1z1137ZybJI5798O6Z//j+N3fPnGQ333hzfvKDc8c9RhfnnP297plLd1zaPfNpz3h598wdV+7YPTNJ9tp/r+6Z3/nKmd0zD7vPQ7pnJslZa8/onnn3Q/9T98wnP/+53TOT5DMf+ETXvKuvuHqbjncmEQAAgIGSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgMFElsaqWVdXfV9X5VXVtVZ1RVY8d91wAME72IwDzaaJKYpKpJBckOSLJrkmOT/KRqjpgjDMBwLjZjwDMm6lxD7AtWmvrkrxhxl2fqapzkzwgyXnjmAkAxs1+BGA+TVRJ3FxV7ZXk4CTf2+z+NUnWJMmSJRP9SwSAbbal/Th6bNiRy5fv1HkyACbBpF1uOqiqHZL8jyT/0Fr7wczHWmsntNZWt9ZW3+EOS8YzIACMwW3tx+TWO3Lp0uX9BwRgwZvIklhVd0jyj0luTnLsmMcBgAXBfgRgPkzctZhVVUn+PsleSR7XWls/5pEAYOzsRwDmy8SVxCR/k+SQJL/VWrth3MMAwAJhPwIwLybqctOq2j/Ji5PcL8klVXXd6OPZYx4NAMbGfgRgPk3UmcTW2vlJatxzAMBCYj8CMJ8m6kwiAAAA25eSCAAAwEBJBAAAYKAkAgAAMFASAQAAGCiJAAAADJREAAAABkoiAAAAg6lxD7C97bjjyhx88IO6Zt7/Effvmjftiosv7Z753a99r3vmvvves3vm01/21O6ZSfLix/bPXb585+6ZU0vH839FPz7jx90zf3ja2d0zr7/+590zk+T6a28YSy5bb/lOy3PYQ+7bNfPqqy/rmjftgLsf0j3zPkfcp3vma5/3nO6ZT3n6sd0zk+TmG2/qnrnPPe7SPfODf/vfu2cmyZFHPqt75r0efK/umSe+5b91z0ySl7z+tV3zfnT+Kdt0vDOJAAAADJREAAAABkoiAAAAAyURAACAgZIIAADAQEkEAABgoCQCAAAwUBIBAAAYKIkAAAAMlEQAAAAGSiIAAAADJREAAIDBvJTEqtprPp6n93MDwPZkPwIwiWZdEqtqVVUdU1WnJjlpdN8+VfWxqrq8qs6tqpfNOH5ZVb2zqi4afbyzqpaNHtujqj5TVVdX1VVV9dWqmp7tpKo6tapeUlWr5vBrBYDtzn4EYNJtU0msqjtU1aOq6kNJzk/yqCRvTXLUaGl9Osm3k9wlySOSvKKqHj369tcleXCS+yW5b5IHJTl+9NhxSS5MsmeSvZL8cZI2euyoJH+W5NFJzq+qf6qqR85Ykr9szjVVtbaq1t58843b8ksEgG02KftxNOuwI69fd908/OoBWGy2uiRW1bFJzkvy50m+meSg1tpTWmufaq2tT/LAJHu21t7UWru5tXZOkhOT/M7oKZ6d5E2ttctaa5cneWOS54weW59k7yT7t9bWt9a+2lprSTK6/cnW2lOSHJTkW0n+a5LzRjP9gtbaCa211a211UuX7rgtvx8AsE0maT+Ovm/YkStW7jS/vxkALArbcibxwCR3THJGNr0aeuVmj++fZJ/RJTFXV9XV2fSK5/R7JvbJpldXp50/ui9J/nuSHyX5UlWdU1V/tIUZrkxy5miGO45mAoBxsh8BWFS2uiS21o7Lplcqv5vkr5OcW1Vvrqp7jA65IMm5rbVVMz52bq09bvT4Rdm0KKftN7ovrbVrW2vHtdbulk2Xz7yqqh4xfWBV3aOq3pzk3CR/leQ7Se42mgkAxsZ+BGCx2ab3JI4uhfnL1tp9kjwtyaok36yq9yc5Ncm1VfWaqlpeVUuq6rCqeuDo2z+U5Piq2rOq9kjyp0k+mCRV9YSquntVVZJrktySZOPosfdn0+U7q5I8tbV239baO0aX5ADA2NmPACwmU7P9xtbaaUlOq6rjktyvtXZLVT0hyV9k0yuay5Kcnf948/1bkuySTZfDJMlHR/clyT2SvDub3pj/syTvba396+ix9yV5SWvt5tnOCgC92I8ATLpZl8Rpo+V06ujri5I8awvH3ZjkZaOPzR97R5J3bOH7Tp3rjADQm/0IwKSa9c9JBAAAYPFREgEAABgoiQAAAAyURAAAAAZKIgAAAAMlEQAAgIGSCAAAwKBaa+OeYbuqqsuTnD/Lb98jyRXzOM5CzRxXrszFlytz8eVOWub+rbU953OYxcyOlLkAcmUuvtzbS+a4cmebuU37cdGXxLmoqrWttdWLPXNcuTIXX67MxZd7e8lk291e/tu4vWSOK1fm4su9vWSOK7dXpstNAQAAGCiJAAAADJTE23bC7SRzXLkyF1+uzMWXe3vJZNvdXv7buL1kjitX5uLLvb1kjiu3S6b3JAIAADBwJhEAAICBkggAAMBASQQAAGCgJAIAADBQEgEAABj8Pxuz84o7/a4zAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x1800 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}